diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index a6d8e00..d746b1e 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
@@ -29,13 +29,29 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "\n",
+    "2\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
     "import wandb\n",
     "\n",
-    "\n",
+    "'''\n",
+    "            'lr': {\n",
+    "                'values': [5e-5, 1e-5]\n",
+    "            },\n",
+    "            'lambda': {\n",
+    "                'values': [0.90, 0.95, 1.0]\n",
+    "            },\n",
+    "            'clip_param': {\n",
+    "                'values': [0.2, 0.3, 0.4]\n",
+    "            },\n",
+    "            'num_sgd_iter': {\n",
+    "                'values': [30, 35, 40]\n",
+    "            },\n",
+    "            'entropy_coeff': {\n",
+    "                'values': [0.0, 1e-4]\n",
+    "            }\n",
+    "'''\n",
     "\n",
     "if __name__ == \"__main__\":\n",
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
@@ -48,61 +64,36 @@
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'num_envs_per_worker': {\n",
-    "                'values': [4, 6, 8]\n",
-    "            },\n",
-    "            'sgd_minibatch_size': {\n",
-    "                'values': [2**13, 2**13 + 2**12, 2**14, 2**14 + 2**13]\n",
-    "            },\n",
     "            'lr': {\n",
-    "                'values': [5e-5, 1e-5]\n",
+    "                'values': [1e-4, 5e-5]\n",
     "            },\n",
-    "            'lambda': {\n",
-    "                'values': [0.90, 0.95, 1.0]\n",
+    "            'use_gae': {\n",
+    "                'values': [False, True]\n",
     "            },\n",
-    "            'clip_param': {\n",
-    "                'values': [0.2, 0.3, 0.4]\n",
+    "            'sgd_minibatch_size': {\n",
+    "                'values': [12112, 14112]\n",
     "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [30, 40]\n",
+    "            'rollout_fragment_length': {\n",
+    "                'values': [512, 768, 1024]\n",
     "            },\n",
+    "            'num_envs_per_worker': {\n",
+    "                'values': [2, 3, 4]\n",
+    "            }\n",
     "        }\n",
     "    }"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
-     "ename": "CommError",
-     "evalue": "Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null.",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mException\u001b[0m: {'message': 'Variable \"entityName\" has invalid value null.\\nExpected type \"String!\", found null.', 'locations': [{'line': 1, 'column': 70}]}",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-4-e4d446407002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RLLIB_SWEEP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mwandb_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Create sweep with ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0msweep_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sweep_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upsertSweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmutation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmutation_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     variable_values={\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_print\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mCommError\u001b[0m: Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null."
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: uy2qf72q\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/uy2qf72q\n"
      ]
     }
    ],
@@ -112,7 +103,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [
     {
@@ -120,7380 +111,3729 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "2020-10-11 11:07:13,020 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-11 11:07:13,323 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:07:13,323 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "\trollout_fragment_length: 512\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "\tuse_gae: True\n",
+      "2020-10-11 11:07:13,326 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --rollout_fragment_length=512 --sgd_minibatch_size=12112 --use_gae=True\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpleasant-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/m8f9dubo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/y7fi985h\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_110715-y7fi985h\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:07:17,351\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:07:18,342 - wandb.wandb_agent - INFO - Running runs: ['y7fi985h']\n",
       "== Status ==\n",
-      "Memory usage on this node: 77.4/754.6 GiB\n",
+      "Memory usage on this node: 32.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-04-38\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "\u001b[2m\u001b[36m(pid=11517)\u001b[0m 2020-10-11 11:07:20,307\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=11458)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11409)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11409)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11378)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11378)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11439)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11439)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11505)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11505)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11424)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11424)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11397)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11397)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11460)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11460)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11403)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11403)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11417)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11417)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11463)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11463)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11400)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11400)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11465)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11465)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11420)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11420)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11415)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11415)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11422)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11422)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11419)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11419)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11440)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11440)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11392)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11392)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11442)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11442)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11405)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11405)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11454)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11454)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11443)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11443)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
+      "  custom_metrics: {}\n",
+      "  date: 2020-10-11_11-07-43\n",
+      "  done: false\n",
+      "  episode_len_mean: .nan\n",
+      "  episode_reward_max: .nan\n",
+      "  episode_reward_mean: .nan\n",
+      "  episode_reward_min: .nan\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 0\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.2355760846819197\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010150781566543239\n",
+      "        model: {}\n",
+      "        policy_loss: -0.034750696537750106\n",
+      "        total_loss: 483.26939610072543\n",
+      "        vf_explained_var: 0.12598323822021484\n",
+      "        vf_loss: 483.30223301478793\n",
+      "    num_steps_sampled: 80896\n",
+      "    num_steps_trained: 80896\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.00833333333333\n",
-      "    gpu_util_percent0: 0.3225\n",
+      "    cpu_util_percent: 27.990476190476194\n",
+      "    gpu_util_percent0: 0.3447619047619047\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 10.413888888888891\n",
-      "    vram_util_percent0: 0.27462328267920266\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    gpu_util_percent2: 0.0004761904761904762\n",
+      "    ram_util_percent: 6.061904761904761\n",
+      "    vram_util_percent0: 0.18846928735416763\n",
+      "    vram_util_percent1: 0.0009075233687267446\n",
+      "    vram_util_percent2: 0.0009075233687267446\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.18350994266746734\n",
-      "    mean_env_wait_ms: 1.6865222444501913\n",
-      "    mean_inference_ms: 5.985971555624452\n",
-      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
-      "  time_since_restore: 30.92910385131836\n",
-      "  time_this_iter_s: 30.92910385131836\n",
-      "  time_total_s: 30.92910385131836\n",
+      "  sampler_perf: {}\n",
+      "  time_since_restore: 17.069397449493408\n",
+      "  time_this_iter_s: 17.069397449493408\n",
+      "  time_total_s: 17.069397449493408\n",
       "  timers:\n",
-      "    learn_throughput: 7789.468\n",
-      "    learn_time_ms: 20770.611\n",
-      "    sample_throughput: 16046.653\n",
-      "    sample_time_ms: 10082.601\n",
-      "    update_time_ms: 36.409\n",
-      "  timestamp: 1602165878\n",
+      "    learn_throughput: 6812.619\n",
+      "    learn_time_ms: 11874.434\n",
+      "    sample_throughput: 15793.705\n",
+      "    sample_time_ms: 5122.041\n",
+      "    update_time_ms: 46.92\n",
+      "  timestamp: 1602414463\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 80896\n",
       "  training_iteration: 1\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 46.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      1 |          17.0694 | 80896 |      nan |                  nan |                  nan |                nan |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-05-08\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3621.1951219512193\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-07-59\n",
       "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 890.7215189873418\n",
+      "  episode_reward_max: 264.20202020201947\n",
+      "  episode_reward_mean: 215.95211609768555\n",
+      "  episode_reward_min: 129.0505050505048\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.104918122291565\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010646762725497996\n",
       "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        policy_loss: -0.02715139969119004\n",
+      "        total_loss: 541.7598702566964\n",
+      "        vf_explained_var: 0.5573452711105347\n",
+      "        vf_loss: 541.7850167410714\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.90294117647059\n",
-      "    gpu_util_percent0: 0.26941176470588235\n",
+      "    cpu_util_percent: 26.663157894736845\n",
+      "    gpu_util_percent0: 0.35105263157894734\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.747058823529413\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.178947368421054\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17676173480204843\n",
-      "    mean_env_wait_ms: 1.6752662514608032\n",
-      "    mean_inference_ms: 5.6785297305935405\n",
-      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
-      "  time_since_restore: 59.91080617904663\n",
-      "  time_this_iter_s: 28.98170232772827\n",
-      "  time_total_s: 59.91080617904663\n",
+      "    mean_action_processing_ms: 0.17199406472206408\n",
+      "    mean_env_wait_ms: 1.2088235111360235\n",
+      "    mean_inference_ms: 5.708397346795727\n",
+      "    mean_raw_obs_processing_ms: 0.4642650336901248\n",
+      "  time_since_restore: 33.077258348464966\n",
+      "  time_this_iter_s: 16.007860898971558\n",
+      "  time_total_s: 33.077258348464966\n",
       "  timers:\n",
-      "    learn_throughput: 7835.536\n",
-      "    learn_time_ms: 20648.493\n",
-      "    sample_throughput: 17536.73\n",
-      "    sample_time_ms: 9225.893\n",
-      "    update_time_ms: 38.294\n",
-      "  timestamp: 1602165908\n",
+      "    learn_throughput: 6884.162\n",
+      "    learn_time_ms: 11751.032\n",
+      "    sample_throughput: 17143.081\n",
+      "    sample_time_ms: 4718.872\n",
+      "    update_time_ms: 36.16\n",
+      "  timestamp: 1602414479\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 161792\n",
       "  training_iteration: 2\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      2 |          33.0773 | 161792 |  215.952 |              264.202 |              129.051 |            890.722 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-05-37\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3621.1951219512193\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-08-14\n",
       "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 890.7215189873418\n",
+      "  episode_reward_max: 264.20202020201947\n",
+      "  episode_reward_mean: 215.95211609768555\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1451326949255807\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013103859898235117\n",
       "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        policy_loss: -0.03772170841693878\n",
+      "        total_loss: 61.807167053222656\n",
+      "        vf_explained_var: 0.3047725260257721\n",
+      "        vf_loss: 61.842381068638396\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.057142857142864\n",
-      "    gpu_util_percent0: 0.2717142857142857\n",
+      "    cpu_util_percent: 25.03684210526316\n",
+      "    gpu_util_percent0: 0.3068421052631579\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762857142857143\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.205263157894738\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17253118731808845\n",
-      "    mean_env_wait_ms: 1.669123154241675\n",
-      "    mean_inference_ms: 5.508714332828136\n",
-      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
-      "  time_since_restore: 89.00577521324158\n",
-      "  time_this_iter_s: 29.094969034194946\n",
-      "  time_total_s: 89.00577521324158\n",
+      "    mean_action_processing_ms: 0.17199406472206408\n",
+      "    mean_env_wait_ms: 1.2088235111360235\n",
+      "    mean_inference_ms: 5.708397346795727\n",
+      "    mean_raw_obs_processing_ms: 0.4642650336901248\n",
+      "  time_since_restore: 48.5854651927948\n",
+      "  time_this_iter_s: 15.508206844329834\n",
+      "  time_total_s: 48.5854651927948\n",
       "  timers:\n",
-      "    learn_throughput: 7852.583\n",
-      "    learn_time_ms: 20603.665\n",
-      "    sample_throughput: 18018.223\n",
-      "    sample_time_ms: 8979.354\n",
-      "    update_time_ms: 41.291\n",
-      "  timestamp: 1602165937\n",
+      "    learn_throughput: 6932.543\n",
+      "    learn_time_ms: 11669.022\n",
+      "    sample_throughput: 18134.025\n",
+      "    sample_time_ms: 4461.006\n",
+      "    update_time_ms: 31.075\n",
+      "  timestamp: 1602414494\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 242688\n",
       "  training_iteration: 3\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      3 |          48.5855 | 242688 |  215.952 |              264.202 |              129.051 |            890.722 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-06-05\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3618.8718861209964\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-08-30\n",
       "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 879.4493670886076\n",
+      "  episode_reward_max: 268.4444444444444\n",
+      "  episode_reward_mean: 217.9453075054339\n",
+      "  episode_reward_min: 129.0505050505048\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1018210308892387\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011968836055270262\n",
       "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        policy_loss: -0.030419912987521718\n",
+      "        total_loss: 338.2612871442522\n",
+      "        vf_explained_var: 0.7406534552574158\n",
+      "        vf_loss: 338.2894199916295\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.938235294117646\n",
-      "    gpu_util_percent0: 0.24941176470588236\n",
+      "    cpu_util_percent: 23.910526315789475\n",
+      "    gpu_util_percent0: 0.4221052631578948\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.205263157894738\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16972262222291365\n",
-      "    mean_env_wait_ms: 1.6663911084469907\n",
-      "    mean_inference_ms: 5.381286213374226\n",
-      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
-      "  time_since_restore: 117.6076283454895\n",
-      "  time_this_iter_s: 28.601853132247925\n",
-      "  time_total_s: 117.6076283454895\n",
+      "    mean_action_processing_ms: 0.1664683872326604\n",
+      "    mean_env_wait_ms: 1.2090395135359495\n",
+      "    mean_inference_ms: 5.448400692912778\n",
+      "    mean_raw_obs_processing_ms: 0.44806285347677643\n",
+      "  time_since_restore: 64.0004415512085\n",
+      "  time_this_iter_s: 15.414976358413696\n",
+      "  time_total_s: 64.0004415512085\n",
       "  timers:\n",
-      "    learn_throughput: 7898.804\n",
-      "    learn_time_ms: 20483.102\n",
-      "    sample_throughput: 18320.006\n",
-      "    sample_time_ms: 8831.438\n",
-      "    update_time_ms: 41.53\n",
-      "  timestamp: 1602165965\n",
+      "    learn_throughput: 6942.391\n",
+      "    learn_time_ms: 11652.47\n",
+      "    sample_throughput: 18954.078\n",
+      "    sample_time_ms: 4268.0\n",
+      "    update_time_ms: 31.145\n",
+      "  timestamp: 1602414510\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 323584\n",
       "  training_iteration: 4\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      4 |          64.0004 | 323584 |  217.945 |              268.444 |              129.051 |            879.449 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-06-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3619.0141843971633\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-08-45\n",
       "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 879.3028391167193\n",
+      "  episode_reward_max: 268.4444444444444\n",
+      "  episode_reward_mean: 217.9397125832455\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 1\n",
+      "  episodes_total: 317\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0629650694983346\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013246477182422365\n",
       "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        policy_loss: -0.0353440453431436\n",
+      "        total_loss: 32.55528858729771\n",
+      "        vf_explained_var: 0.8335528373718262\n",
+      "        vf_loss: 32.588090079171316\n",
+      "    num_steps_sampled: 404480\n",
+      "    num_steps_trained: 404480\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.05\n",
-      "    gpu_util_percent0: 0.27676470588235297\n",
+      "    cpu_util_percent: 24.61666666666666\n",
+      "    gpu_util_percent0: 0.3338888888888889\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.222222222222222\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1668569945682094\n",
-      "    mean_env_wait_ms: 1.6661518036410352\n",
-      "    mean_inference_ms: 5.245339771382172\n",
-      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
-      "  time_since_restore: 146.34429287910461\n",
-      "  time_this_iter_s: 28.736664533615112\n",
-      "  time_total_s: 146.34429287910461\n",
+      "    mean_action_processing_ms: 0.1664021890297938\n",
+      "    mean_env_wait_ms: 1.2090652828885642\n",
+      "    mean_inference_ms: 5.445749303343484\n",
+      "    mean_raw_obs_processing_ms: 0.44791848390135747\n",
+      "  time_since_restore: 79.37057852745056\n",
+      "  time_this_iter_s: 15.370136976242065\n",
+      "  time_total_s: 79.37057852745056\n",
       "  timers:\n",
-      "    learn_throughput: 7912.652\n",
-      "    learn_time_ms: 20447.253\n",
-      "    sample_throughput: 18556.235\n",
-      "    sample_time_ms: 8719.01\n",
-      "    update_time_ms: 53.489\n",
-      "  timestamp: 1602165994\n",
+      "    learn_throughput: 6943.782\n",
+      "    learn_time_ms: 11650.135\n",
+      "    sample_throughput: 19496.779\n",
+      "    sample_time_ms: 4149.198\n",
+      "    update_time_ms: 29.133\n",
+      "  timestamp: 1602414525\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 404480\n",
       "  training_iteration: 5\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      5 |          79.3706 | 404480 |   217.94 |              268.444 |              129.051 |            879.303 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-07-03\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3614.5466970387242\n",
+      "    time_step_min: 3301\n",
+      "  date: 2020-10-11_11-09-01\n",
       "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 874.873417721519\n",
+      "  episode_reward_max: 268.4444444444444\n",
+      "  episode_reward_mean: 218.84496867408242\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 157\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1305710928780692\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.00940956494637898\n",
       "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        policy_loss: -0.02775775800858225\n",
+      "        total_loss: 86.53898402622768\n",
+      "        vf_explained_var: 0.8763986229896545\n",
+      "        vf_loss: 86.56497410365513\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.087878787878783\n",
-      "    gpu_util_percent0: 0.2751515151515152\n",
+      "    cpu_util_percent: 23.37368421052631\n",
+      "    gpu_util_percent0: 0.3310526315789474\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751515151515152\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.1947368421052635\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16521363319543925\n",
-      "    mean_env_wait_ms: 1.6677695579501226\n",
-      "    mean_inference_ms: 5.160918708210536\n",
-      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
-      "  time_since_restore: 174.83844447135925\n",
-      "  time_this_iter_s: 28.49415159225464\n",
-      "  time_total_s: 174.83844447135925\n",
+      "    mean_action_processing_ms: 0.16330449318082624\n",
+      "    mean_env_wait_ms: 1.2084176545278669\n",
+      "    mean_inference_ms: 5.27002022088971\n",
+      "    mean_raw_obs_processing_ms: 0.43788779842756653\n",
+      "  time_since_restore: 94.90622282028198\n",
+      "  time_this_iter_s: 15.535644292831421\n",
+      "  time_total_s: 94.90622282028198\n",
       "  timers:\n",
-      "    learn_throughput: 7937.482\n",
-      "    learn_time_ms: 20383.289\n",
-      "    sample_throughput: 18693.433\n",
-      "    sample_time_ms: 8655.018\n",
-      "    update_time_ms: 51.581\n",
-      "  timestamp: 1602166023\n",
+      "    learn_throughput: 6931.717\n",
+      "    learn_time_ms: 11670.414\n",
+      "    sample_throughput: 19865.372\n",
+      "    sample_time_ms: 4072.212\n",
+      "    update_time_ms: 30.704\n",
+      "  timestamp: 1602414541\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 485376\n",
       "  training_iteration: 6\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      6 |          94.9062 | 485376 |  218.845 |              268.444 |              129.051 |            874.873 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-07-31\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3599.7512605042016\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-09-16\n",
       "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 870.7253968253968\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 221.0759980759979\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 156\n",
+      "  episodes_total: 630\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0338162354060583\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01128895820251533\n",
       "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        policy_loss: -0.030630421425615038\n",
+      "        total_loss: 76.87986101422992\n",
+      "        vf_explained_var: 0.9067110419273376\n",
+      "        vf_loss: 76.90833718436105\n",
+      "    num_steps_sampled: 566272\n",
+      "    num_steps_trained: 566272\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.423529411764708\n",
-      "    gpu_util_percent0: 0.25617647058823534\n",
+      "    cpu_util_percent: 23.899999999999995\n",
+      "    gpu_util_percent0: 0.34444444444444444\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16428938352115002\n",
-      "    mean_env_wait_ms: 1.6688146539398103\n",
-      "    mean_inference_ms: 5.1135213379920055\n",
-      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
-      "  time_since_restore: 203.33799719810486\n",
-      "  time_this_iter_s: 28.499552726745605\n",
-      "  time_total_s: 203.33799719810486\n",
+      "    mean_action_processing_ms: 0.16143699532427172\n",
+      "    mean_env_wait_ms: 1.2088684311529978\n",
+      "    mean_inference_ms: 5.161913655684243\n",
+      "    mean_raw_obs_processing_ms: 0.4322594420046009\n",
+      "  time_since_restore: 110.28288292884827\n",
+      "  time_this_iter_s: 15.376660108566284\n",
+      "  time_total_s: 110.28288292884827\n",
       "  timers:\n",
-      "    learn_throughput: 7953.152\n",
-      "    learn_time_ms: 20343.13\n",
-      "    sample_throughput: 18800.381\n",
-      "    sample_time_ms: 8605.783\n",
-      "    update_time_ms: 48.851\n",
-      "  timestamp: 1602166051\n",
+      "    learn_throughput: 6934.629\n",
+      "    learn_time_ms: 11665.512\n",
+      "    sample_throughput: 20147.728\n",
+      "    sample_time_ms: 4015.143\n",
+      "    update_time_ms: 30.898\n",
+      "  timestamp: 1602414556\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 566272\n",
       "  training_iteration: 7\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      7 |          110.283 | 566272 |  221.076 |              282.687 |              129.051 |            870.725 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-00\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3600.165829145729\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-09-32\n",
       "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 870.8433544303797\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 221.01516749776226\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 2\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0777911799294608\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012940970515566213\n",
       "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        policy_loss: -0.03934905957430601\n",
+      "        total_loss: 11.274031366620745\n",
+      "        vf_explained_var: 0.8349117636680603\n",
+      "        vf_loss: 11.310900688171387\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.724242424242426\n",
-      "    gpu_util_percent0: 0.2678787878787879\n",
+      "    cpu_util_percent: 22.973684210526315\n",
+      "    gpu_util_percent0: 0.3068421052631579\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16348854866217513\n",
-      "    mean_env_wait_ms: 1.6700574598453726\n",
-      "    mean_inference_ms: 5.072164794599845\n",
-      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
-      "  time_since_restore: 231.6390438079834\n",
-      "  time_this_iter_s: 28.30104660987854\n",
-      "  time_total_s: 231.6390438079834\n",
+      "    mean_action_processing_ms: 0.1614256084534045\n",
+      "    mean_env_wait_ms: 1.2089110374403544\n",
+      "    mean_inference_ms: 5.160506855743884\n",
+      "    mean_raw_obs_processing_ms: 0.4322031186244616\n",
+      "  time_since_restore: 125.68149065971375\n",
+      "  time_this_iter_s: 15.398607730865479\n",
+      "  time_total_s: 125.68149065971375\n",
       "  timers:\n",
-      "    learn_throughput: 7959.464\n",
-      "    learn_time_ms: 20326.997\n",
-      "    sample_throughput: 18968.066\n",
-      "    sample_time_ms: 8529.705\n",
-      "    update_time_ms: 47.225\n",
-      "  timestamp: 1602166080\n",
+      "    learn_throughput: 6932.158\n",
+      "    learn_time_ms: 11669.671\n",
+      "    sample_throughput: 20402.25\n",
+      "    sample_time_ms: 3965.053\n",
+      "    update_time_ms: 32.067\n",
+      "  timestamp: 1602414572\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 647168\n",
       "  training_iteration: 8\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      8 |          125.681 | 647168 |  221.015 |              282.687 |              129.051 |            870.843 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-28\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3583.548344370861\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-09-47\n",
       "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 864.9392405063292\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 223.6602096918551\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0281649146761214\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010988853871822357\n",
       "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        policy_loss: -0.03038667674575533\n",
+      "        total_loss: 99.28263092041016\n",
+      "        vf_explained_var: 0.9136572480201721\n",
+      "        vf_loss: 99.31092398507255\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.59705882352941\n",
-      "    gpu_util_percent0: 0.25941176470588234\n",
+      "    cpu_util_percent: 24.577777777777776\n",
+      "    gpu_util_percent0: 0.35444444444444445\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.162284443845516\n",
-      "    mean_env_wait_ms: 1.6727489665801578\n",
-      "    mean_inference_ms: 5.009821132584934\n",
-      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
-      "  time_since_restore: 259.97689414024353\n",
-      "  time_this_iter_s: 28.337850332260132\n",
-      "  time_total_s: 259.97689414024353\n",
+      "    mean_action_processing_ms: 0.15995345913671608\n",
+      "    mean_env_wait_ms: 1.2100571945889735\n",
+      "    mean_inference_ms: 5.073819843280334\n",
+      "    mean_raw_obs_processing_ms: 0.42774308899470204\n",
+      "  time_since_restore: 140.99153351783752\n",
+      "  time_this_iter_s: 15.31004285812378\n",
+      "  time_total_s: 140.99153351783752\n",
       "  timers:\n",
-      "    learn_throughput: 7968.61\n",
-      "    learn_time_ms: 20303.667\n",
-      "    sample_throughput: 19067.411\n",
-      "    sample_time_ms: 8485.263\n",
-      "    update_time_ms: 45.663\n",
-      "  timestamp: 1602166108\n",
+      "    learn_throughput: 6935.861\n",
+      "    learn_time_ms: 11663.441\n",
+      "    sample_throughput: 20591.808\n",
+      "    sample_time_ms: 3928.553\n",
+      "    update_time_ms: 31.2\n",
+      "  timestamp: 1602414587\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 728064\n",
       "  training_iteration: 9\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      9 |          140.992 | 728064 |   223.66 |              282.687 |              129.051 |            864.939 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-57\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3581.105128205128\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-02\n",
       "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 863.6822085889571\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 224.0084898060356\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 25\n",
+      "  episodes_total: 815\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.987507028239114\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013111596660954612\n",
       "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        policy_loss: -0.03521772553878171\n",
+      "        total_loss: 20.77414403642927\n",
+      "        vf_explained_var: 0.9506732225418091\n",
+      "        vf_loss: 20.806838989257812\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.339393939393936\n",
-      "    gpu_util_percent0: 0.29575757575757583\n",
+      "    cpu_util_percent: 23.28421052631579\n",
+      "    gpu_util_percent0: 0.3494736842105264\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16170883141459513\n",
-      "    mean_env_wait_ms: 1.6746347609608598\n",
-      "    mean_inference_ms: 4.978956771385591\n",
-      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
-      "  time_since_restore: 288.5126984119415\n",
-      "  time_this_iter_s: 28.535804271697998\n",
-      "  time_total_s: 288.5126984119415\n",
+      "    mean_action_processing_ms: 0.15973198961384183\n",
+      "    mean_env_wait_ms: 1.2103405669664478\n",
+      "    mean_inference_ms: 5.061434809621857\n",
+      "    mean_raw_obs_processing_ms: 0.42702146120421813\n",
+      "  time_since_restore: 156.33395624160767\n",
+      "  time_this_iter_s: 15.342422723770142\n",
+      "  time_total_s: 156.33395624160767\n",
       "  timers:\n",
-      "    learn_throughput: 7972.454\n",
-      "    learn_time_ms: 20293.877\n",
-      "    sample_throughput: 19124.35\n",
-      "    sample_time_ms: 8460.0\n",
-      "    update_time_ms: 44.735\n",
-      "  timestamp: 1602166137\n",
+      "    learn_throughput: 6938.897\n",
+      "    learn_time_ms: 11658.337\n",
+      "    sample_throughput: 20727.776\n",
+      "    sample_time_ms: 3902.782\n",
+      "    update_time_ms: 30.607\n",
+      "  timestamp: 1602414602\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 808960\n",
       "  training_iteration: 10\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     10 |          156.334 | 808960 |  224.008 |              282.687 |              129.051 |            863.682 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-25\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3571.9802847754654\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-18\n",
       "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 859.967299578059\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 225.29475131057393\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 133\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.045826860836574\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009954532741435937\n",
       "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        policy_loss: -0.029595830610820224\n",
+      "        total_loss: 18.947863715035574\n",
+      "        vf_explained_var: 0.9571961164474487\n",
+      "        vf_loss: 18.975573131016322\n",
+      "    num_steps_sampled: 889856\n",
+      "    num_steps_trained: 889856\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.45151515151515\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 24.211111111111112\n",
+      "    gpu_util_percent0: 0.3644444444444444\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.194444444444445\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125382205207386\n",
-      "    mean_env_wait_ms: 1.6761243985903949\n",
-      "    mean_inference_ms: 4.954596343237678\n",
-      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
-      "  time_since_restore: 316.5878527164459\n",
-      "  time_this_iter_s: 28.075154304504395\n",
-      "  time_total_s: 316.5878527164459\n",
+      "    mean_action_processing_ms: 0.15879813645463797\n",
+      "    mean_env_wait_ms: 1.211128149274603\n",
+      "    mean_inference_ms: 5.005509192438234\n",
+      "    mean_raw_obs_processing_ms: 0.42413205982647995\n",
+      "  time_since_restore: 171.7176637649536\n",
+      "  time_this_iter_s: 15.383707523345947\n",
+      "  time_total_s: 171.7176637649536\n",
       "  timers:\n",
-      "    learn_throughput: 8000.406\n",
-      "    learn_time_ms: 20222.974\n",
-      "    sample_throughput: 19629.04\n",
-      "    sample_time_ms: 8242.482\n",
-      "    update_time_ms: 45.435\n",
-      "  timestamp: 1602166165\n",
+      "    learn_throughput: 6953.498\n",
+      "    learn_time_ms: 11633.857\n",
+      "    sample_throughput: 21513.646\n",
+      "    sample_time_ms: 3760.218\n",
+      "    update_time_ms: 28.069\n",
+      "  timestamp: 1602414618\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 889856\n",
       "  training_iteration: 11\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     11 |          171.718 | 889856 |  225.295 |              282.687 |              129.051 |            859.967 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-54\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3566.089635854342\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-33\n",
       "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 856.50904159132\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 226.2248707691744\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9601052488599505\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012055230060858386\n",
       "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        policy_loss: -0.030359721343432153\n",
+      "        total_loss: 37.07370104108538\n",
+      "        vf_explained_var: 0.9558514952659607\n",
+      "        vf_loss: 37.10174560546875\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.993939393939392\n",
-      "    gpu_util_percent0: 0.26969696969696966\n",
+      "    cpu_util_percent: 23.46315789473684\n",
+      "    gpu_util_percent0: 0.3863157894736842\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757575757575758\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16085250209822033\n",
-      "    mean_env_wait_ms: 1.6775510346401423\n",
-      "    mean_inference_ms: 4.932401985457557\n",
-      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
-      "  time_since_restore: 345.2145109176636\n",
-      "  time_this_iter_s: 28.62665820121765\n",
-      "  time_total_s: 345.2145109176636\n",
+      "    mean_action_processing_ms: 0.15789295050711372\n",
+      "    mean_env_wait_ms: 1.2122332529673068\n",
+      "    mean_inference_ms: 4.951915592301066\n",
+      "    mean_raw_obs_processing_ms: 0.4213907139795608\n",
+      "  time_since_restore: 187.1134786605835\n",
+      "  time_this_iter_s: 15.395814895629883\n",
+      "  time_total_s: 187.1134786605835\n",
       "  timers:\n",
-      "    learn_throughput: 8013.686\n",
-      "    learn_time_ms: 20189.46\n",
-      "    sample_throughput: 19635.364\n",
-      "    sample_time_ms: 8239.827\n",
-      "    update_time_ms: 45.402\n",
-      "  timestamp: 1602166194\n",
+      "    learn_throughput: 6954.196\n",
+      "    learn_time_ms: 11632.689\n",
+      "    sample_throughput: 21859.474\n",
+      "    sample_time_ms: 3700.729\n",
+      "    update_time_ms: 27.535\n",
+      "  timestamp: 1602414633\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 970752\n",
       "  training_iteration: 12\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     12 |          187.113 | 970752 |  226.225 |              282.687 |              117.687 |            856.509 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-22\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3566.089635854342\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-49\n",
       "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 856.50904159132\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 226.2248707691744\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9797454476356506\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012896751053631306\n",
       "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        policy_loss: -0.041537076767001836\n",
+      "        total_loss: 7.74065773827689\n",
+      "        vf_explained_var: 0.9532109498977661\n",
+      "        vf_loss: 7.779713494437082\n",
+      "    num_steps_sampled: 1051648\n",
+      "    num_steps_trained: 1051648\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.370588235294115\n",
-      "    gpu_util_percent0: 0.2747058823529412\n",
+      "    cpu_util_percent: 23.205555555555556\n",
+      "    gpu_util_percent0: 0.36388888888888893\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16017287678084888\n",
-      "    mean_env_wait_ms: 1.6802277086992836\n",
-      "    mean_inference_ms: 4.89439148640374\n",
-      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
-      "  time_since_restore: 373.45997977256775\n",
-      "  time_this_iter_s: 28.245468854904175\n",
-      "  time_total_s: 373.45997977256775\n",
+      "    mean_action_processing_ms: 0.1578929505071137\n",
+      "    mean_env_wait_ms: 1.2122332529673068\n",
+      "    mean_inference_ms: 4.951915592301066\n",
+      "    mean_raw_obs_processing_ms: 0.42139071397956074\n",
+      "  time_since_restore: 202.41565418243408\n",
+      "  time_this_iter_s: 15.302175521850586\n",
+      "  time_total_s: 202.41565418243408\n",
       "  timers:\n",
-      "    learn_throughput: 8026.419\n",
-      "    learn_time_ms: 20157.433\n",
-      "    sample_throughput: 19763.446\n",
-      "    sample_time_ms: 8186.427\n",
-      "    update_time_ms: 44.475\n",
-      "  timestamp: 1602166222\n",
+      "    learn_throughput: 6946.916\n",
+      "    learn_time_ms: 11644.879\n",
+      "    sample_throughput: 22062.043\n",
+      "    sample_time_ms: 3666.75\n",
+      "    update_time_ms: 28.95\n",
+      "  timestamp: 1602414649\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 1051648\n",
       "  training_iteration: 13\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     13 |          202.416 | 1051648 |  226.225 |              282.687 |              117.687 |            856.509 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-50\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3559.820179007323\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-04\n",
       "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 853.4018987341772\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 227.41044943101886\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9573245303971427\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010491540655493736\n",
       "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        policy_loss: -0.02854319236108235\n",
+      "        total_loss: 28.880344118390763\n",
+      "        vf_explained_var: 0.9712379574775696\n",
+      "        vf_loss: 28.906884329659597\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.312121212121212\n",
-      "    gpu_util_percent0: 0.26151515151515153\n",
+      "    cpu_util_percent: 23.321052631578947\n",
+      "    gpu_util_percent0: 0.2831578947368421\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.772727272727275\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15988462752258317\n",
-      "    mean_env_wait_ms: 1.6814425515145586\n",
-      "    mean_inference_ms: 4.878041025826835\n",
-      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
-      "  time_since_restore: 401.80727195739746\n",
-      "  time_this_iter_s: 28.347292184829712\n",
-      "  time_total_s: 401.80727195739746\n",
+      "    mean_action_processing_ms: 0.1571431737437744\n",
+      "    mean_env_wait_ms: 1.213288599347626\n",
+      "    mean_inference_ms: 4.906653870888696\n",
+      "    mean_raw_obs_processing_ms: 0.4189866891285491\n",
+      "  time_since_restore: 217.90839791297913\n",
+      "  time_this_iter_s: 15.492743730545044\n",
+      "  time_total_s: 217.90839791297913\n",
       "  timers:\n",
-      "    learn_throughput: 8023.866\n",
-      "    learn_time_ms: 20163.846\n",
-      "    sample_throughput: 19841.783\n",
-      "    sample_time_ms: 8154.106\n",
-      "    update_time_ms: 44.12\n",
-      "  timestamp: 1602166250\n",
+      "    learn_throughput: 6942.93\n",
+      "    learn_time_ms: 11651.565\n",
+      "    sample_throughput: 22027.115\n",
+      "    sample_time_ms: 3672.564\n",
+      "    update_time_ms: 29.496\n",
+      "  timestamp: 1602414664\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 1132544\n",
       "  training_iteration: 14\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     14 |          217.908 | 1132544 |   227.41 |              282.687 |              117.687 |            853.402 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-19\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3553.6249062265565\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-20\n",
       "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 851.2441520467836\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 228.1558125110755\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 104\n",
+      "  episodes_total: 1368\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9227380497114999\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012362753839365073\n",
       "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        policy_loss: -0.03274130182606833\n",
+      "        total_loss: 24.246925626482284\n",
+      "        vf_explained_var: 0.9645282626152039\n",
+      "        vf_loss: 24.277286802019393\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.59705882352941\n",
-      "    gpu_util_percent0: 0.27\n",
+      "    cpu_util_percent: 23.694444444444443\n",
+      "    gpu_util_percent0: 0.37611111111111106\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15962256586295442\n",
-      "    mean_env_wait_ms: 1.6825632050368664\n",
-      "    mean_inference_ms: 4.862887505621167\n",
-      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
-      "  time_since_restore: 430.180118560791\n",
-      "  time_this_iter_s: 28.372846603393555\n",
-      "  time_total_s: 430.180118560791\n",
+      "    mean_action_processing_ms: 0.15669643186371113\n",
+      "    mean_env_wait_ms: 1.213879770455507\n",
+      "    mean_inference_ms: 4.880938505249473\n",
+      "    mean_raw_obs_processing_ms: 0.41758802125738176\n",
+      "  time_since_restore: 233.22773909568787\n",
+      "  time_this_iter_s: 15.31934118270874\n",
+      "  time_total_s: 233.22773909568787\n",
       "  timers:\n",
-      "    learn_throughput: 8029.244\n",
-      "    learn_time_ms: 20150.342\n",
-      "    sample_throughput: 19898.49\n",
-      "    sample_time_ms: 8130.868\n",
-      "    update_time_ms: 37.742\n",
-      "  timestamp: 1602166279\n",
+      "    learn_throughput: 6940.425\n",
+      "    learn_time_ms: 11655.771\n",
+      "    sample_throughput: 22087.15\n",
+      "    sample_time_ms: 3662.582\n",
+      "    update_time_ms: 29.445\n",
+      "  timestamp: 1602414680\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 1213440\n",
       "  training_iteration: 15\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     15 |          233.228 | 1213440 |  228.156 |              282.687 |              117.687 |            851.244 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-48\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3550.6575342465753\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-35\n",
       "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 850.6476793248945\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 228.66575033030716\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 54\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9501965812274388\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011891363986900874\n",
       "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        policy_loss: -0.03691769976701055\n",
+      "        total_loss: 6.539995942796979\n",
+      "        vf_explained_var: 0.9532654881477356\n",
+      "        vf_loss: 6.574630396706717\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.03030303030303\n",
-      "    gpu_util_percent0: 0.28878787878787876\n",
+      "    cpu_util_percent: 23.257894736842108\n",
+      "    gpu_util_percent0: 0.3689473684210527\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76060606060606\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.205263157894738\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15936424957771478\n",
-      "    mean_env_wait_ms: 1.6837075606485503\n",
-      "    mean_inference_ms: 4.8476482100837615\n",
-      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
-      "  time_since_restore: 458.61421608924866\n",
-      "  time_this_iter_s: 28.43409752845764\n",
-      "  time_total_s: 458.61421608924866\n",
+      "    mean_action_processing_ms: 0.15652106777015845\n",
+      "    mean_env_wait_ms: 1.2141530806568188\n",
+      "    mean_inference_ms: 4.869173612186312\n",
+      "    mean_raw_obs_processing_ms: 0.41700752465286606\n",
+      "  time_since_restore: 248.63334608078003\n",
+      "  time_this_iter_s: 15.405606985092163\n",
+      "  time_total_s: 248.63334608078003\n",
       "  timers:\n",
-      "    learn_throughput: 8025.775\n",
-      "    learn_time_ms: 20159.051\n",
-      "    sample_throughput: 19933.741\n",
-      "    sample_time_ms: 8116.489\n",
-      "    update_time_ms: 36.891\n",
-      "  timestamp: 1602166308\n",
+      "    learn_throughput: 6948.54\n",
+      "    learn_time_ms: 11642.158\n",
+      "    sample_throughput: 22107.419\n",
+      "    sample_time_ms: 3659.224\n",
+      "    update_time_ms: 27.808\n",
+      "  timestamp: 1602414695\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 1294336\n",
       "  training_iteration: 16\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     16 |          248.633 | 1294336 |  228.666 |              282.687 |              117.687 |            850.648 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-16\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3544.044012944984\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-51\n",
       "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 847.9379746835443\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 229.5562587904359\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8869837948254177\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010574847858931338\n",
       "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        policy_loss: -0.030033384316733906\n",
+      "        total_loss: 23.887325014386857\n",
+      "        vf_explained_var: 0.9734358191490173\n",
+      "        vf_loss: 23.9153322492327\n",
+      "    num_steps_sampled: 1375232\n",
+      "    num_steps_trained: 1375232\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.170588235294122\n",
-      "    gpu_util_percent0: 0.22911764705882354\n",
+      "    cpu_util_percent: 24.12777777777778\n",
+      "    gpu_util_percent0: 0.37111111111111117\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1589481712029165\n",
-      "    mean_env_wait_ms: 1.6856610626461734\n",
-      "    mean_inference_ms: 4.823647348850542\n",
-      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
-      "  time_since_restore: 486.7920489311218\n",
-      "  time_this_iter_s: 28.17783284187317\n",
-      "  time_total_s: 486.7920489311218\n",
+      "    mean_action_processing_ms: 0.15598861878496514\n",
+      "    mean_env_wait_ms: 1.2151207173575873\n",
+      "    mean_inference_ms: 4.836795072091276\n",
+      "    mean_raw_obs_processing_ms: 0.41531330512907777\n",
+      "  time_since_restore: 264.00063276290894\n",
+      "  time_this_iter_s: 15.367286682128906\n",
+      "  time_total_s: 264.00063276290894\n",
       "  timers:\n",
-      "    learn_throughput: 8025.414\n",
-      "    learn_time_ms: 20159.958\n",
-      "    sample_throughput: 20020.205\n",
-      "    sample_time_ms: 8081.436\n",
-      "    update_time_ms: 37.784\n",
-      "  timestamp: 1602166336\n",
+      "    learn_throughput: 6950.277\n",
+      "    learn_time_ms: 11639.249\n",
+      "    sample_throughput: 22092.804\n",
+      "    sample_time_ms: 3661.645\n",
+      "    update_time_ms: 26.446\n",
+      "  timestamp: 1602414711\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 1375232\n",
       "  training_iteration: 17\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     17 |          264.001 | 1375232 |  229.556 |              282.687 |              117.687 |            847.938 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-44\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3543.446233097231\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-06\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 847.7896725440806\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 229.63910515736697\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 8\n",
+      "  episodes_total: 1588\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8809702311243329\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013751132280698844\n",
       "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.04006186420364039\n",
+      "        total_loss: 8.013969761984688\n",
+      "        vf_explained_var: 0.9799981117248535\n",
+      "        vf_loss: 8.05136946269444\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.263636363636362\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 24.18888888888889\n",
+      "    gpu_util_percent0: 0.34388888888888886\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15875079551526766\n",
-      "    mean_env_wait_ms: 1.6865974079727117\n",
-      "    mean_inference_ms: 4.812393081904589\n",
-      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
-      "  time_since_restore: 515.002126455307\n",
-      "  time_this_iter_s: 28.21007752418518\n",
-      "  time_total_s: 515.002126455307\n",
+      "    mean_action_processing_ms: 0.15596295876330984\n",
+      "    mean_env_wait_ms: 1.2152144628972157\n",
+      "    mean_inference_ms: 4.835293774425444\n",
+      "    mean_raw_obs_processing_ms: 0.4152315100989919\n",
+      "  time_since_restore: 279.209707736969\n",
+      "  time_this_iter_s: 15.209074974060059\n",
+      "  time_total_s: 279.209707736969\n",
       "  timers:\n",
-      "    learn_throughput: 8034.771\n",
-      "    learn_time_ms: 20136.48\n",
-      "    sample_throughput: 19987.012\n",
-      "    sample_time_ms: 8094.857\n",
-      "    update_time_ms: 37.274\n",
-      "  timestamp: 1602166364\n",
+      "    learn_throughput: 6958.713\n",
+      "    learn_time_ms: 11625.139\n",
+      "    sample_throughput: 22105.921\n",
+      "    sample_time_ms: 3659.472\n",
+      "    update_time_ms: 24.606\n",
+      "  timestamp: 1602414726\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 1456128\n",
       "  training_iteration: 18\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     18 |           279.21 | 1456128 |  229.639 |              282.687 |              117.687 |             847.79 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-13\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3538.6934820904285\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-22\n",
       "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 846.4361334867664\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 230.19087886924467\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 150\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8852814521108355\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0099599530388202\n",
       "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.027756639091031893\n",
+      "        total_loss: 17.517151968819753\n",
+      "        vf_explained_var: 0.9784713387489319\n",
+      "        vf_loss: 17.543005534580775\n",
+      "    num_steps_sampled: 1537024\n",
+      "    num_steps_trained: 1537024\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.017647058823528\n",
-      "    gpu_util_percent0: 0.2832352941176471\n",
+      "    cpu_util_percent: 23.321052631578947\n",
+      "    gpu_util_percent0: 0.3547368421052632\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.189473684210527\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15856558726293105\n",
-      "    mean_env_wait_ms: 1.6874969155605837\n",
-      "    mean_inference_ms: 4.801814859500953\n",
-      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
-      "  time_since_restore: 543.3891928195953\n",
-      "  time_this_iter_s: 28.38706636428833\n",
-      "  time_total_s: 543.3891928195953\n",
+      "    mean_action_processing_ms: 0.15553169296870034\n",
+      "    mean_env_wait_ms: 1.2159003987180077\n",
+      "    mean_inference_ms: 4.808477786258893\n",
+      "    mean_raw_obs_processing_ms: 0.4138048648065393\n",
+      "  time_since_restore: 294.74597215652466\n",
+      "  time_this_iter_s: 15.536264419555664\n",
+      "  time_total_s: 294.74597215652466\n",
       "  timers:\n",
-      "    learn_throughput: 8037.512\n",
-      "    learn_time_ms: 20129.612\n",
-      "    sample_throughput: 19971.836\n",
-      "    sample_time_ms: 8101.008\n",
-      "    update_time_ms: 41.201\n",
-      "  timestamp: 1602166393\n",
+      "    learn_throughput: 6952.935\n",
+      "    learn_time_ms: 11634.798\n",
+      "    sample_throughput: 22040.273\n",
+      "    sample_time_ms: 3670.372\n",
+      "    update_time_ms: 25.99\n",
+      "  timestamp: 1602414742\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 1537024\n",
       "  training_iteration: 19\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     19 |          294.746 | 1537024 |  230.191 |              282.687 |              117.687 |            846.436 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-42\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3532.3775620280476\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-37\n",
       "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 844.0365272631021\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 231.15752014587363\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 151\n",
+      "  episodes_total: 1889\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8439452222415379\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01139848040682929\n",
       "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        policy_loss: -0.03071598948112556\n",
+      "        total_loss: 18.11450685773577\n",
+      "        vf_explained_var: 0.9758296608924866\n",
+      "        vf_loss: 18.143027441842214\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.500000000000007\n",
-      "    gpu_util_percent0: 0.2582352941176471\n",
+      "    cpu_util_percent: 23.226315789473684\n",
+      "    gpu_util_percent0: 0.3752631578947369\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15824728170515573\n",
-      "    mean_env_wait_ms: 1.689080359464987\n",
-      "    mean_inference_ms: 4.783977737237845\n",
-      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
-      "  time_since_restore: 572.0331726074219\n",
-      "  time_this_iter_s: 28.643979787826538\n",
-      "  time_total_s: 572.0331726074219\n",
+      "    mean_action_processing_ms: 0.1551511801015778\n",
+      "    mean_env_wait_ms: 1.2166455419470106\n",
+      "    mean_inference_ms: 4.784982314134217\n",
+      "    mean_raw_obs_processing_ms: 0.4125990287185259\n",
+      "  time_since_restore: 310.2400779724121\n",
+      "  time_this_iter_s: 15.494105815887451\n",
+      "  time_total_s: 310.2400779724121\n",
       "  timers:\n",
-      "    learn_throughput: 8035.517\n",
-      "    learn_time_ms: 20134.61\n",
-      "    sample_throughput: 19976.949\n",
-      "    sample_time_ms: 8098.935\n",
-      "    update_time_ms: 46.558\n",
-      "  timestamp: 1602166422\n",
+      "    learn_throughput: 6943.523\n",
+      "    learn_time_ms: 11650.57\n",
+      "    sample_throughput: 22063.796\n",
+      "    sample_time_ms: 3666.459\n",
+      "    update_time_ms: 28.532\n",
+      "  timestamp: 1602414757\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 1617920\n",
       "  training_iteration: 20\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     20 |           310.24 | 1617920 |  231.158 |              282.687 |              117.687 |            844.037 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-14-10\n",
-      "  done: true\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3531.802256851155\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.964135021097\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 231.25578570515262\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 7\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.849527929510389\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012149149152849401\n",
       "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
+      "        policy_loss: -0.0404457508453301\n",
+      "        total_loss: 5.171197891235352\n",
+      "        vf_explained_var: 0.9693788886070251\n",
+      "        vf_loss: 5.209298746926444\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
       "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.76060606060606\n",
-      "    gpu_util_percent0: 0.25030303030303036\n",
+      "    cpu_util_percent: 24.477777777777774\n",
+      "    gpu_util_percent0: 0.3211111111111111\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15806698356889384\n",
-      "    mean_env_wait_ms: 1.6900183481280247\n",
-      "    mean_inference_ms: 4.773945395364269\n",
-      "    mean_raw_obs_processing_ms: 0.42436064467246504\n",
-      "  time_since_restore: 600.5207903385162\n",
-      "  time_this_iter_s: 28.48761773109436\n",
-      "  time_total_s: 600.5207903385162\n",
+      "    mean_action_processing_ms: 0.15513663481693202\n",
+      "    mean_env_wait_ms: 1.2166701954384804\n",
+      "    mean_inference_ms: 4.784032923931228\n",
+      "    mean_raw_obs_processing_ms: 0.412545884382204\n",
+      "  time_since_restore: 325.52921962738037\n",
+      "  time_this_iter_s: 15.289141654968262\n",
+      "  time_total_s: 325.52921962738037\n",
       "  timers:\n",
-      "    learn_throughput: 8034.641\n",
-      "    learn_time_ms: 20136.804\n",
-      "    sample_throughput: 19881.19\n",
-      "    sample_time_ms: 8137.943\n",
-      "    update_time_ms: 46.415\n",
-      "  timestamp: 1602166450\n",
+      "    learn_throughput: 6945.797\n",
+      "    learn_time_ms: 11646.755\n",
+      "    sample_throughput: 22099.962\n",
+      "    sample_time_ms: 3660.459\n",
+      "    update_time_ms: 28.36\n",
+      "  timestamp: 1602414773\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
+      "  timesteps_total: 1698816\n",
       "  training_iteration: 21\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57594\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3176.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 614\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602166450\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 282.48485\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 227.63033\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "2020-10-08 14:14:19,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 5nvugt1y\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 14:14:19,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_141421-fpfrymi0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:14:23,731\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:14:24,486 - wandb.wandb_agent - INFO - Running runs: ['fpfrymi0']\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     21 |          325.529 | 1698816 |  231.256 |              282.687 |              117.687 |            843.964 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=756)\u001b[0m 2020-10-08 14:14:26,675\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-14-58\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3524.741456166419\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-13-08\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 37.735483870967734\n",
-      "    gpu_util_percent0: 0.051935483870967754\n",
-      "    gpu_util_percent1: 0.0003225806451612903\n",
-      "    gpu_util_percent2: 0.0003225806451612903\n",
-      "    ram_util_percent: 9.529032258064516\n",
-      "    vram_util_percent0: 0.25613104243591234\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17423707785964127\n",
-      "    mean_env_wait_ms: 1.645963223637825\n",
-      "    mean_inference_ms: 5.692081848902995\n",
-      "    mean_raw_obs_processing_ms: 0.4677243687628816\n",
-      "  time_since_restore: 26.03303360939026\n",
-      "  time_this_iter_s: 26.03303360939026\n",
-      "  time_total_s: 26.03303360939026\n",
-      "  timers:\n",
-      "    learn_throughput: 9842.911\n",
-      "    learn_time_ms: 16437.413\n",
-      "    sample_throughput: 17001.439\n",
-      "    sample_time_ms: 9516.371\n",
-      "    update_time_ms: 39.605\n",
-      "  timestamp: 1602166498\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      1 |           26.033 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-23\n",
-      "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.220689655172414\n",
-      "    gpu_util_percent0: 0.019655172413793106\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74137931034483\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17038163777984144\n",
-      "    mean_env_wait_ms: 1.6424572254451888\n",
-      "    mean_inference_ms: 5.447572680731352\n",
-      "    mean_raw_obs_processing_ms: 0.4584056950467155\n",
-      "  time_since_restore: 50.949177742004395\n",
-      "  time_this_iter_s: 24.916144132614136\n",
-      "  time_total_s: 50.949177742004395\n",
-      "  timers:\n",
-      "    learn_throughput: 9861.266\n",
-      "    learn_time_ms: 16406.818\n",
-      "    sample_throughput: 18024.658\n",
-      "    sample_time_ms: 8976.148\n",
-      "    update_time_ms: 38.131\n",
-      "  timestamp: 1602166523\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      2 |          50.9492 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-48\n",
-      "  done: false\n",
-      "  episode_len_mean: 867.8713080168776\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 228.246196138601\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1271256804466248\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007389193354174495\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018508310522884132\n",
-      "        total_loss: 6.457739639282226\n",
-      "        vf_explained_var: 0.9464155435562134\n",
-      "        vf_loss: 6.4747700691223145\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.61379310344827\n",
-      "    gpu_util_percent0: 0.21344827586206902\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16769761323536675\n",
-      "    mean_env_wait_ms: 1.6416986329657957\n",
-      "    mean_inference_ms: 5.306852272749373\n",
-      "    mean_raw_obs_processing_ms: 0.4500760030355006\n",
-      "  time_since_restore: 75.78218650817871\n",
-      "  time_this_iter_s: 24.833008766174316\n",
-      "  time_total_s: 75.78218650817871\n",
-      "  timers:\n",
-      "    learn_throughput: 9901.992\n",
-      "    learn_time_ms: 16339.339\n",
-      "    sample_throughput: 18316.884\n",
-      "    sample_time_ms: 8832.943\n",
-      "    update_time_ms: 36.895\n",
-      "  timestamp: 1602166548\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      3 |          75.7822 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3230.0\n",
-      "  date: 2020-10-08_14-16-13\n",
-      "  done: false\n",
-      "  episode_len_mean: 862.3544303797469\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 230.3964326812426\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0996861219406129\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008276985818520188\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020328705292195083\n",
-      "        total_loss: 5.005046558380127\n",
-      "        vf_explained_var: 0.9697187542915344\n",
-      "        vf_loss: 5.023719763755798\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.723333333333336\n",
-      "    gpu_util_percent0: 0.4343333333333333\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1657578301907817\n",
-      "    mean_env_wait_ms: 1.6430517247856948\n",
-      "    mean_inference_ms: 5.2018997182402025\n",
-      "    mean_raw_obs_processing_ms: 0.44406851617825566\n",
-      "  time_since_restore: 100.74394655227661\n",
-      "  time_this_iter_s: 24.9617600440979\n",
-      "  time_total_s: 100.74394655227661\n",
-      "  timers:\n",
-      "    learn_throughput: 9911.992\n",
-      "    learn_time_ms: 16322.854\n",
-      "    sample_throughput: 18445.327\n",
-      "    sample_time_ms: 8771.436\n",
-      "    update_time_ms: 36.541\n",
-      "  timestamp: 1602166573\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      4 |          100.744 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-16-38\n",
-      "  done: false\n",
-      "  episode_len_mean: 852.6247216035634\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.18069334773102\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 266\n",
-      "  episodes_total: 898\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0624429881572723\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0077964670956134794\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02084309732308611\n",
-      "        total_loss: 7.683893799781799\n",
-      "        vf_explained_var: 0.9791978597640991\n",
-      "        vf_loss: 7.703177666664123\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.225\n",
-      "    gpu_util_percent0: 0.25178571428571433\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16364555568838862\n",
-      "    mean_env_wait_ms: 1.649353801806338\n",
-      "    mean_inference_ms: 5.083644859595276\n",
-      "    mean_raw_obs_processing_ms: 0.4376329609722663\n",
-      "  time_since_restore: 125.15412139892578\n",
-      "  time_this_iter_s: 24.41017484664917\n",
-      "  time_total_s: 125.15412139892578\n",
-      "  timers:\n",
-      "    learn_throughput: 9921.993\n",
-      "    learn_time_ms: 16306.401\n",
-      "    sample_throughput: 18736.645\n",
-      "    sample_time_ms: 8635.057\n",
-      "    update_time_ms: 35.191\n",
-      "  timestamp: 1602166598\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      5 |          125.154 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-17-02\n",
-      "  done: false\n",
-      "  episode_len_mean: 846.0479204339964\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.96029919447625\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 208\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0738083600997925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007217544643208384\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02225890466943383\n",
-      "        total_loss: 4.545075726509094\n",
-      "        vf_explained_var: 0.9842392206192017\n",
-      "        vf_loss: 4.565891194343567\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.55517241379311\n",
-      "    gpu_util_percent0: 0.4293103448275861\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16251990142651115\n",
-      "    mean_env_wait_ms: 1.6530343779974206\n",
-      "    mean_inference_ms: 5.018380813854082\n",
-      "    mean_raw_obs_processing_ms: 0.43409996967266995\n",
-      "  time_since_restore: 149.7096438407898\n",
-      "  time_this_iter_s: 24.555522441864014\n",
-      "  time_total_s: 149.7096438407898\n",
-      "  timers:\n",
-      "    learn_throughput: 9912.286\n",
-      "    learn_time_ms: 16322.371\n",
-      "    sample_throughput: 18942.241\n",
-      "    sample_time_ms: 8541.334\n",
-      "    update_time_ms: 33.368\n",
-      "  timestamp: 1602166622\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      6 |           149.71 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.3995253164557\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 232.7926815624599\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0473353922367097\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006994991353712976\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022564191045239566\n",
-      "        total_loss: 4.000831997394561\n",
-      "        vf_explained_var: 0.9874190092086792\n",
-      "        vf_loss: 4.021997082233429\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.59655172413793\n",
-      "    gpu_util_percent0: 0.4562068965517241\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655174\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16183355318977655\n",
-      "    mean_env_wait_ms: 1.656038102133309\n",
-      "    mean_inference_ms: 4.9782716342931606\n",
-      "    mean_raw_obs_processing_ms: 0.4319914234530791\n",
-      "  time_since_restore: 174.1368727684021\n",
-      "  time_this_iter_s: 24.427228927612305\n",
-      "  time_total_s: 174.1368727684021\n",
-      "  timers:\n",
-      "    learn_throughput: 9918.301\n",
-      "    learn_time_ms: 16312.471\n",
-      "    sample_throughput: 19088.76\n",
-      "    sample_time_ms: 8475.773\n",
-      "    update_time_ms: 33.238\n",
-      "  timestamp: 1602166647\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      7 |          174.137 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.3713080168776\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 233.61432184006011\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.01868434548378\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007189809367991984\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023347471375018358\n",
-      "        total_loss: 3.781139385700226\n",
-      "        vf_explained_var: 0.9891014099121094\n",
-      "        vf_loss: 3.803048861026764\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.625\n",
-      "    gpu_util_percent0: 0.04107142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.771428571428572\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125876245924115\n",
-      "    mean_env_wait_ms: 1.6590341255429097\n",
-      "    mean_inference_ms: 4.943515953135972\n",
-      "    mean_raw_obs_processing_ms: 0.430128591449942\n",
-      "  time_since_restore: 198.50214219093323\n",
-      "  time_this_iter_s: 24.365269422531128\n",
-      "  time_total_s: 198.50214219093323\n",
-      "  timers:\n",
-      "    learn_throughput: 9923.421\n",
-      "    learn_time_ms: 16304.054\n",
-      "    sample_throughput: 19218.701\n",
-      "    sample_time_ms: 8418.467\n",
-      "    update_time_ms: 34.044\n",
-      "  timestamp: 1602166671\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      8 |          198.502 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-15\n",
-      "  done: false\n",
-      "  episode_len_mean: 829.8141542002302\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.34277179156337\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9904811769723892\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006311689200811088\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020997717510908842\n",
-      "        total_loss: 5.1504497051239015\n",
-      "        vf_explained_var: 0.9909344911575317\n",
-      "        vf_loss: 5.170185089111328\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.30821428571428566\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.160369309924211\n",
-      "    mean_env_wait_ms: 1.6650071130850876\n",
-      "    mean_inference_ms: 4.888377085687167\n",
-      "    mean_raw_obs_processing_ms: 0.42729617584826485\n",
-      "  time_since_restore: 222.59675359725952\n",
-      "  time_this_iter_s: 24.094611406326294\n",
-      "  time_total_s: 222.59675359725952\n",
-      "  timers:\n",
-      "    learn_throughput: 9938.553\n",
-      "    learn_time_ms: 16279.231\n",
-      "    sample_throughput: 19342.706\n",
-      "    sample_time_ms: 8364.497\n",
-      "    update_time_ms: 33.218\n",
-      "  timestamp: 1602166695\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      9 |          222.597 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-40\n",
-      "  done: false\n",
-      "  episode_len_mean: 826.4541139240506\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.7108905510803\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9730047971010208\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006372990598902106\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022790615819394587\n",
-      "        total_loss: 3.343014180660248\n",
-      "        vf_explained_var: 0.9915106892585754\n",
-      "        vf_loss: 3.3645302057266235\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.324137931034485\n",
-      "    gpu_util_percent0: 0.2775862068965517\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16000657164975352\n",
-      "    mean_env_wait_ms: 1.6678046661692965\n",
-      "    mean_inference_ms: 4.86599024622493\n",
-      "    mean_raw_obs_processing_ms: 0.42614775920547227\n",
-      "  time_since_restore: 246.9238064289093\n",
-      "  time_this_iter_s: 24.32705283164978\n",
-      "  time_total_s: 246.9238064289093\n",
-      "  timers:\n",
-      "    learn_throughput: 9939.106\n",
-      "    learn_time_ms: 16278.326\n",
-      "    sample_throughput: 19435.411\n",
-      "    sample_time_ms: 8324.599\n",
-      "    update_time_ms: 33.566\n",
-      "  timestamp: 1602166720\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     10 |          246.924 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-04\n",
-      "  done: false\n",
-      "  episode_len_mean: 823.6002921129503\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 236.65748035368276\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9577732890844345\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006211055861786008\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022765795403392984\n",
-      "        total_loss: 3.0192813992500307\n",
-      "        vf_explained_var: 0.9923363924026489\n",
-      "        vf_loss: 3.0408049702644346\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.706896551724135\n",
-      "    gpu_util_percent0: 0.43068965517241387\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1596848966715417\n",
-      "    mean_env_wait_ms: 1.6704675074629387\n",
-      "    mean_inference_ms: 4.845793508809106\n",
-      "    mean_raw_obs_processing_ms: 0.42510446710641553\n",
-      "  time_since_restore: 271.42553091049194\n",
-      "  time_this_iter_s: 24.50172448158264\n",
-      "  time_total_s: 271.42553091049194\n",
-      "  timers:\n",
-      "    learn_throughput: 9946.653\n",
-      "    learn_time_ms: 16265.974\n",
-      "    sample_throughput: 19772.529\n",
-      "    sample_time_ms: 8182.666\n",
-      "    update_time_ms: 32.542\n",
-      "  timestamp: 1602166744\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     11 |          271.426 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.2957437472576\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 237.36838769440774\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 225\n",
-      "  episodes_total: 2279\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9244333893060684\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006004941323772073\n",
-      "        model: {}\n",
-      "        policy_loss: -0.021168453525751828\n",
-      "        total_loss: 4.074023377895355\n",
-      "        vf_explained_var: 0.9932994842529297\n",
-      "        vf_loss: 4.093990921974182\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.251724137931035\n",
-      "    gpu_util_percent0: 0.39206896551724135\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744827586206897\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1592619934185692\n",
-      "    mean_env_wait_ms: 1.6739541868498113\n",
-      "    mean_inference_ms: 4.819806265535011\n",
-      "    mean_raw_obs_processing_ms: 0.42372078258183\n",
-      "  time_since_restore: 296.40609192848206\n",
-      "  time_this_iter_s: 24.980561017990112\n",
-      "  time_total_s: 296.40609192848206\n",
-      "  timers:\n",
-      "    learn_throughput: 9957.289\n",
-      "    learn_time_ms: 16248.6\n",
-      "    sample_throughput: 19727.515\n",
-      "    sample_time_ms: 8201.337\n",
-      "    update_time_ms: 32.973\n",
-      "  timestamp: 1602166769\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     12 |          296.406 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 817.5490506329114\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.05452068149842\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 249\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9116032361984253\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0059999656863510605\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020421561488183214\n",
-      "        total_loss: 3.2677656054496764\n",
-      "        vf_explained_var: 0.9931272268295288\n",
-      "        vf_loss: 3.2869871616363526\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.02857142857143\n",
-      "    gpu_util_percent0: 0.06035714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.764285714285716\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15888263499780286\n",
-      "    mean_env_wait_ms: 1.677646536061787\n",
-      "    mean_inference_ms: 4.796171409815506\n",
-      "    mean_raw_obs_processing_ms: 0.42253131691795703\n",
-      "  time_since_restore: 320.67564845085144\n",
-      "  time_this_iter_s: 24.269556522369385\n",
-      "  time_total_s: 320.67564845085144\n",
-      "  timers:\n",
-      "    learn_throughput: 9954.003\n",
-      "    learn_time_ms: 16253.963\n",
-      "    sample_throughput: 19876.989\n",
-      "    sample_time_ms: 8139.664\n",
-      "    update_time_ms: 31.685\n",
-      "  timestamp: 1602166794\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     13 |          320.676 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 816.2442293373045\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.46138225140444\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9013321816921234\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006421135948039591\n",
-      "        model: {}\n",
-      "        policy_loss: -0.021805241936817765\n",
-      "        total_loss: 2.9366058349609374\n",
-      "        vf_explained_var: 0.9931826591491699\n",
-      "        vf_loss: 2.9571268558502197\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.642857142857146\n",
-      "    gpu_util_percent0: 0.30678571428571433\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15866013164662812\n",
-      "    mean_env_wait_ms: 1.6796736234314602\n",
-      "    mean_inference_ms: 4.782626736230756\n",
-      "    mean_raw_obs_processing_ms: 0.42183995211689523\n",
-      "  time_since_restore: 344.8741044998169\n",
-      "  time_this_iter_s: 24.198456048965454\n",
-      "  time_total_s: 344.8741044998169\n",
-      "  timers:\n",
-      "    learn_throughput: 9964.721\n",
-      "    learn_time_ms: 16236.481\n",
-      "    sample_throughput: 20015.961\n",
-      "    sample_time_ms: 8083.149\n",
-      "    update_time_ms: 29.819\n",
-      "  timestamp: 1602166818\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     14 |          344.874 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-43\n",
-      "  done: false\n",
-      "  episode_len_mean: 814.502106741573\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.95662736919752\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 162\n",
-      "  episodes_total: 2848\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8737345904111862\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005880716699175536\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023541058914270253\n",
-      "        total_loss: 2.77874299287796\n",
-      "        vf_explained_var: 0.9943079948425293\n",
-      "        vf_loss: 2.801107919216156\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.53793103448275\n",
-      "    gpu_util_percent0: 0.09275862068965515\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77241379310345\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15844943627409838\n",
-      "    mean_env_wait_ms: 1.6816497328437465\n",
-      "    mean_inference_ms: 4.769681731783559\n",
-      "    mean_raw_obs_processing_ms: 0.42115262835775236\n",
-      "  time_since_restore: 369.2295935153961\n",
-      "  time_this_iter_s: 24.355489015579224\n",
-      "  time_total_s: 369.2295935153961\n",
-      "  timers:\n",
-      "    learn_throughput: 9970.424\n",
-      "    learn_time_ms: 16227.193\n",
-      "    sample_throughput: 20006.648\n",
-      "    sample_time_ms: 8086.912\n",
-      "    update_time_ms: 28.747\n",
-      "  timestamp: 1602166843\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     15 |           369.23 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-07\n",
-      "  done: false\n",
-      "  episode_len_mean: 811.5661392405063\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.56847270170044\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 312\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.836417630314827\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005600748467259109\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019153478858061134\n",
-      "        total_loss: 3.4916038155555724\n",
-      "        vf_explained_var: 0.9944165349006653\n",
-      "        vf_loss: 3.5096370816230773\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.9551724137931\n",
-      "    gpu_util_percent0: 0.43275862068965526\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15809978406417496\n",
-      "    mean_env_wait_ms: 1.6853761096348427\n",
-      "    mean_inference_ms: 4.748027409045223\n",
-      "    mean_raw_obs_processing_ms: 0.42003623239671906\n",
-      "  time_since_restore: 393.7941789627075\n",
-      "  time_this_iter_s: 24.5645854473114\n",
-      "  time_total_s: 393.7941789627075\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.021\n",
-      "    learn_time_ms: 16216.464\n",
-      "    sample_throughput: 19987.267\n",
-      "    sample_time_ms: 8094.753\n",
-      "    update_time_ms: 30.454\n",
-      "  timestamp: 1602166867\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     16 |          393.794 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-32\n",
-      "  done: false\n",
-      "  episode_len_mean: 810.3282097649186\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.7355501975754\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8335719257593155\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006123062083497643\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020987965818494558\n",
-      "        total_loss: 2.507720983028412\n",
-      "        vf_explained_var: 0.9944343566894531\n",
-      "        vf_loss: 2.5274842858314512\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.18275862068966\n",
-      "    gpu_util_percent0: 0.27655172413793105\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655173\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15794348066077543\n",
-      "    mean_env_wait_ms: 1.687080352601384\n",
-      "    mean_inference_ms: 4.7382363513709365\n",
-      "    mean_raw_obs_processing_ms: 0.41954097731825146\n",
-      "  time_since_restore: 418.4777216911316\n",
-      "  time_this_iter_s: 24.683542728424072\n",
-      "  time_total_s: 418.4777216911316\n",
-      "  timers:\n",
-      "    learn_throughput: 9984.096\n",
-      "    learn_time_ms: 16204.972\n",
-      "    sample_throughput: 19915.659\n",
-      "    sample_time_ms: 8123.859\n",
-      "    update_time_ms: 31.876\n",
-      "  timestamp: 1602166892\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     17 |          418.478 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 809.0097813578826\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.89810649649536\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.830751609802246\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005981297581456602\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023448871518485247\n",
-      "        total_loss: 2.440117084980011\n",
-      "        vf_explained_var: 0.994672954082489\n",
-      "        vf_loss: 2.462369680404663\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.04142857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.792857142857144\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15779369461228313\n",
-      "    mean_env_wait_ms: 1.6887300269221321\n",
-      "    mean_inference_ms: 4.729069241301459\n",
-      "    mean_raw_obs_processing_ms: 0.419066132995007\n",
-      "  time_since_restore: 442.8714327812195\n",
-      "  time_this_iter_s: 24.39371109008789\n",
-      "  time_total_s: 442.8714327812195\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.82\n",
-      "    learn_time_ms: 16215.165\n",
-      "    sample_throughput: 19931.133\n",
-      "    sample_time_ms: 8117.551\n",
-      "    update_time_ms: 31.094\n",
-      "  timestamp: 1602166917\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     18 |          442.871 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 806.8230485232068\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.2267639474917\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7929262965917587\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005467748525552452\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018968340079300105\n",
-      "        total_loss: 3.431827688217163\n",
-      "        vf_explained_var: 0.9950782060623169\n",
-      "        vf_loss: 3.4497024059295653\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.27379310344827584\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15751807790452294\n",
-      "    mean_env_wait_ms: 1.6918670821992567\n",
-      "    mean_inference_ms: 4.71261405039136\n",
-      "    mean_raw_obs_processing_ms: 0.41822277427376653\n",
-      "  time_since_restore: 467.25490164756775\n",
-      "  time_this_iter_s: 24.383468866348267\n",
-      "  time_total_s: 467.25490164756775\n",
-      "  timers:\n",
-      "    learn_throughput: 9975.719\n",
-      "    learn_time_ms: 16218.58\n",
-      "    sample_throughput: 19874.518\n",
-      "    sample_time_ms: 8140.676\n",
-      "    update_time_ms: 32.327\n",
-      "  timestamp: 1602166941\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     19 |          467.255 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-46\n",
-      "  done: false\n",
-      "  episode_len_mean: 805.7225316455696\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.49984400971735\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3950\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7794228792190552\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005526655982248485\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023039081250317395\n",
-      "        total_loss: 2.078591358661652\n",
-      "        vf_explained_var: 0.9953739047050476\n",
-      "        vf_loss: 2.1005250751972198\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.92068965517242\n",
-      "    gpu_util_percent0: 0.4165517241379311\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1573904574836841\n",
-      "    mean_env_wait_ms: 1.6933221569620878\n",
-      "    mean_inference_ms: 4.705165325354333\n",
-      "    mean_raw_obs_processing_ms: 0.4178457110788417\n",
-      "  time_since_restore: 491.8251175880432\n",
-      "  time_this_iter_s: 24.570215940475464\n",
-      "  time_total_s: 491.8251175880432\n",
-      "  timers:\n",
-      "    learn_throughput: 9972.19\n",
-      "    learn_time_ms: 16224.319\n",
-      "    sample_throughput: 19829.965\n",
-      "    sample_time_ms: 8158.965\n",
-      "    update_time_ms: 31.231\n",
-      "  timestamp: 1602166966\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     20 |          491.825 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 804.7280915287245\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.70876486382807\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7865538984537125\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005757506913505494\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02310952057596296\n",
-      "        total_loss: 1.973700213432312\n",
-      "        vf_explained_var: 0.9953605532646179\n",
-      "        vf_loss: 1.9956582367420197\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.4148275862068965\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15726970308067142\n",
-      "    mean_env_wait_ms: 1.6947178273814376\n",
-      "    mean_inference_ms: 4.698130026253491\n",
-      "    mean_raw_obs_processing_ms: 0.4174790686263623\n",
-      "  time_since_restore: 516.4608044624329\n",
-      "  time_this_iter_s: 24.63568687438965\n",
-      "  time_total_s: 516.4608044624329\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.798\n",
-      "    learn_time_ms: 16215.201\n",
-      "    sample_throughput: 19793.078\n",
-      "    sample_time_ms: 8174.171\n",
-      "    update_time_ms: 32.464\n",
-      "  timestamp: 1602166991\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     21 |          516.461 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-36\n",
-      "  done: false\n",
-      "  episode_len_mean: 803.1457812144644\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.09711855879692\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4397\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.755255714058876\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005404739850200712\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019464567000977696\n",
-      "        total_loss: 3.0453175783157347\n",
-      "        vf_explained_var: 0.9953736066818237\n",
-      "        vf_loss: 3.0637012124061584\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.010344827586216\n",
-      "    gpu_util_percent0: 0.25551724137931037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15706065795015647\n",
-      "    mean_env_wait_ms: 1.6971458462496418\n",
-      "    mean_inference_ms: 4.686353824274288\n",
-      "    mean_raw_obs_processing_ms: 0.41688654879158077\n",
-      "  time_since_restore: 541.0245015621185\n",
-      "  time_this_iter_s: 24.56369709968567\n",
-      "  time_total_s: 541.0245015621185\n",
-      "  timers:\n",
-      "    learn_throughput: 9974.186\n",
-      "    learn_time_ms: 16221.074\n",
-      "    sample_throughput: 19914.903\n",
-      "    sample_time_ms: 8124.167\n",
-      "    update_time_ms: 32.124\n",
-      "  timestamp: 1602167016\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     22 |          541.025 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-00\n",
-      "  done: false\n",
-      "  episode_len_mean: 802.2247926669577\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.27666671075653\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7225345104932785\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005478021572344005\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022186438925564288\n",
-      "        total_loss: 1.9642526030540466\n",
-      "        vf_explained_var: 0.9957612752914429\n",
-      "        vf_loss: 1.9853434622287751\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.33793103448276\n",
-      "    gpu_util_percent0: 0.43206896551724133\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569378381550041\n",
-      "    mean_env_wait_ms: 1.698596232047108\n",
-      "    mean_inference_ms: 4.679417530334113\n",
-      "    mean_raw_obs_processing_ms: 0.4165376750547412\n",
-      "  time_since_restore: 565.687112569809\n",
-      "  time_this_iter_s: 24.66261100769043\n",
-      "  time_total_s: 565.687112569809\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.382\n",
-      "    learn_time_ms: 16230.518\n",
-      "    sample_throughput: 19860.374\n",
-      "    sample_time_ms: 8146.473\n",
-      "    update_time_ms: 32.606\n",
-      "  timestamp: 1602167040\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     23 |          565.687 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 801.512447257384\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.5184460640156\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7451686680316925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005771003756672144\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024150656536221504\n",
-      "        total_loss: 1.7480961799621582\n",
-      "        vf_explained_var: 0.9958817362785339\n",
-      "        vf_loss: 1.7710926413536072\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.81071428571429\n",
-      "    gpu_util_percent0: 0.16499999999999998\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.782142857142857\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15683784552145583\n",
-      "    mean_env_wait_ms: 1.6997744080868349\n",
-      "    mean_inference_ms: 4.673850092393118\n",
-      "    mean_raw_obs_processing_ms: 0.4162613145590402\n",
-      "  time_since_restore: 590.1530044078827\n",
-      "  time_this_iter_s: 24.46589183807373\n",
-      "  time_total_s: 590.1530044078827\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.406\n",
-      "    learn_time_ms: 16230.478\n",
-      "    sample_throughput: 19802.656\n",
-      "    sample_time_ms: 8170.217\n",
-      "    update_time_ms: 35.007\n",
-      "  timestamp: 1602167065\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     24 |          590.153 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-50\n",
-      "  done: true\n",
-      "  episode_len_mean: 800.4764492753624\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.8013874656386\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 228\n",
-      "  episodes_total: 4968\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7212436735630036\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00533560358453542\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020342798670753837\n",
-      "        total_loss: 2.63335440158844\n",
-      "        vf_explained_var: 0.9957489967346191\n",
-      "        vf_loss: 2.65263010263443\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.09666666666667\n",
-      "    gpu_util_percent0: 0.22766666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746666666666668\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15670386391308977\n",
-      "    mean_env_wait_ms: 1.7014434824573494\n",
-      "    mean_inference_ms: 4.66638510128689\n",
-      "    mean_raw_obs_processing_ms: 0.41590574797057145\n",
-      "  time_since_restore: 614.7696187496185\n",
-      "  time_this_iter_s: 24.61661434173584\n",
-      "  time_total_s: 614.7696187496185\n",
-      "  timers:\n",
-      "    learn_throughput: 9960.015\n",
-      "    learn_time_ms: 16244.153\n",
-      "    sample_throughput: 19778.628\n",
-      "    sample_time_ms: 8180.143\n",
-      "    update_time_ms: 36.793\n",
-      "  timestamp: 1602167090\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 502\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3125.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167090\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.24242\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 235.34277\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1738\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "2020-10-08 14:25:03,027 - wandb.wandb_agent - INFO - Cleaning up finished run: fpfrymi0\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 16384\n",
-      "2020-10-08 14:25:03,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_142505-w8c2p6ff\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:25:07,555\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:25:08,410 - wandb.wandb_agent - INFO - Running runs: ['w8c2p6ff']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=33202)\u001b[0m 2020-10-08 14:25:10,570\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-25-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1623204231262207\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048057976178824905\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00972368239890784\n",
-      "        total_loss: 8.319466400146485\n",
-      "        vf_explained_var: 0.7498777508735657\n",
-      "        vf_loss: 8.328228569030761\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 37.63333333333333\n",
-      "    gpu_util_percent0: 0.26266666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003333333333333333\n",
-      "    ram_util_percent: 9.49\n",
-      "    vram_util_percent0: 0.2729856783644911\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17678140968259154\n",
-      "    mean_env_wait_ms: 1.6502532711659141\n",
-      "    mean_inference_ms: 5.870735121936333\n",
-      "    mean_raw_obs_processing_ms: 0.4788182656976241\n",
-      "  time_since_restore: 25.622228860855103\n",
-      "  time_this_iter_s: 25.622228860855103\n",
-      "  time_total_s: 25.622228860855103\n",
-      "  timers:\n",
-      "    learn_throughput: 10340.312\n",
-      "    learn_time_ms: 15646.724\n",
-      "    sample_throughput: 16338.488\n",
-      "    sample_time_ms: 9902.507\n",
-      "    update_time_ms: 42.975\n",
-      "  timestamp: 1602167142\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-06\n",
-      "  done: false\n",
-      "  episode_len_mean: 870.7974683544304\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.3724267996418\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.138706338405609\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006825200421735645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01274334719637409\n",
-      "        total_loss: 7.690042400360108\n",
-      "        vf_explained_var: 0.8869457244873047\n",
-      "        vf_loss: 7.702103328704834\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.425925925925924\n",
-      "    gpu_util_percent0: 0.3437037037037037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.73703703703704\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17196632938280343\n",
-      "    mean_env_wait_ms: 1.646491991621751\n",
-      "    mean_inference_ms: 5.588687582318563\n",
-      "    mean_raw_obs_processing_ms: 0.467505042931231\n",
-      "  time_since_restore: 49.39094591140747\n",
-      "  time_this_iter_s: 23.768717050552368\n",
-      "  time_total_s: 49.39094591140747\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.268\n",
-      "    learn_time_ms: 15479.129\n",
-      "    sample_throughput: 17702.943\n",
-      "    sample_time_ms: 9139.271\n",
-      "    update_time_ms: 38.137\n",
-      "  timestamp: 1602167166\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-30\n",
-      "  done: false\n",
-      "  episode_len_mean: 866.331223628692\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.87126539658163\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1217446804046631\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007683717552572489\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014337884564884006\n",
-      "        total_loss: 8.763248443603516\n",
-      "        vf_explained_var: 0.9284197092056274\n",
-      "        vf_loss: 8.77681770324707\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.08620689655172\n",
-      "    gpu_util_percent0: 0.3172413793103448\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16894469760208242\n",
-      "    mean_env_wait_ms: 1.6450424063300917\n",
-      "    mean_inference_ms: 5.427040881695507\n",
-      "    mean_raw_obs_processing_ms: 0.45877313240781425\n",
-      "  time_since_restore: 73.57178139686584\n",
-      "  time_this_iter_s: 24.180835485458374\n",
-      "  time_total_s: 73.57178139686584\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.901\n",
-      "    learn_time_ms: 15478.191\n",
-      "    sample_throughput: 18089.282\n",
-      "    sample_time_ms: 8944.081\n",
-      "    update_time_ms: 56.055\n",
-      "  timestamp: 1602167190\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 861.253164556962\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 227.7450294080039\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0939712405204773\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009209706541150808\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015771377924829723\n",
-      "        total_loss: 8.429035234451295\n",
-      "        vf_explained_var: 0.9521434903144836\n",
-      "        vf_loss: 8.443885612487794\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.03333333333334\n",
-      "    gpu_util_percent0: 0.2777777777777778\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16676384022481172\n",
-      "    mean_env_wait_ms: 1.6466515242102222\n",
-      "    mean_inference_ms: 5.307577815654116\n",
-      "    mean_raw_obs_processing_ms: 0.4522795805237597\n",
-      "  time_since_restore: 97.21736693382263\n",
-      "  time_this_iter_s: 23.645585536956787\n",
-      "  time_total_s: 97.21736693382263\n",
-      "  timers:\n",
-      "    learn_throughput: 10478.311\n",
-      "    learn_time_ms: 15440.657\n",
-      "    sample_throughput: 18466.869\n",
-      "    sample_time_ms: 8761.204\n",
-      "    update_time_ms: 52.666\n",
-      "  timestamp: 1602167214\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.2613882863341\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.4696860141544\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 290\n",
-      "  episodes_total: 922\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0592716097831727\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007743995590135455\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014329827937763185\n",
-      "        total_loss: 12.433664703369141\n",
-      "        vf_explained_var: 0.967904269695282\n",
-      "        vf_loss: 12.447219848632812\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.35357142857143\n",
-      "    gpu_util_percent0: 0.2582142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16431055835082262\n",
-      "    mean_env_wait_ms: 1.6540874340682217\n",
-      "    mean_inference_ms: 5.1659246506223315\n",
-      "    mean_raw_obs_processing_ms: 0.4451297976580212\n",
-      "  time_since_restore: 120.98013472557068\n",
-      "  time_this_iter_s: 23.762767791748047\n",
-      "  time_total_s: 120.98013472557068\n",
-      "  timers:\n",
-      "    learn_throughput: 10471.141\n",
-      "    learn_time_ms: 15451.229\n",
-      "    sample_throughput: 18710.121\n",
-      "    sample_time_ms: 8647.299\n",
-      "    update_time_ms: 46.768\n",
-      "  timestamp: 1602167237\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-41\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2649186256781\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.83911447202573\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 184\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0483574509620666\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007546161720529199\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015934903593733906\n",
-      "        total_loss: 6.211568450927734\n",
-      "        vf_explained_var: 0.979483425617218\n",
-      "        vf_loss: 6.22674880027771\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.42962962962963\n",
-      "    gpu_util_percent0: 0.23518518518518516\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16320835121240662\n",
-      "    mean_env_wait_ms: 1.658072254904595\n",
-      "    mean_inference_ms: 5.101929976377745\n",
-      "    mean_raw_obs_processing_ms: 0.44197622201871506\n",
-      "  time_since_restore: 144.46361637115479\n",
-      "  time_this_iter_s: 23.483481645584106\n",
-      "  time_total_s: 144.46361637115479\n",
-      "  timers:\n",
-      "    learn_throughput: 10482.756\n",
-      "    learn_time_ms: 15434.108\n",
-      "    sample_throughput: 18930.618\n",
-      "    sample_time_ms: 8546.578\n",
-      "    update_time_ms: 45.48\n",
-      "  timestamp: 1602167261\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-05\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.381329113924\n",
-      "  episode_reward_max: 279.83838383838383\n",
-      "  episode_reward_mean: 228.88543664493022\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0276257395744324\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006892968993633985\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01625481452792883\n",
-      "        total_loss: 5.934515047073364\n",
-      "        vf_explained_var: 0.9834254384040833\n",
-      "        vf_loss: 5.950080394744873\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.47777777777778\n",
-      "    gpu_util_percent0: 0.2955555555555555\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16243749898577767\n",
-      "    mean_env_wait_ms: 1.6615503416153818\n",
-      "    mean_inference_ms: 5.056720554339727\n",
-      "    mean_raw_obs_processing_ms: 0.439742077717109\n",
-      "  time_since_restore: 168.09322547912598\n",
-      "  time_this_iter_s: 23.62960910797119\n",
-      "  time_total_s: 168.09322547912598\n",
-      "  timers:\n",
-      "    learn_throughput: 10486.247\n",
-      "    learn_time_ms: 15428.971\n",
-      "    sample_throughput: 19063.221\n",
-      "    sample_time_ms: 8487.128\n",
-      "    update_time_ms: 45.241\n",
-      "  timestamp: 1602167285\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-28\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.6736990154711\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.3878233814942\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9920619606971741\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0067844231147319075\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01662699868902564\n",
-      "        total_loss: 5.330079460144043\n",
-      "        vf_explained_var: 0.9873720407485962\n",
-      "        vf_loss: 5.346027898788452\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.72222222222223\n",
-      "    gpu_util_percent0: 0.2811111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16179048159969586\n",
-      "    mean_env_wait_ms: 1.664834322637065\n",
-      "    mean_inference_ms: 5.017627986563437\n",
-      "    mean_raw_obs_processing_ms: 0.43762471876215703\n",
-      "  time_since_restore: 191.7211263179779\n",
-      "  time_this_iter_s: 23.62790083885193\n",
-      "  time_total_s: 191.7211263179779\n",
-      "  timers:\n",
-      "    learn_throughput: 10499.739\n",
-      "    learn_time_ms: 15409.145\n",
-      "    sample_throughput: 19126.146\n",
-      "    sample_time_ms: 8459.205\n",
-      "    update_time_ms: 44.366\n",
-      "  timestamp: 1602167308\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 827.9994246260069\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.99320593739455\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9606243968009949\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005957465758547187\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013455570582300425\n",
-      "        total_loss: 7.494734096527099\n",
-      "        vf_explained_var: 0.9888100624084473\n",
-      "        vf_loss: 7.5075939178466795\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.90357142857143\n",
-      "    gpu_util_percent0: 0.26678571428571424\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16076244116115793\n",
-      "    mean_env_wait_ms: 1.6704480394177186\n",
-      "    mean_inference_ms: 4.955192966914281\n",
-      "    mean_raw_obs_processing_ms: 0.4343471050403994\n",
-      "  time_since_restore: 215.57324147224426\n",
-      "  time_this_iter_s: 23.852115154266357\n",
-      "  time_total_s: 215.57324147224426\n",
-      "  timers:\n",
-      "    learn_throughput: 10506.415\n",
-      "    learn_time_ms: 15399.353\n",
-      "    sample_throughput: 19131.856\n",
-      "    sample_time_ms: 8456.681\n",
-      "    update_time_ms: 41.666\n",
-      "  timestamp: 1602167332\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 826.5395569620254\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.1556546477432\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9285854279994965\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0062581704463809725\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016021200059913098\n",
-      "        total_loss: 3.8204103231430055\n",
-      "        vf_explained_var: 0.9922056198120117\n",
-      "        vf_loss: 3.835805630683899\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.096296296296295\n",
-      "    gpu_util_percent0: 0.25592592592592595\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1603412050605606\n",
-      "    mean_env_wait_ms: 1.6728638400028686\n",
-      "    mean_inference_ms: 4.929926052491426\n",
-      "    mean_raw_obs_processing_ms: 0.4330192737930434\n",
-      "  time_since_restore: 238.919837474823\n",
-      "  time_this_iter_s: 23.346596002578735\n",
-      "  time_total_s: 238.919837474823\n",
-      "  timers:\n",
-      "    learn_throughput: 10519.707\n",
-      "    learn_time_ms: 15379.897\n",
-      "    sample_throughput: 19222.536\n",
-      "    sample_time_ms: 8416.788\n",
-      "    update_time_ms: 40.812\n",
-      "  timestamp: 1602167356\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-39\n",
-      "  done: false\n",
-      "  episode_len_mean: 825.4615384615385\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.21514069615333\n",
-      "  episode_reward_min: 114.74747474747485\n",
+      "  episode_len_mean: 841.4780915287245\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 232.2242089837025\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9235042989253998\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005789411393925548\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8218174661908831\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010251943288104874\n",
       "        model: {}\n",
-      "        policy_loss: -0.014859883906319737\n",
-      "        total_loss: 4.004831600189209\n",
-      "        vf_explained_var: 0.9919689893722534\n",
-      "        vf_loss: 4.019112539291382\n",
+      "        policy_loss: -0.02944521393094744\n",
+      "        total_loss: 17.44329833984375\n",
+      "        vf_explained_var: 0.9816536903381348\n",
+      "        vf_loss: 17.47077533176967\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
+      "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.4\n",
-      "    gpu_util_percent0: 0.3125925925925926\n",
+      "    cpu_util_percent: 22.842105263157894\n",
+      "    gpu_util_percent0: 0.4152631578947369\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15996985034496003\n",
-      "    mean_env_wait_ms: 1.675007114196491\n",
-      "    mean_inference_ms: 4.907016710777437\n",
-      "    mean_raw_obs_processing_ms: 0.4317794077781022\n",
-      "  time_since_restore: 262.4391770362854\n",
-      "  time_this_iter_s: 23.519339561462402\n",
-      "  time_total_s: 262.4391770362854\n",
+      "    mean_action_processing_ms: 0.15478313317442852\n",
+      "    mean_env_wait_ms: 1.2174722675860634\n",
+      "    mean_inference_ms: 4.762186846049648\n",
+      "    mean_raw_obs_processing_ms: 0.41139221014187294\n",
+      "  time_since_restore: 340.94291734695435\n",
+      "  time_this_iter_s: 15.413697719573975\n",
+      "  time_total_s: 340.94291734695435\n",
       "  timers:\n",
-      "    learn_throughput: 10544.089\n",
-      "    learn_time_ms: 15344.332\n",
-      "    sample_throughput: 19638.715\n",
-      "    sample_time_ms: 8238.421\n",
-      "    update_time_ms: 40.485\n",
-      "  timestamp: 1602167379\n",
+      "    learn_throughput: 6938.785\n",
+      "    learn_time_ms: 11658.525\n",
+      "    sample_throughput: 22166.284\n",
+      "    sample_time_ms: 3649.507\n",
+      "    update_time_ms: 28.858\n",
+      "  timestamp: 1602414788\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.152428057554\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.18242224402292\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 170\n",
-      "  episodes_total: 2224\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8818272411823272\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005413110228255391\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013095138547942042\n",
-      "        total_loss: 5.083396100997925\n",
-      "        vf_explained_var: 0.9921062588691711\n",
-      "        vf_loss: 5.0959498405456545\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.042857142857144\n",
-      "    gpu_util_percent0: 0.1942857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15960744702974256\n",
-      "    mean_env_wait_ms: 1.677271579492208\n",
-      "    mean_inference_ms: 4.884761150099492\n",
-      "    mean_raw_obs_processing_ms: 0.4305594741365648\n",
-      "  time_since_restore: 286.0365300178528\n",
-      "  time_this_iter_s: 23.597352981567383\n",
-      "  time_total_s: 286.0365300178528\n",
-      "  timers:\n",
-      "    learn_throughput: 10540.17\n",
-      "    learn_time_ms: 15350.038\n",
-      "    sample_throughput: 19693.201\n",
-      "    sample_time_ms: 8215.627\n",
-      "    update_time_ms: 39.264\n",
-      "  timestamp: 1602167403\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 822.2670094936709\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.69313387034907\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 304\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8522311568260192\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005159769672900438\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012773643853142858\n",
-      "        total_loss: 5.1331462383270265\n",
-      "        vf_explained_var: 0.9925912618637085\n",
-      "        vf_loss: 5.145403909683227\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.01481481481482\n",
-      "    gpu_util_percent0: 0.30111111111111116\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15905681990758594\n",
-      "    mean_env_wait_ms: 1.68066117965344\n",
-      "    mean_inference_ms: 4.850479242048183\n",
-      "    mean_raw_obs_processing_ms: 0.4287066632526924\n",
-      "  time_since_restore: 309.50186347961426\n",
-      "  time_this_iter_s: 23.465333461761475\n",
-      "  time_total_s: 309.50186347961426\n",
-      "  timers:\n",
-      "    learn_throughput: 10553.501\n",
-      "    learn_time_ms: 15330.648\n",
-      "    sample_throughput: 19829.166\n",
-      "    sample_time_ms: 8159.294\n",
-      "    update_time_ms: 40.29\n",
-      "  timestamp: 1602167427\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 821.4538346984364\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.94512511563886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8369874477386474\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005370886158198118\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01467731585726142\n",
-      "        total_loss: 3.154995489120483\n",
-      "        vf_explained_var: 0.9942510724067688\n",
-      "        vf_loss: 3.1691357612609865\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.181481481481484\n",
-      "    gpu_util_percent0: 0.3040740740740741\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1588082507195649\n",
-      "    mean_env_wait_ms: 1.6822641931487865\n",
-      "    mean_inference_ms: 4.835116455543884\n",
-      "    mean_raw_obs_processing_ms: 0.42786989591003743\n",
-      "  time_since_restore: 332.9755485057831\n",
-      "  time_this_iter_s: 23.473685026168823\n",
-      "  time_total_s: 332.9755485057831\n",
-      "  timers:\n",
-      "    learn_throughput: 10555.883\n",
-      "    learn_time_ms: 15327.187\n",
-      "    sample_throughput: 19878.044\n",
-      "    sample_time_ms: 8139.232\n",
-      "    update_time_ms: 45.711\n",
-      "  timestamp: 1602167450\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: '11823_00000'\n",
+      "  training_iteration: 22\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     22 |          340.943 | 1779712 |  232.224 |              282.687 |              117.687 |            841.478 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-14\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.854781997187\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.2064917813863\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3521.2922932330825\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-13-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.4711049468331\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 232.7377239804423\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 109\n",
+      "  episodes_total: 2163\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.827689278125763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005339382635429502\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8014648301260812\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010746340666498457\n",
       "        model: {}\n",
-      "        policy_loss: -0.014263017289340495\n",
-      "        total_loss: 3.00002179145813\n",
-      "        vf_explained_var: 0.9941463470458984\n",
-      "        vf_loss: 3.0137508869171143\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
+      "        policy_loss: -0.030137435400060246\n",
+      "        total_loss: 15.846869196210589\n",
+      "        vf_explained_var: 0.9765214920043945\n",
+      "        vf_loss: 15.874937057495117\n",
+      "    num_steps_sampled: 1860608\n",
+      "    num_steps_trained: 1860608\n",
+      "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.57037037037037\n",
-      "    gpu_util_percent0: 0.2274074074074074\n",
+      "    cpu_util_percent: 24.450000000000003\n",
+      "    gpu_util_percent0: 0.37111111111111117\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77037037037037\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15857855076630387\n",
-      "    mean_env_wait_ms: 1.6837618809370547\n",
-      "    mean_inference_ms: 4.820936656490715\n",
-      "    mean_raw_obs_processing_ms: 0.4270767088680792\n",
-      "  time_since_restore: 356.605441570282\n",
-      "  time_this_iter_s: 23.6298930644989\n",
-      "  time_total_s: 356.605441570282\n",
+      "    mean_action_processing_ms: 0.15456071634715085\n",
+      "    mean_env_wait_ms: 1.2180728870997632\n",
+      "    mean_inference_ms: 4.748850502955983\n",
+      "    mean_raw_obs_processing_ms: 0.41069641132000073\n",
+      "  time_since_restore: 356.4750211238861\n",
+      "  time_this_iter_s: 15.532103776931763\n",
+      "  time_total_s: 356.4750211238861\n",
       "  timers:\n",
-      "    learn_throughput: 10553.654\n",
-      "    learn_time_ms: 15330.425\n",
-      "    sample_throughput: 19924.68\n",
-      "    sample_time_ms: 8120.181\n",
-      "    update_time_ms: 47.653\n",
-      "  timestamp: 1602167474\n",
+      "    learn_throughput: 6936.205\n",
+      "    learn_time_ms: 11662.861\n",
+      "    sample_throughput: 22060.373\n",
+      "    sample_time_ms: 3667.028\n",
+      "    update_time_ms: 29.02\n",
+      "  timestamp: 1602414804\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1860608\n",
+      "  training_iteration: 23\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     23 |          356.475 | 1860608 |  232.738 |              285.111 |              117.687 |            839.471 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-38\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3520.273311897106\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-13-39\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0182767624021\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.22214310203864\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 220\n",
-      "  episodes_total: 3064\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 838.866636528029\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 232.95071876084518\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 49\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7918125212192535\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004892151476815343\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8027615376881191\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011178621756178992\n",
       "        model: {}\n",
-      "        policy_loss: -0.012084704916924238\n",
-      "        total_loss: 4.1488186597824095\n",
-      "        vf_explained_var: 0.9942665100097656\n",
-      "        vf_loss: 4.160414218902588\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.03632411014820848\n",
+      "        total_loss: 5.472229072025844\n",
+      "        vf_explained_var: 0.9705377817153931\n",
+      "        vf_loss: 5.506397928510394\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 24\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.81481481481482\n",
-      "    gpu_util_percent0: 0.3077777777777778\n",
+      "    cpu_util_percent: 23.073684210526316\n",
+      "    gpu_util_percent0: 0.3136842105263158\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.158297804116007\n",
-      "    mean_env_wait_ms: 1.6859562656031242\n",
-      "    mean_inference_ms: 4.803618536248515\n",
-      "    mean_raw_obs_processing_ms: 0.42616514556223817\n",
-      "  time_since_restore: 380.0873718261719\n",
-      "  time_this_iter_s: 23.481930255889893\n",
-      "  time_total_s: 380.0873718261719\n",
+      "    mean_action_processing_ms: 0.1544685852667721\n",
+      "    mean_env_wait_ms: 1.2182278892020562\n",
+      "    mean_inference_ms: 4.742784170217995\n",
+      "    mean_raw_obs_processing_ms: 0.4103645265367753\n",
+      "  time_since_restore: 371.84721636772156\n",
+      "  time_this_iter_s: 15.37219524383545\n",
+      "  time_total_s: 371.84721636772156\n",
       "  timers:\n",
-      "    learn_throughput: 10556.149\n",
-      "    learn_time_ms: 15326.802\n",
-      "    sample_throughput: 19915.022\n",
-      "    sample_time_ms: 8124.119\n",
-      "    update_time_ms: 46.174\n",
-      "  timestamp: 1602167498\n",
+      "    learn_throughput: 6939.484\n",
+      "    learn_time_ms: 11657.352\n",
+      "    sample_throughput: 22095.085\n",
+      "    sample_time_ms: 3661.267\n",
+      "    update_time_ms: 27.78\n",
+      "  timestamp: 1602414819\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 24\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     24 |          371.847 | 1941504 |  232.951 |              285.111 |              117.687 |            838.867 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-01\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3514.3297644539616\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-13-55\n",
       "  done: false\n",
-      "  episode_len_mean: 819.2076552139844\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.34207049396923\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 836.1455696202531\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 233.97161488300716\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.05\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7639730334281921\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004952558875083923\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7634506140436444\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01075770945421287\n",
       "        model: {}\n",
-      "        policy_loss: -0.011812644638121128\n",
-      "        total_loss: 3.641219711303711\n",
-      "        vf_explained_var: 0.9940530061721802\n",
-      "        vf_loss: 3.6527847766876222\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.03034432658127376\n",
+      "        total_loss: 13.53955432346889\n",
+      "        vf_explained_var: 0.9839022755622864\n",
+      "        vf_loss: 13.567823546273369\n",
+      "    num_steps_sampled: 2022400\n",
+      "    num_steps_trained: 2022400\n",
+      "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.58928571428571\n",
-      "    gpu_util_percent0: 0.33428571428571435\n",
+      "    cpu_util_percent: 23.66842105263158\n",
+      "    gpu_util_percent0: 0.3626315789473684\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1579861428053209\n",
-      "    mean_env_wait_ms: 1.6878268274425987\n",
-      "    mean_inference_ms: 4.784786851610141\n",
-      "    mean_raw_obs_processing_ms: 0.4251258149287427\n",
-      "  time_since_restore: 403.5224757194519\n",
-      "  time_this_iter_s: 23.43510389328003\n",
-      "  time_total_s: 403.5224757194519\n",
+      "    mean_action_processing_ms: 0.15418583463624513\n",
+      "    mean_env_wait_ms: 1.219061598042449\n",
+      "    mean_inference_ms: 4.7252878782857275\n",
+      "    mean_raw_obs_processing_ms: 0.40943558152485915\n",
+      "  time_since_restore: 387.34790420532227\n",
+      "  time_this_iter_s: 15.500687837600708\n",
+      "  time_total_s: 387.34790420532227\n",
       "  timers:\n",
-      "    learn_throughput: 10564.477\n",
-      "    learn_time_ms: 15314.719\n",
-      "    sample_throughput: 19933.192\n",
-      "    sample_time_ms: 8116.713\n",
-      "    update_time_ms: 45.777\n",
-      "  timestamp: 1602167521\n",
+      "    learn_throughput: 6935.852\n",
+      "    learn_time_ms: 11663.455\n",
+      "    sample_throughput: 22038.179\n",
+      "    sample_time_ms: 3670.721\n",
+      "    update_time_ms: 29.508\n",
+      "  timestamp: 1602414835\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2022400\n",
+      "  training_iteration: 25\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     25 |          387.348 | 2022400 |  233.972 |              285.111 |              117.687 |            836.146 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-25\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3512.205439330544\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-10\n",
       "  done: false\n",
-      "  episode_len_mean: 818.5304948216341\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.56991956387816\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 835.2358762886598\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 234.24388212017067\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 55\n",
+      "  episodes_total: 2425\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7660917460918426\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005422895355150103\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7645284192902702\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011046201921999454\n",
       "        model: {}\n",
-      "        policy_loss: -0.013137935660779476\n",
-      "        total_loss: 2.9323360919952393\n",
-      "        vf_explained_var: 0.9942866563796997\n",
-      "        vf_loss: 2.94533851146698\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.03211360025618758\n",
+      "        total_loss: 11.541997228349958\n",
+      "        vf_explained_var: 0.9777361750602722\n",
+      "        vf_loss: 11.571977751595634\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.25925925925925\n",
-      "    gpu_util_percent0: 0.36148148148148146\n",
+      "    cpu_util_percent: 24.450000000000003\n",
+      "    gpu_util_percent0: 0.32944444444444443\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.759259259259261\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15781721284272957\n",
-      "    mean_env_wait_ms: 1.6890502862525536\n",
-      "    mean_inference_ms: 4.774409463690571\n",
-      "    mean_raw_obs_processing_ms: 0.4245721837690542\n",
-      "  time_since_restore: 426.88156366348267\n",
-      "  time_this_iter_s: 23.35908794403076\n",
-      "  time_total_s: 426.88156366348267\n",
+      "    mean_action_processing_ms: 0.1540866708881542\n",
+      "    mean_env_wait_ms: 1.2193572901306673\n",
+      "    mean_inference_ms: 4.719611668274306\n",
+      "    mean_raw_obs_processing_ms: 0.4091137457703957\n",
+      "  time_since_restore: 402.7666323184967\n",
+      "  time_this_iter_s: 15.418728113174438\n",
+      "  time_total_s: 402.7666323184967\n",
       "  timers:\n",
-      "    learn_throughput: 10562.111\n",
-      "    learn_time_ms: 15318.149\n",
-      "    sample_throughput: 20027.117\n",
-      "    sample_time_ms: 8078.647\n",
-      "    update_time_ms: 51.49\n",
-      "  timestamp: 1602167545\n",
+      "    learn_throughput: 6927.737\n",
+      "    learn_time_ms: 11677.118\n",
+      "    sample_throughput: 22093.872\n",
+      "    sample_time_ms: 3661.468\n",
+      "    update_time_ms: 31.122\n",
+      "  timestamp: 1602414850\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 26\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     26 |          402.767 | 2103296 |  234.244 |              285.111 |              117.687 |            835.236 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-49\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3508.1211391897314\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-26\n",
       "  done: false\n",
-      "  episode_len_mean: 817.8346629986245\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.78994900865604\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3635\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 834.1194620253165\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 234.74916490857933\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 103\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.761504179239273\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00561123825609684\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7696538737842015\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009899940873895372\n",
       "        model: {}\n",
-      "        policy_loss: -0.01371184946037829\n",
-      "        total_loss: 2.586661458015442\n",
-      "        vf_explained_var: 0.9948149919509888\n",
-      "        vf_loss: 2.6002331018447875\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
+      "        policy_loss: -0.03010483897690262\n",
+      "        total_loss: 7.996133531842913\n",
+      "        vf_explained_var: 0.9810003042221069\n",
+      "        vf_loss: 8.024335248129708\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.98518518518519\n",
-      "    gpu_util_percent0: 0.25\n",
+      "    cpu_util_percent: 23.047368421052635\n",
+      "    gpu_util_percent0: 0.32263157894736844\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.205263157894737\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1576552038626758\n",
-      "    mean_env_wait_ms: 1.6902745430630273\n",
-      "    mean_inference_ms: 4.764639495963006\n",
-      "    mean_raw_obs_processing_ms: 0.42404147010851506\n",
-      "  time_since_restore: 450.4647214412689\n",
-      "  time_this_iter_s: 23.583157777786255\n",
-      "  time_total_s: 450.4647214412689\n",
+      "    mean_action_processing_ms: 0.15393358815170508\n",
+      "    mean_env_wait_ms: 1.2198577496072052\n",
+      "    mean_inference_ms: 4.709424175827586\n",
+      "    mean_raw_obs_processing_ms: 0.40858386146833126\n",
+      "  time_since_restore: 418.18699383735657\n",
+      "  time_this_iter_s: 15.420361518859863\n",
+      "  time_total_s: 418.18699383735657\n",
       "  timers:\n",
-      "    learn_throughput: 10558.952\n",
-      "    learn_time_ms: 15322.733\n",
-      "    sample_throughput: 20107.322\n",
-      "    sample_time_ms: 8046.422\n",
-      "    update_time_ms: 53.421\n",
-      "  timestamp: 1602167569\n",
+      "    learn_throughput: 6928.452\n",
+      "    learn_time_ms: 11675.912\n",
+      "    sample_throughput: 22068.825\n",
+      "    sample_time_ms: 3665.623\n",
+      "    update_time_ms: 33.599\n",
+      "  timestamp: 1602414866\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 27\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     27 |          418.187 | 2184192 |  234.749 |              285.111 |              117.687 |            834.119 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-12\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3502.2642506606267\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-41\n",
       "  done: false\n",
-      "  episode_len_mean: 816.6687881873727\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.22543664753442\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 293\n",
-      "  episodes_total: 3928\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 832.1322652757079\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 235.60601920847813\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 156\n",
+      "  episodes_total: 2684\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7176933705806732\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004935431573539972\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7382196017674038\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010356013397020953\n",
       "        model: {}\n",
-      "        policy_loss: -0.011507348460145294\n",
-      "        total_loss: 3.7333247661590576\n",
-      "        vf_explained_var: 0.9947683215141296\n",
-      "        vf_loss: 3.744708704948425\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
+      "        policy_loss: -0.028260654636791775\n",
+      "        total_loss: 13.343521799360003\n",
+      "        vf_explained_var: 0.9828724265098572\n",
+      "        vf_loss: 13.36978530883789\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 28\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92962962962963\n",
-      "    gpu_util_percent0: 0.22925925925925927\n",
+      "    cpu_util_percent: 23.80526315789474\n",
+      "    gpu_util_percent0: 0.35578947368421054\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15738510281829127\n",
-      "    mean_env_wait_ms: 1.6923950386450304\n",
-      "    mean_inference_ms: 4.748233050103123\n",
-      "    mean_raw_obs_processing_ms: 0.4231474863161252\n",
-      "  time_since_restore: 473.9994788169861\n",
-      "  time_this_iter_s: 23.534757375717163\n",
-      "  time_total_s: 473.9994788169861\n",
+      "    mean_action_processing_ms: 0.1537085266981266\n",
+      "    mean_env_wait_ms: 1.220682130353048\n",
+      "    mean_inference_ms: 4.6951938469222805\n",
+      "    mean_raw_obs_processing_ms: 0.40782552885921136\n",
+      "  time_since_restore: 433.7264211177826\n",
+      "  time_this_iter_s: 15.539427280426025\n",
+      "  time_total_s: 433.7264211177826\n",
       "  timers:\n",
-      "    learn_throughput: 10546.772\n",
-      "    learn_time_ms: 15340.429\n",
-      "    sample_throughput: 20112.723\n",
-      "    sample_time_ms: 8044.261\n",
-      "    update_time_ms: 53.96\n",
-      "  timestamp: 1602167592\n",
+      "    learn_throughput: 6914.972\n",
+      "    learn_time_ms: 11698.674\n",
+      "    sample_throughput: 22014.804\n",
+      "    sample_time_ms: 3674.618\n",
+      "    update_time_ms: 33.996\n",
+      "  timestamp: 1602414881\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 28\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     28 |          433.726 | 2265088 |  235.606 |              288.899 |              117.687 |            832.132 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-36\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3501.7143393393394\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-57\n",
       "  done: false\n",
-      "  episode_len_mean: 815.9362220058423\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.68833171048362\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 831.9573916265283\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 235.6916291480944\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 15\n",
+      "  episodes_total: 2699\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6961194634437561\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0054001738782972096\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.741259115082877\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011515548718827111\n",
       "        model: {}\n",
-      "        policy_loss: -0.013575149234384298\n",
-      "        total_loss: 2.1967584609985353\n",
-      "        vf_explained_var: 0.9954622387886047\n",
-      "        vf_loss: 2.210266089439392\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
+      "        policy_loss: -0.0386028066277504\n",
+      "        total_loss: 5.7686494418552945\n",
+      "        vf_explained_var: 0.9847227931022644\n",
+      "        vf_loss: 5.805023602076939\n",
+      "    num_steps_sampled: 2345984\n",
+      "    num_steps_trained: 2345984\n",
+      "  iterations_since_restore: 29\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.440740740740736\n",
-      "    gpu_util_percent0: 0.29666666666666663\n",
+      "    cpu_util_percent: 24.344444444444445\n",
+      "    gpu_util_percent0: 0.3016666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15722895249997093\n",
-      "    mean_env_wait_ms: 1.6936030533075188\n",
-      "    mean_inference_ms: 4.738907510439971\n",
-      "    mean_raw_obs_processing_ms: 0.42262820408828605\n",
-      "  time_since_restore: 497.52709674835205\n",
-      "  time_this_iter_s: 23.527617931365967\n",
-      "  time_total_s: 497.52709674835205\n",
+      "    mean_action_processing_ms: 0.15368784955660025\n",
+      "    mean_env_wait_ms: 1.220787727557082\n",
+      "    mean_inference_ms: 4.693690857541116\n",
+      "    mean_raw_obs_processing_ms: 0.40773859312733546\n",
+      "  time_since_restore: 449.04663133621216\n",
+      "  time_this_iter_s: 15.320210218429565\n",
+      "  time_total_s: 449.04663133621216\n",
       "  timers:\n",
-      "    learn_throughput: 10537.753\n",
-      "    learn_time_ms: 15353.558\n",
-      "    sample_throughput: 20139.989\n",
-      "    sample_time_ms: 8033.371\n",
-      "    update_time_ms: 52.995\n",
-      "  timestamp: 1602167616\n",
+      "    learn_throughput: 6918.65\n",
+      "    learn_time_ms: 11692.455\n",
+      "    sample_throughput: 22099.217\n",
+      "    sample_time_ms: 3660.582\n",
+      "    update_time_ms: 32.081\n",
+      "  timestamp: 1602414897\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2345984\n",
+      "  training_iteration: 29\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     29 |          449.047 | 2345984 |  235.692 |              288.899 |              117.687 |            831.957 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-00\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3496.444998220007\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-13\n",
       "  done: false\n",
-      "  episode_len_mean: 815.2585560243788\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.9339172313856\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 830.2095639943741\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 236.55434087712558\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 145\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7063014328479766\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005521039292216301\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7333477054323468\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009345830285123416\n",
       "        model: {}\n",
-      "        policy_loss: -0.013345666276291013\n",
-      "        total_loss: 2.40686240196228\n",
-      "        vf_explained_var: 0.994661808013916\n",
-      "        vf_loss: 2.4201390743255615\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
+      "        policy_loss: -0.027462404487388476\n",
+      "        total_loss: 9.17048522404262\n",
+      "        vf_explained_var: 0.985461413860321\n",
+      "        vf_loss: 9.196151460920062\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 30\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.3\n",
-      "    gpu_util_percent0: 0.3596428571428571\n",
+      "    cpu_util_percent: 21.994736842105265\n",
+      "    gpu_util_percent0: 0.3536842105263157\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.760714285714286\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15710538677505165\n",
-      "    mean_env_wait_ms: 1.694637493002915\n",
-      "    mean_inference_ms: 4.731284261187251\n",
-      "    mean_raw_obs_processing_ms: 0.42220494507105216\n",
-      "  time_since_restore: 521.2907056808472\n",
-      "  time_this_iter_s: 23.763608932495117\n",
-      "  time_total_s: 521.2907056808472\n",
+      "    mean_action_processing_ms: 0.1534987590693203\n",
+      "    mean_env_wait_ms: 1.2214597079228968\n",
+      "    mean_inference_ms: 4.681632229679235\n",
+      "    mean_raw_obs_processing_ms: 0.4070969874551114\n",
+      "  time_since_restore: 464.6360778808594\n",
+      "  time_this_iter_s: 15.589446544647217\n",
+      "  time_total_s: 464.6360778808594\n",
       "  timers:\n",
-      "    learn_throughput: 10529.291\n",
-      "    learn_time_ms: 15365.897\n",
-      "    sample_throughput: 20152.527\n",
-      "    sample_time_ms: 8028.373\n",
-      "    update_time_ms: 60.563\n",
-      "  timestamp: 1602167640\n",
+      "    learn_throughput: 6916.731\n",
+      "    learn_time_ms: 11695.698\n",
+      "    sample_throughput: 22056.083\n",
+      "    sample_time_ms: 3667.741\n",
+      "    update_time_ms: 30.853\n",
+      "  timestamp: 1602414913\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 30\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     30 |          464.636 | 2426880 |  236.554 |              288.899 |              117.687 |             830.21 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-24\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3491.385887913572\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-28\n",
       "  done: false\n",
-      "  episode_len_mean: 814.5122444394518\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.18438711990723\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4451\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 828.4894894894895\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 237.34450612228375\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 153\n",
+      "  episodes_total: 2997\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.687007212638855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005151082994416356\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7141761098589215\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010538498205798013\n",
       "        model: {}\n",
-      "        policy_loss: -0.0136242700740695\n",
-      "        total_loss: 2.3987212419509887\n",
-      "        vf_explained_var: 0.9956458210945129\n",
-      "        vf_loss: 2.412281060218811\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
+      "        policy_loss: -0.03002121073326894\n",
+      "        total_loss: 12.987276213509697\n",
+      "        vf_explained_var: 0.9814284443855286\n",
+      "        vf_loss: 13.015260968889509\n",
+      "    num_steps_sampled: 2507776\n",
+      "    num_steps_trained: 2507776\n",
+      "  iterations_since_restore: 31\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.87777777777778\n",
-      "    gpu_util_percent0: 0.32259259259259254\n",
+      "    cpu_util_percent: 23.484210526315795\n",
+      "    gpu_util_percent0: 0.3489473684210526\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15697868978775206\n",
-      "    mean_env_wait_ms: 1.6959996633636125\n",
-      "    mean_inference_ms: 4.723299684373984\n",
-      "    mean_raw_obs_processing_ms: 0.42177767922029563\n",
-      "  time_since_restore: 544.7509255409241\n",
-      "  time_this_iter_s: 23.460219860076904\n",
-      "  time_total_s: 544.7509255409241\n",
+      "    mean_action_processing_ms: 0.1533164741883748\n",
+      "    mean_env_wait_ms: 1.2222260271011502\n",
+      "    mean_inference_ms: 4.669791183442398\n",
+      "    mean_raw_obs_processing_ms: 0.4064721500356665\n",
+      "  time_since_restore: 480.01299381256104\n",
+      "  time_this_iter_s: 15.37691593170166\n",
+      "  time_total_s: 480.01299381256104\n",
       "  timers:\n",
-      "    learn_throughput: 10523.637\n",
-      "    learn_time_ms: 15374.152\n",
-      "    sample_throughput: 20153.695\n",
-      "    sample_time_ms: 8027.908\n",
-      "    update_time_ms: 54.413\n",
-      "  timestamp: 1602167664\n",
+      "    learn_throughput: 6914.421\n",
+      "    learn_time_ms: 11699.606\n",
+      "    sample_throughput: 22037.607\n",
+      "    sample_time_ms: 3670.816\n",
+      "    update_time_ms: 32.095\n",
+      "  timestamp: 1602414928\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2507776\n",
+      "  training_iteration: 31\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     31 |          480.013 | 2507776 |  237.345 |              288.899 |              117.687 |            828.489 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-48\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3491.1973728528124\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-44\n",
       "  done: false\n",
-      "  episode_len_mean: 813.3535864978903\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.57533989685885\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 828.3931424766978\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 237.37692840522388\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 7\n",
+      "  episodes_total: 3004\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6324166178703308\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048749387264251706\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7138987694467817\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011370175118957247\n",
       "        model: {}\n",
-      "        policy_loss: -0.011797640426084399\n",
-      "        total_loss: 2.6533204078674317\n",
-      "        vf_explained_var: 0.9955232739448547\n",
-      "        vf_loss: 2.66505708694458\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
+      "        policy_loss: -0.04013798572123051\n",
+      "        total_loss: 4.070477996553693\n",
+      "        vf_explained_var: 0.9827483892440796\n",
+      "        vf_loss: 4.10841349193028\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 32\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.074074074074076\n",
-      "    gpu_util_percent0: 0.3251851851851852\n",
+      "    cpu_util_percent: 23.51111111111111\n",
+      "    gpu_util_percent0: 0.36277777777777775\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.222222222222222\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15677630383088909\n",
-      "    mean_env_wait_ms: 1.6975983446472827\n",
-      "    mean_inference_ms: 4.710750302441915\n",
-      "    mean_raw_obs_processing_ms: 0.421060709542158\n",
-      "  time_since_restore: 568.4359018802643\n",
-      "  time_this_iter_s: 23.68497633934021\n",
-      "  time_total_s: 568.4359018802643\n",
+      "    mean_action_processing_ms: 0.1533064561571048\n",
+      "    mean_env_wait_ms: 1.2222521564882434\n",
+      "    mean_inference_ms: 4.6691816857432045\n",
+      "    mean_raw_obs_processing_ms: 0.40643459995117087\n",
+      "  time_since_restore: 495.2956557273865\n",
+      "  time_this_iter_s: 15.28266191482544\n",
+      "  time_total_s: 495.2956557273865\n",
       "  timers:\n",
-      "    learn_throughput: 10517.772\n",
-      "    learn_time_ms: 15382.726\n",
-      "    sample_throughput: 20124.264\n",
-      "    sample_time_ms: 8039.648\n",
-      "    update_time_ms: 48.571\n",
-      "  timestamp: 1602167688\n",
+      "    learn_throughput: 6922.456\n",
+      "    learn_time_ms: 11686.026\n",
+      "    sample_throughput: 22035.276\n",
+      "    sample_time_ms: 3671.204\n",
+      "    update_time_ms: 31.844\n",
+      "  timestamp: 1602414944\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 32\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     32 |          495.296 | 2588672 |  237.377 |              288.899 |              117.687 |            828.393 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-11\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3486.02176\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-59\n",
       "  done: false\n",
-      "  episode_len_mean: 812.6929358922009\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.80383252698485\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4898\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 826.7759493670886\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 238.20249968034767\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 156\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.00625\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6476718962192536\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004980697343125939\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7064724820000785\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009518824517726898\n",
       "        model: {}\n",
-      "        policy_loss: -0.012937380420044064\n",
-      "        total_loss: 2.2160698890686037\n",
-      "        vf_explained_var: 0.9949172735214233\n",
-      "        vf_loss: 2.2289761781692503\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
+      "        policy_loss: -0.029149129454578673\n",
+      "        total_loss: 8.81074333190918\n",
+      "        vf_explained_var: 0.988771378993988\n",
+      "        vf_loss: 8.838059425354004\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 33\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.93703703703704\n",
-      "    gpu_util_percent0: 0.2511111111111111\n",
+      "    cpu_util_percent: 24.18888888888889\n",
+      "    gpu_util_percent0: 0.32944444444444443\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15667803602924033\n",
-      "    mean_env_wait_ms: 1.6985389146300989\n",
-      "    mean_inference_ms: 4.704622565044838\n",
-      "    mean_raw_obs_processing_ms: 0.420720785257639\n",
-      "  time_since_restore: 592.1190402507782\n",
-      "  time_this_iter_s: 23.683138370513916\n",
-      "  time_total_s: 592.1190402507782\n",
+      "    mean_action_processing_ms: 0.1531353521503298\n",
+      "    mean_env_wait_ms: 1.2230012031400455\n",
+      "    mean_inference_ms: 4.657997312372352\n",
+      "    mean_raw_obs_processing_ms: 0.405836882924193\n",
+      "  time_since_restore: 510.6310017108917\n",
+      "  time_this_iter_s: 15.335345983505249\n",
+      "  time_total_s: 510.6310017108917\n",
       "  timers:\n",
-      "    learn_throughput: 10525.475\n",
-      "    learn_time_ms: 15371.468\n",
-      "    sample_throughput: 20083.377\n",
-      "    sample_time_ms: 8056.016\n",
-      "    update_time_ms: 47.817\n",
-      "  timestamp: 1602167711\n",
+      "    learn_throughput: 6922.808\n",
+      "    learn_time_ms: 11685.432\n",
+      "    sample_throughput: 22142.487\n",
+      "    sample_time_ms: 3653.429\n",
+      "    update_time_ms: 30.31\n",
+      "  timestamp: 1602414959\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 33\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     33 |          510.631 | 2669568 |  238.202 |              288.899 |              117.687 |            826.776 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-35\n",
-      "  done: true\n",
-      "  episode_len_mean: 812.0104784499803\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 234.07366667864886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 160\n",
-      "  episodes_total: 5058\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3481.9266871165646\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-16-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.322913505311\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 238.75570576784526\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 135\n",
+      "  episodes_total: 3295\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.003125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6387091696262359\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00521918865852058\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6861251592636108\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009984563237854413\n",
       "        model: {}\n",
-      "        policy_loss: -0.013382896583061665\n",
-      "        total_loss: 2.0056067228317263\n",
-      "        vf_explained_var: 0.9955011606216431\n",
-      "        vf_loss: 2.0189733505249023\n",
-      "    num_steps_sampled: 4206592\n",
-      "    num_steps_trained: 4206592\n",
-      "  iterations_since_restore: 26\n",
+      "        policy_loss: -0.028198028781584332\n",
+      "        total_loss: 13.189177240644183\n",
+      "        vf_explained_var: 0.9802125096321106\n",
+      "        vf_loss: 13.21544715336391\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 34\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.729629629629635\n",
-      "    gpu_util_percent0: 0.267037037037037\n",
+      "    cpu_util_percent: 23.45263157894737\n",
+      "    gpu_util_percent0: 0.3442105263157894\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15658306876779257\n",
-      "    mean_env_wait_ms: 1.6995085455679213\n",
-      "    mean_inference_ms: 4.6987769399539845\n",
-      "    mean_raw_obs_processing_ms: 0.42039589930108456\n",
-      "  time_since_restore: 615.6618909835815\n",
-      "  time_this_iter_s: 23.542850732803345\n",
-      "  time_total_s: 615.6618909835815\n",
+      "    mean_action_processing_ms: 0.1529844828154928\n",
+      "    mean_env_wait_ms: 1.223661539893914\n",
+      "    mean_inference_ms: 4.648884962993294\n",
+      "    mean_raw_obs_processing_ms: 0.4053319879620939\n",
+      "  time_since_restore: 526.1448483467102\n",
+      "  time_this_iter_s: 15.513846635818481\n",
+      "  time_total_s: 526.1448483467102\n",
       "  timers:\n",
-      "    learn_throughput: 10524.21\n",
-      "    learn_time_ms: 15373.315\n",
-      "    sample_throughput: 20076.608\n",
-      "    sample_time_ms: 8058.732\n",
-      "    update_time_ms: 48.59\n",
-      "  timestamp: 1602167735\n",
+      "    learn_throughput: 6915.508\n",
+      "    learn_time_ms: 11697.767\n",
+      "    sample_throughput: 22132.635\n",
+      "    sample_time_ms: 3655.055\n",
+      "    update_time_ms: 30.002\n",
+      "  timestamp: 1602414975\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4206592\n",
-      "  training_iteration: 26\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 34\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32990\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3204.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 630\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 279.83838\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.88544\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "2020-10-08 14:35:46,970 - wandb.wandb_agent - INFO - Cleaning up finished run: w8c2p6ff\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 32768\n",
-      "2020-10-08 14:35:47,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=32768\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/y6ys1sgz\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_143549-y6ys1sgz\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:35:51,552\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:35:52,322 - wandb.wandb_agent - INFO - Running runs: ['y6ys1sgz']\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     34 |          526.145 | 2750464 |  238.756 |              288.899 |              117.687 |            825.323 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=62403)\u001b[0m 2020-10-08 14:35:54,588\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-36-25\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3480.9317697228144\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-16-30\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 825.1428571428571\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 238.89698065647423\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 23\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1634249687194824\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0036954283714294434\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6846187114715576\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010950947712574686\n",
       "        model: {}\n",
-      "        policy_loss: -0.006869117938913405\n",
-      "        total_loss: 9.30032901763916\n",
-      "        vf_explained_var: 0.7174946069717407\n",
-      "        vf_loss: 9.306459045410156\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.03858303331903049\n",
+      "        total_loss: 3.6150619983673096\n",
+      "        vf_explained_var: 0.9793863296508789\n",
+      "        vf_loss: 3.6515232835497176\n",
+      "    num_steps_sampled: 2831360\n",
+      "    num_steps_trained: 2831360\n",
+      "  iterations_since_restore: 35\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 39.282758620689656\n",
-      "    gpu_util_percent0: 0.27758620689655167\n",
+      "    cpu_util_percent: 22.778947368421054\n",
+      "    gpu_util_percent0: 0.29\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003448275862068966\n",
-      "    ram_util_percent: 9.486206896551723\n",
-      "    vram_util_percent0: 0.30692086721480194\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1757240295410156\n",
-      "    mean_env_wait_ms: 1.64632514878238\n",
-      "    mean_inference_ms: 5.702464303031089\n",
-      "    mean_raw_obs_processing_ms: 0.4785182454697177\n",
-      "  time_since_restore: 24.381270170211792\n",
-      "  time_this_iter_s: 24.381270170211792\n",
-      "  time_total_s: 24.381270170211792\n",
+      "    mean_action_processing_ms: 0.15297329920887245\n",
+      "    mean_env_wait_ms: 1.2237476763616006\n",
+      "    mean_inference_ms: 4.6474416361949995\n",
+      "    mean_raw_obs_processing_ms: 0.4052684775842852\n",
+      "  time_since_restore: 541.7210958003998\n",
+      "  time_this_iter_s: 15.576247453689575\n",
+      "  time_total_s: 541.7210958003998\n",
       "  timers:\n",
-      "    learn_throughput: 10955.585\n",
-      "    learn_time_ms: 14767.992\n",
-      "    sample_throughput: 16976.731\n",
-      "    sample_time_ms: 9530.221\n",
-      "    update_time_ms: 49.441\n",
-      "  timestamp: 1602167785\n",
+      "    learn_throughput: 6910.252\n",
+      "    learn_time_ms: 11706.663\n",
+      "    sample_throughput: 22141.4\n",
+      "    sample_time_ms: 3653.608\n",
+      "    update_time_ms: 30.476\n",
+      "  timestamp: 1602414990\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2831360\n",
+      "  training_iteration: 35\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     35 |          541.721 | 2831360 |  238.897 |              288.899 |              117.687 |            825.143 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-36-48\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3476.683812845103\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-16-46\n",
       "  done: false\n",
-      "  episode_len_mean: 867.5569620253165\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 226.67721518987318\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 823.734752589183\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 239.4782868965837\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1362101554870605\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006970350444316864\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6705271346228463\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009495977844510759\n",
       "        model: {}\n",
-      "        policy_loss: -0.009705625101923942\n",
-      "        total_loss: 10.32210750579834\n",
-      "        vf_explained_var: 0.8451136350631714\n",
-      "        vf_loss: 10.331116104125977\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.027984988210456713\n",
+      "        total_loss: 10.82583590916225\n",
+      "        vf_explained_var: 0.9875221252441406\n",
+      "        vf_loss: 10.851988383701869\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 36\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.548148148148144\n",
-      "    gpu_util_percent0: 0.2866666666666667\n",
+      "    cpu_util_percent: 23.383333333333336\n",
+      "    gpu_util_percent0: 0.3\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.733333333333334\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.222222222222222\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17100616576939356\n",
-      "    mean_env_wait_ms: 1.647485749663841\n",
-      "    mean_inference_ms: 5.449976105277291\n",
-      "    mean_raw_obs_processing_ms: 0.4667153357279003\n",
-      "  time_since_restore: 47.252567291259766\n",
-      "  time_this_iter_s: 22.871297121047974\n",
-      "  time_total_s: 47.252567291259766\n",
+      "    mean_action_processing_ms: 0.15282164445607432\n",
+      "    mean_env_wait_ms: 1.2244793275638173\n",
+      "    mean_inference_ms: 4.63757056643333\n",
+      "    mean_raw_obs_processing_ms: 0.4047337000957116\n",
+      "  time_since_restore: 557.1422667503357\n",
+      "  time_this_iter_s: 15.421170949935913\n",
+      "  time_total_s: 557.1422667503357\n",
       "  timers:\n",
-      "    learn_throughput: 11041.238\n",
-      "    learn_time_ms: 14653.429\n",
-      "    sample_throughput: 18199.954\n",
-      "    sample_time_ms: 8889.693\n",
-      "    update_time_ms: 42.206\n",
-      "  timestamp: 1602167808\n",
+      "    learn_throughput: 6913.815\n",
+      "    learn_time_ms: 11700.631\n",
+      "    sample_throughput: 22094.423\n",
+      "    sample_time_ms: 3661.376\n",
+      "    update_time_ms: 28.494\n",
+      "  timestamp: 1602415006\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 36\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     36 |          557.142 | 2912256 |  239.478 |              288.899 |              117.687 |            823.735 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-11\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3474.3468811741463\n",
+      "    time_step_min: 3172\n",
+      "  date: 2020-10-11_11-17-02\n",
       "  done: false\n",
-      "  episode_len_mean: 859.824894514768\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.24830584324238\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 822.8353828954723\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 239.84187317557905\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 102\n",
+      "  episodes_total: 3578\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.12405526638031\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006674189120531082\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6732551966394696\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010459980927407742\n",
       "        model: {}\n",
-      "        policy_loss: -0.010977230872958899\n",
-      "        total_loss: 12.676021194458007\n",
-      "        vf_explained_var: 0.8899718523025513\n",
-      "        vf_loss: 12.686330986022949\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.02988721669784614\n",
+      "        total_loss: 12.020891189575195\n",
+      "        vf_explained_var: 0.9796990156173706\n",
+      "        vf_loss: 12.04875387464251\n",
+      "    num_steps_sampled: 2993152\n",
+      "    num_steps_trained: 2993152\n",
+      "  iterations_since_restore: 37\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.05555555555555\n",
-      "    gpu_util_percent0: 0.2644444444444444\n",
+      "    cpu_util_percent: 22.978947368421053\n",
+      "    gpu_util_percent0: 0.3431578947368421\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16808367664964877\n",
-      "    mean_env_wait_ms: 1.6489405832417077\n",
-      "    mean_inference_ms: 5.307994845910706\n",
-      "    mean_raw_obs_processing_ms: 0.45738673020424264\n",
-      "  time_since_restore: 70.47958087921143\n",
-      "  time_this_iter_s: 23.22701358795166\n",
-      "  time_total_s: 70.47958087921143\n",
+      "    mean_action_processing_ms: 0.1527189275009953\n",
+      "    mean_env_wait_ms: 1.2249342826484029\n",
+      "    mean_inference_ms: 4.63159545625294\n",
+      "    mean_raw_obs_processing_ms: 0.4044093019860797\n",
+      "  time_since_restore: 572.7838077545166\n",
+      "  time_this_iter_s: 15.641541004180908\n",
+      "  time_total_s: 572.7838077545166\n",
       "  timers:\n",
-      "    learn_throughput: 11042.229\n",
-      "    learn_time_ms: 14652.115\n",
-      "    sample_throughput: 18479.026\n",
-      "    sample_time_ms: 8755.44\n",
-      "    update_time_ms: 41.454\n",
-      "  timestamp: 1602167831\n",
+      "    learn_throughput: 6895.582\n",
+      "    learn_time_ms: 11731.569\n",
+      "    sample_throughput: 22149.093\n",
+      "    sample_time_ms: 3652.339\n",
+      "    update_time_ms: 28.275\n",
+      "  timestamp: 1602415022\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2993152\n",
+      "  training_iteration: 37\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     37 |          572.784 | 2993152 |  239.842 |              288.899 |              117.687 |            822.835 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-34\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3472.9027507641013\n",
+      "    time_step_min: 3172\n",
+      "  date: 2020-10-11_11-17-17\n",
       "  done: false\n",
-      "  episode_len_mean: 853.2689873417721\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.76543920214786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 822.44551458448\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 240.0620375466274\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 56\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0947366952896118\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005848201550543308\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.657863906451634\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010496733177985464\n",
       "        model: {}\n",
-      "        policy_loss: -0.01150441262871027\n",
-      "        total_loss: 13.476828002929688\n",
-      "        vf_explained_var: 0.9183750152587891\n",
-      "        vf_loss: 13.487747383117675\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.0346918199211359\n",
+      "        total_loss: 4.282534122467041\n",
+      "        vf_explained_var: 0.9811368584632874\n",
+      "        vf_loss: 4.315192358834403\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 38\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.855555555555554\n",
-      "    gpu_util_percent0: 0.27814814814814814\n",
+      "    cpu_util_percent: 23.42105263157895\n",
+      "    gpu_util_percent0: 0.3310526315789474\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744444444444445\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16618084056987167\n",
-      "    mean_env_wait_ms: 1.652121993019246\n",
-      "    mean_inference_ms: 5.206010003773685\n",
-      "    mean_raw_obs_processing_ms: 0.45115332512960615\n",
-      "  time_since_restore: 93.41903614997864\n",
-      "  time_this_iter_s: 22.939455270767212\n",
-      "  time_total_s: 93.41903614997864\n",
+      "    mean_action_processing_ms: 0.15268028988154853\n",
+      "    mean_env_wait_ms: 1.2251785091633063\n",
+      "    mean_inference_ms: 4.628354002228403\n",
+      "    mean_raw_obs_processing_ms: 0.4042345731914658\n",
+      "  time_since_restore: 588.1606180667877\n",
+      "  time_this_iter_s: 15.376810312271118\n",
+      "  time_total_s: 588.1606180667877\n",
       "  timers:\n",
-      "    learn_throughput: 11054.503\n",
-      "    learn_time_ms: 14635.845\n",
-      "    sample_throughput: 18733.219\n",
-      "    sample_time_ms: 8636.637\n",
-      "    update_time_ms: 36.312\n",
-      "  timestamp: 1602167854\n",
+      "    learn_throughput: 6899.122\n",
+      "    learn_time_ms: 11725.55\n",
+      "    sample_throughput: 22216.641\n",
+      "    sample_time_ms: 3641.234\n",
+      "    update_time_ms: 28.207\n",
+      "  timestamp: 1602415037\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 38\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     38 |          588.161 | 3074048 |  240.062 |              288.899 |              117.687 |            822.446 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2431289640592\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.57511691972567\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 314\n",
-      "  episodes_total: 946\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3469.076923076923\n",
+      "    time_step_min: 3172\n",
+      "  date: 2020-10-11_11-17-33\n",
+      "  done: true\n",
+      "  episode_len_mean: 821.0094936708861\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 240.60125783147927\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0704583883285523\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006159011553972959\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.642860301903316\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009801473202449935\n",
       "        model: {}\n",
-      "        policy_loss: -0.01097527714446187\n",
-      "        total_loss: 18.48041114807129\n",
-      "        vf_explained_var: 0.9505600929260254\n",
-      "        vf_loss: 18.490771102905274\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.027483725188566104\n",
+      "        total_loss: 13.555409022739955\n",
+      "        vf_explained_var: 0.9839209318161011\n",
+      "        vf_loss: 13.580996922084264\n",
+      "    num_steps_sampled: 3154944\n",
+      "    num_steps_trained: 3154944\n",
+      "  iterations_since_restore: 39\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.67142857142857\n",
-      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    cpu_util_percent: 24.233333333333334\n",
+      "    gpu_util_percent0: 0.2744444444444445\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.739285714285716\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1637216679032345\n",
-      "    mean_env_wait_ms: 1.6595417244788717\n",
-      "    mean_inference_ms: 5.075327722233796\n",
-      "    mean_raw_obs_processing_ms: 0.443719930951552\n",
-      "  time_since_restore: 116.6165714263916\n",
-      "  time_this_iter_s: 23.197535276412964\n",
-      "  time_total_s: 116.6165714263916\n",
+      "    mean_action_processing_ms: 0.15254677791204402\n",
+      "    mean_env_wait_ms: 1.2258875543427181\n",
+      "    mean_inference_ms: 4.619694203955828\n",
+      "    mean_raw_obs_processing_ms: 0.4037668223539728\n",
+      "  time_since_restore: 603.536078453064\n",
+      "  time_this_iter_s: 15.375460386276245\n",
+      "  time_total_s: 603.536078453064\n",
       "  timers:\n",
-      "    learn_throughput: 11077.95\n",
-      "    learn_time_ms: 14604.868\n",
-      "    sample_throughput: 18764.263\n",
-      "    sample_time_ms: 8622.347\n",
-      "    update_time_ms: 48.444\n",
-      "  timestamp: 1602167877\n",
+      "    learn_throughput: 6895.914\n",
+      "    learn_time_ms: 11731.006\n",
+      "    sample_throughput: 22231.775\n",
+      "    sample_time_ms: 3638.756\n",
+      "    update_time_ms: 30.262\n",
+      "  timestamp: 1602415053\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3154944\n",
+      "  training_iteration: 39\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | TERMINATED |       |     39 |          603.536 | 3154944 |  240.601 |              288.899 |              117.687 |            821.009 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | TERMINATED |       |     39 |          603.536 | 3154944 |  240.601 |              288.899 |              117.687 |            821.009 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
+      "    return self._engine.get_loc(casted_key)\n",
+      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "The above exception was the direct cause of the following exception:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 57, in train_func\n",
+      "    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 92, in dataframe\n",
+      "    rows = self._retrieve_rows(metric=metric, mode=mode)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 254, in _retrieve_rows\n",
+      "    idx = df[metric].idxmin()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
+      "    indexer = self.columns.get_loc(key)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
+      "    raise KeyError(key) from err\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 11266\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_110715-y7fi985h/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_110715-y7fi985h/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpleasant-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/y7fi985h\u001b[0m\n",
+      "2020-10-11 11:17:44,012 - wandb.wandb_agent - INFO - Cleaning up finished run: y7fi985h\n",
+      "2020-10-11 11:17:44,320 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:17:44,320 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\trollout_fragment_length: 512\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "\tuse_gae: False\n",
+      "2020-10-11 11:17:44,324 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --rollout_fragment_length=512 --sgd_minibatch_size=12112 --use_gae=False\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwinter-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/m8f9dubo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ege8euj2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_111746-ege8euj2\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 11:17:48,204\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:17:49,338 - wandb.wandb_agent - INFO - Running runs: ['ege8euj2']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 32.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_658bd_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "2020-10-11 11:17:51,139\tERROR trial_runner.py:567 -- Trial PPO_jss_env_658bd_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::PPO.train()\u001b[39m (pid=52949, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
+      "    Trainer.__init__(self, config, env, logger_creator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
+      "    super().__init__(config, logger_creator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
+      "    self.setup(copy.deepcopy(self.config))\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
+      "    self._init(self.config, self.env_creator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 107, in _init\n",
+      "    validate_config(config)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/ppo/ppo.py\", line 127, in validate_config\n",
+      "    raise ValueError(\n",
+      "ValueError: Episode truncation is not supported without a value function. Consider setting batch_mode=complete_episodes.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 32.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_658bd_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_658bd_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_658bd_00000_0_2020-10-11_11-17-49/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_658bd_00000])\n",
+      "\u001b[2m\u001b[36m(pid=52949)\u001b[0m 2020-10-11 11:17:51,127\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 52730\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_111746-ege8euj2/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_111746-ege8euj2/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwinter-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ege8euj2\u001b[0m\n",
+      "2020-10-11 11:17:59,973 - wandb.wandb_agent - INFO - Cleaning up finished run: ege8euj2\n",
+      "2020-10-11 11:18:00,301 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:18:00,301 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\trollout_fragment_length: 512\n",
+      "\tsgd_minibatch_size: 14112\n",
+      "\tuse_gae: True\n",
+      "2020-10-11 11:18:00,305 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --rollout_fragment_length=512 --sgd_minibatch_size=14112 --use_gae=True\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfragrant-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/m8f9dubo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3ljhyuu6\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_111802-3ljhyuu6\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 11:18:04,196\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:18:05,322 - wandb.wandb_agent - INFO - Running runs: ['3ljhyuu6']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 32.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_6f133_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
       "\n",
-      "\n"
+      "\u001b[2m\u001b[36m(pid=54494)\u001b[0m 2020-10-11 11:18:07,106\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=54505)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54505)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54430)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54430)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54425)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54425)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54538)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54538)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54499)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54499)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54437)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54437)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54512)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54512)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54414)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54414)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54435)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54435)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54536)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54536)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54417)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54417)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54528)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54528)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54422)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54422)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54434)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54434)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54409)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54409)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54424)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54424)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54421)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54421)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54410)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54410)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54442)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54442)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54439)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54439)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54501)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54501)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54407)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54407)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54490)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54490)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54412)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54412)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54441)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54441)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54426)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54426)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54416)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54416)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54482)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54482)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54428)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54428)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54420)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54420)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54521)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54521)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54418)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54418)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54423)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54423)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent rfs7la4y"
+    "!wandb agent uy2qf72q"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/default_config-checkpoint.py b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
index c91ecc1..8fb0ebb 100644
--- a/JSS/.ipynb_checkpoints/default_config-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
@@ -12,7 +12,7 @@ default_config = {
     'num_envs_per_worker': 2,
     'rollout_fragment_length': 1024,
     'num_workers': mp.cpu_count() - 1,
-    'sgd_minibatch_size': 16112,
+    'sgd_minibatch_size': 12112,
     'evaluation_interval': None,
     'metrics_smoothing_episodes': 100000,
     'layer_size': 1024,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 0.0,
+    "entropy_coeff": 1e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/.ipynb_checkpoints/train-checkpoint.py b/JSS/.ipynb_checkpoints/train-checkpoint.py
index 568cc37..726922e 100644
--- a/JSS/.ipynb_checkpoints/train-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train-checkpoint.py
@@ -54,7 +54,7 @@ def train_func():
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
-    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
+    result = analysis.dataframe(metric='episode_reward_max', mode='max').to_dict('index')[0]
     wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
     if result['custom_metrics/time_step_max'] != float('inf'):
         wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index 73bfae9..d746b1e 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
@@ -29,13 +29,29 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "\n",
+    "2\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
     "import wandb\n",
     "\n",
-    "\n",
+    "'''\n",
+    "            'lr': {\n",
+    "                'values': [5e-5, 1e-5]\n",
+    "            },\n",
+    "            'lambda': {\n",
+    "                'values': [0.90, 0.95, 1.0]\n",
+    "            },\n",
+    "            'clip_param': {\n",
+    "                'values': [0.2, 0.3, 0.4]\n",
+    "            },\n",
+    "            'num_sgd_iter': {\n",
+    "                'values': [30, 35, 40]\n",
+    "            },\n",
+    "            'entropy_coeff': {\n",
+    "                'values': [0.0, 1e-4]\n",
+    "            }\n",
+    "'''\n",
     "\n",
     "if __name__ == \"__main__\":\n",
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
@@ -48,61 +64,36 @@
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'num_envs_per_worker': {\n",
-    "                'values': [4, 6, 8]\n",
-    "            },\n",
-    "            'sgd_minibatch_size': {\n",
-    "                'values': [2**13, 2**13 + 2**12, 2**14, 2**14 + 2**13]\n",
-    "            },\n",
     "            'lr': {\n",
-    "                'values': [5e-5, 1e-5]\n",
+    "                'values': [1e-4, 5e-5]\n",
     "            },\n",
-    "            'lambda': {\n",
-    "                'values': [0.90, 0.95, 1.0]\n",
+    "            'use_gae': {\n",
+    "                'values': [False, True]\n",
     "            },\n",
-    "            'clip_param': {\n",
-    "                'values': [0.2, 0.3, 0.4]\n",
+    "            'sgd_minibatch_size': {\n",
+    "                'values': [12112, 14112]\n",
     "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [30, 40]\n",
+    "            'rollout_fragment_length': {\n",
+    "                'values': [512, 768, 1024]\n",
     "            },\n",
+    "            'num_envs_per_worker': {\n",
+    "                'values': [2, 3, 4]\n",
+    "            }\n",
     "        }\n",
     "    }"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
-     "ename": "CommError",
-     "evalue": "Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null.",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mException\u001b[0m: {'message': 'Variable \"entityName\" has invalid value null.\\nExpected type \"String!\", found null.', 'locations': [{'line': 1, 'column': 70}]}",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-10-25143ac4787e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RLLIB_SWEEP_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mwandb_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Create sweep with ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0msweep_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sweep_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upsertSweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmutation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmutation_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     variable_values={\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_print\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mCommError\u001b[0m: Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null."
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: uy2qf72q\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/uy2qf72q\n"
      ]
     }
    ],
@@ -112,7 +103,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [
     {
@@ -120,7380 +111,3729 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "2020-10-11 11:07:13,020 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-11 11:07:13,323 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:07:13,323 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "\trollout_fragment_length: 512\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "\tuse_gae: True\n",
+      "2020-10-11 11:07:13,326 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --rollout_fragment_length=512 --sgd_minibatch_size=12112 --use_gae=True\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpleasant-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/m8f9dubo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/y7fi985h\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_110715-y7fi985h\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:07:17,351\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:07:18,342 - wandb.wandb_agent - INFO - Running runs: ['y7fi985h']\n",
       "== Status ==\n",
-      "Memory usage on this node: 77.4/754.6 GiB\n",
+      "Memory usage on this node: 32.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-04-38\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "\u001b[2m\u001b[36m(pid=11517)\u001b[0m 2020-10-11 11:07:20,307\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=11458)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11409)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11409)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11378)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11378)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11439)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11439)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11482)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11499)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11505)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11505)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11424)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11424)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11397)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11397)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11460)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11460)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11403)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11403)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11417)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11417)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11463)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11463)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11400)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11400)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11465)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11465)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11420)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11420)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11415)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11415)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11422)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11422)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11419)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11419)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11440)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11440)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11392)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11392)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11442)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11442)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11405)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11405)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11454)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11454)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11443)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11443)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
+      "  custom_metrics: {}\n",
+      "  date: 2020-10-11_11-07-43\n",
+      "  done: false\n",
+      "  episode_len_mean: .nan\n",
+      "  episode_reward_max: .nan\n",
+      "  episode_reward_mean: .nan\n",
+      "  episode_reward_min: .nan\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 0\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.2355760846819197\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010150781566543239\n",
+      "        model: {}\n",
+      "        policy_loss: -0.034750696537750106\n",
+      "        total_loss: 483.26939610072543\n",
+      "        vf_explained_var: 0.12598323822021484\n",
+      "        vf_loss: 483.30223301478793\n",
+      "    num_steps_sampled: 80896\n",
+      "    num_steps_trained: 80896\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.00833333333333\n",
-      "    gpu_util_percent0: 0.3225\n",
+      "    cpu_util_percent: 27.990476190476194\n",
+      "    gpu_util_percent0: 0.3447619047619047\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 10.413888888888891\n",
-      "    vram_util_percent0: 0.27462328267920266\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    gpu_util_percent2: 0.0004761904761904762\n",
+      "    ram_util_percent: 6.061904761904761\n",
+      "    vram_util_percent0: 0.18846928735416763\n",
+      "    vram_util_percent1: 0.0009075233687267446\n",
+      "    vram_util_percent2: 0.0009075233687267446\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.18350994266746734\n",
-      "    mean_env_wait_ms: 1.6865222444501913\n",
-      "    mean_inference_ms: 5.985971555624452\n",
-      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
-      "  time_since_restore: 30.92910385131836\n",
-      "  time_this_iter_s: 30.92910385131836\n",
-      "  time_total_s: 30.92910385131836\n",
+      "  sampler_perf: {}\n",
+      "  time_since_restore: 17.069397449493408\n",
+      "  time_this_iter_s: 17.069397449493408\n",
+      "  time_total_s: 17.069397449493408\n",
       "  timers:\n",
-      "    learn_throughput: 7789.468\n",
-      "    learn_time_ms: 20770.611\n",
-      "    sample_throughput: 16046.653\n",
-      "    sample_time_ms: 10082.601\n",
-      "    update_time_ms: 36.409\n",
-      "  timestamp: 1602165878\n",
+      "    learn_throughput: 6812.619\n",
+      "    learn_time_ms: 11874.434\n",
+      "    sample_throughput: 15793.705\n",
+      "    sample_time_ms: 5122.041\n",
+      "    update_time_ms: 46.92\n",
+      "  timestamp: 1602414463\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 80896\n",
       "  training_iteration: 1\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 46.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      1 |          17.0694 | 80896 |      nan |                  nan |                  nan |                nan |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-05-08\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3621.1951219512193\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-07-59\n",
       "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 890.7215189873418\n",
+      "  episode_reward_max: 264.20202020201947\n",
+      "  episode_reward_mean: 215.95211609768555\n",
+      "  episode_reward_min: 129.0505050505048\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.104918122291565\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010646762725497996\n",
       "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        policy_loss: -0.02715139969119004\n",
+      "        total_loss: 541.7598702566964\n",
+      "        vf_explained_var: 0.5573452711105347\n",
+      "        vf_loss: 541.7850167410714\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.90294117647059\n",
-      "    gpu_util_percent0: 0.26941176470588235\n",
+      "    cpu_util_percent: 26.663157894736845\n",
+      "    gpu_util_percent0: 0.35105263157894734\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.747058823529413\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.178947368421054\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17676173480204843\n",
-      "    mean_env_wait_ms: 1.6752662514608032\n",
-      "    mean_inference_ms: 5.6785297305935405\n",
-      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
-      "  time_since_restore: 59.91080617904663\n",
-      "  time_this_iter_s: 28.98170232772827\n",
-      "  time_total_s: 59.91080617904663\n",
+      "    mean_action_processing_ms: 0.17199406472206408\n",
+      "    mean_env_wait_ms: 1.2088235111360235\n",
+      "    mean_inference_ms: 5.708397346795727\n",
+      "    mean_raw_obs_processing_ms: 0.4642650336901248\n",
+      "  time_since_restore: 33.077258348464966\n",
+      "  time_this_iter_s: 16.007860898971558\n",
+      "  time_total_s: 33.077258348464966\n",
       "  timers:\n",
-      "    learn_throughput: 7835.536\n",
-      "    learn_time_ms: 20648.493\n",
-      "    sample_throughput: 17536.73\n",
-      "    sample_time_ms: 9225.893\n",
-      "    update_time_ms: 38.294\n",
-      "  timestamp: 1602165908\n",
+      "    learn_throughput: 6884.162\n",
+      "    learn_time_ms: 11751.032\n",
+      "    sample_throughput: 17143.081\n",
+      "    sample_time_ms: 4718.872\n",
+      "    update_time_ms: 36.16\n",
+      "  timestamp: 1602414479\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 161792\n",
       "  training_iteration: 2\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      2 |          33.0773 | 161792 |  215.952 |              264.202 |              129.051 |            890.722 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-05-37\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3621.1951219512193\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-08-14\n",
       "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 890.7215189873418\n",
+      "  episode_reward_max: 264.20202020201947\n",
+      "  episode_reward_mean: 215.95211609768555\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1451326949255807\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013103859898235117\n",
       "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        policy_loss: -0.03772170841693878\n",
+      "        total_loss: 61.807167053222656\n",
+      "        vf_explained_var: 0.3047725260257721\n",
+      "        vf_loss: 61.842381068638396\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.057142857142864\n",
-      "    gpu_util_percent0: 0.2717142857142857\n",
+      "    cpu_util_percent: 25.03684210526316\n",
+      "    gpu_util_percent0: 0.3068421052631579\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762857142857143\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.205263157894738\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17253118731808845\n",
-      "    mean_env_wait_ms: 1.669123154241675\n",
-      "    mean_inference_ms: 5.508714332828136\n",
-      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
-      "  time_since_restore: 89.00577521324158\n",
-      "  time_this_iter_s: 29.094969034194946\n",
-      "  time_total_s: 89.00577521324158\n",
+      "    mean_action_processing_ms: 0.17199406472206408\n",
+      "    mean_env_wait_ms: 1.2088235111360235\n",
+      "    mean_inference_ms: 5.708397346795727\n",
+      "    mean_raw_obs_processing_ms: 0.4642650336901248\n",
+      "  time_since_restore: 48.5854651927948\n",
+      "  time_this_iter_s: 15.508206844329834\n",
+      "  time_total_s: 48.5854651927948\n",
       "  timers:\n",
-      "    learn_throughput: 7852.583\n",
-      "    learn_time_ms: 20603.665\n",
-      "    sample_throughput: 18018.223\n",
-      "    sample_time_ms: 8979.354\n",
-      "    update_time_ms: 41.291\n",
-      "  timestamp: 1602165937\n",
+      "    learn_throughput: 6932.543\n",
+      "    learn_time_ms: 11669.022\n",
+      "    sample_throughput: 18134.025\n",
+      "    sample_time_ms: 4461.006\n",
+      "    update_time_ms: 31.075\n",
+      "  timestamp: 1602414494\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 242688\n",
       "  training_iteration: 3\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      3 |          48.5855 | 242688 |  215.952 |              264.202 |              129.051 |            890.722 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-06-05\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3618.8718861209964\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-08-30\n",
       "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 879.4493670886076\n",
+      "  episode_reward_max: 268.4444444444444\n",
+      "  episode_reward_mean: 217.9453075054339\n",
+      "  episode_reward_min: 129.0505050505048\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1018210308892387\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011968836055270262\n",
       "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        policy_loss: -0.030419912987521718\n",
+      "        total_loss: 338.2612871442522\n",
+      "        vf_explained_var: 0.7406534552574158\n",
+      "        vf_loss: 338.2894199916295\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.938235294117646\n",
-      "    gpu_util_percent0: 0.24941176470588236\n",
+      "    cpu_util_percent: 23.910526315789475\n",
+      "    gpu_util_percent0: 0.4221052631578948\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.205263157894738\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16972262222291365\n",
-      "    mean_env_wait_ms: 1.6663911084469907\n",
-      "    mean_inference_ms: 5.381286213374226\n",
-      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
-      "  time_since_restore: 117.6076283454895\n",
-      "  time_this_iter_s: 28.601853132247925\n",
-      "  time_total_s: 117.6076283454895\n",
+      "    mean_action_processing_ms: 0.1664683872326604\n",
+      "    mean_env_wait_ms: 1.2090395135359495\n",
+      "    mean_inference_ms: 5.448400692912778\n",
+      "    mean_raw_obs_processing_ms: 0.44806285347677643\n",
+      "  time_since_restore: 64.0004415512085\n",
+      "  time_this_iter_s: 15.414976358413696\n",
+      "  time_total_s: 64.0004415512085\n",
       "  timers:\n",
-      "    learn_throughput: 7898.804\n",
-      "    learn_time_ms: 20483.102\n",
-      "    sample_throughput: 18320.006\n",
-      "    sample_time_ms: 8831.438\n",
-      "    update_time_ms: 41.53\n",
-      "  timestamp: 1602165965\n",
+      "    learn_throughput: 6942.391\n",
+      "    learn_time_ms: 11652.47\n",
+      "    sample_throughput: 18954.078\n",
+      "    sample_time_ms: 4268.0\n",
+      "    update_time_ms: 31.145\n",
+      "  timestamp: 1602414510\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 323584\n",
       "  training_iteration: 4\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      4 |          64.0004 | 323584 |  217.945 |              268.444 |              129.051 |            879.449 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-06-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3619.0141843971633\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-11_11-08-45\n",
       "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 879.3028391167193\n",
+      "  episode_reward_max: 268.4444444444444\n",
+      "  episode_reward_mean: 217.9397125832455\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 1\n",
+      "  episodes_total: 317\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0629650694983346\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013246477182422365\n",
       "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        policy_loss: -0.0353440453431436\n",
+      "        total_loss: 32.55528858729771\n",
+      "        vf_explained_var: 0.8335528373718262\n",
+      "        vf_loss: 32.588090079171316\n",
+      "    num_steps_sampled: 404480\n",
+      "    num_steps_trained: 404480\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.05\n",
-      "    gpu_util_percent0: 0.27676470588235297\n",
+      "    cpu_util_percent: 24.61666666666666\n",
+      "    gpu_util_percent0: 0.3338888888888889\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.222222222222222\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1668569945682094\n",
-      "    mean_env_wait_ms: 1.6661518036410352\n",
-      "    mean_inference_ms: 5.245339771382172\n",
-      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
-      "  time_since_restore: 146.34429287910461\n",
-      "  time_this_iter_s: 28.736664533615112\n",
-      "  time_total_s: 146.34429287910461\n",
+      "    mean_action_processing_ms: 0.1664021890297938\n",
+      "    mean_env_wait_ms: 1.2090652828885642\n",
+      "    mean_inference_ms: 5.445749303343484\n",
+      "    mean_raw_obs_processing_ms: 0.44791848390135747\n",
+      "  time_since_restore: 79.37057852745056\n",
+      "  time_this_iter_s: 15.370136976242065\n",
+      "  time_total_s: 79.37057852745056\n",
       "  timers:\n",
-      "    learn_throughput: 7912.652\n",
-      "    learn_time_ms: 20447.253\n",
-      "    sample_throughput: 18556.235\n",
-      "    sample_time_ms: 8719.01\n",
-      "    update_time_ms: 53.489\n",
-      "  timestamp: 1602165994\n",
+      "    learn_throughput: 6943.782\n",
+      "    learn_time_ms: 11650.135\n",
+      "    sample_throughput: 19496.779\n",
+      "    sample_time_ms: 4149.198\n",
+      "    update_time_ms: 29.133\n",
+      "  timestamp: 1602414525\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 404480\n",
       "  training_iteration: 5\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      5 |          79.3706 | 404480 |   217.94 |              268.444 |              129.051 |            879.303 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-07-03\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3614.5466970387242\n",
+      "    time_step_min: 3301\n",
+      "  date: 2020-10-11_11-09-01\n",
       "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 874.873417721519\n",
+      "  episode_reward_max: 268.4444444444444\n",
+      "  episode_reward_mean: 218.84496867408242\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 157\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1305710928780692\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.00940956494637898\n",
       "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        policy_loss: -0.02775775800858225\n",
+      "        total_loss: 86.53898402622768\n",
+      "        vf_explained_var: 0.8763986229896545\n",
+      "        vf_loss: 86.56497410365513\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.087878787878783\n",
-      "    gpu_util_percent0: 0.2751515151515152\n",
+      "    cpu_util_percent: 23.37368421052631\n",
+      "    gpu_util_percent0: 0.3310526315789474\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751515151515152\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.1947368421052635\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16521363319543925\n",
-      "    mean_env_wait_ms: 1.6677695579501226\n",
-      "    mean_inference_ms: 5.160918708210536\n",
-      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
-      "  time_since_restore: 174.83844447135925\n",
-      "  time_this_iter_s: 28.49415159225464\n",
-      "  time_total_s: 174.83844447135925\n",
+      "    mean_action_processing_ms: 0.16330449318082624\n",
+      "    mean_env_wait_ms: 1.2084176545278669\n",
+      "    mean_inference_ms: 5.27002022088971\n",
+      "    mean_raw_obs_processing_ms: 0.43788779842756653\n",
+      "  time_since_restore: 94.90622282028198\n",
+      "  time_this_iter_s: 15.535644292831421\n",
+      "  time_total_s: 94.90622282028198\n",
       "  timers:\n",
-      "    learn_throughput: 7937.482\n",
-      "    learn_time_ms: 20383.289\n",
-      "    sample_throughput: 18693.433\n",
-      "    sample_time_ms: 8655.018\n",
-      "    update_time_ms: 51.581\n",
-      "  timestamp: 1602166023\n",
+      "    learn_throughput: 6931.717\n",
+      "    learn_time_ms: 11670.414\n",
+      "    sample_throughput: 19865.372\n",
+      "    sample_time_ms: 4072.212\n",
+      "    update_time_ms: 30.704\n",
+      "  timestamp: 1602414541\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 485376\n",
       "  training_iteration: 6\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      6 |          94.9062 | 485376 |  218.845 |              268.444 |              129.051 |            874.873 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-07-31\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3599.7512605042016\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-09-16\n",
       "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 870.7253968253968\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 221.0759980759979\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 156\n",
+      "  episodes_total: 630\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0338162354060583\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01128895820251533\n",
       "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        policy_loss: -0.030630421425615038\n",
+      "        total_loss: 76.87986101422992\n",
+      "        vf_explained_var: 0.9067110419273376\n",
+      "        vf_loss: 76.90833718436105\n",
+      "    num_steps_sampled: 566272\n",
+      "    num_steps_trained: 566272\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.423529411764708\n",
-      "    gpu_util_percent0: 0.25617647058823534\n",
+      "    cpu_util_percent: 23.899999999999995\n",
+      "    gpu_util_percent0: 0.34444444444444444\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16428938352115002\n",
-      "    mean_env_wait_ms: 1.6688146539398103\n",
-      "    mean_inference_ms: 5.1135213379920055\n",
-      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
-      "  time_since_restore: 203.33799719810486\n",
-      "  time_this_iter_s: 28.499552726745605\n",
-      "  time_total_s: 203.33799719810486\n",
+      "    mean_action_processing_ms: 0.16143699532427172\n",
+      "    mean_env_wait_ms: 1.2088684311529978\n",
+      "    mean_inference_ms: 5.161913655684243\n",
+      "    mean_raw_obs_processing_ms: 0.4322594420046009\n",
+      "  time_since_restore: 110.28288292884827\n",
+      "  time_this_iter_s: 15.376660108566284\n",
+      "  time_total_s: 110.28288292884827\n",
       "  timers:\n",
-      "    learn_throughput: 7953.152\n",
-      "    learn_time_ms: 20343.13\n",
-      "    sample_throughput: 18800.381\n",
-      "    sample_time_ms: 8605.783\n",
-      "    update_time_ms: 48.851\n",
-      "  timestamp: 1602166051\n",
+      "    learn_throughput: 6934.629\n",
+      "    learn_time_ms: 11665.512\n",
+      "    sample_throughput: 20147.728\n",
+      "    sample_time_ms: 4015.143\n",
+      "    update_time_ms: 30.898\n",
+      "  timestamp: 1602414556\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 566272\n",
       "  training_iteration: 7\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      7 |          110.283 | 566272 |  221.076 |              282.687 |              129.051 |            870.725 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-00\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3600.165829145729\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-09-32\n",
       "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 870.8433544303797\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 221.01516749776226\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 2\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0777911799294608\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012940970515566213\n",
       "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        policy_loss: -0.03934905957430601\n",
+      "        total_loss: 11.274031366620745\n",
+      "        vf_explained_var: 0.8349117636680603\n",
+      "        vf_loss: 11.310900688171387\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.724242424242426\n",
-      "    gpu_util_percent0: 0.2678787878787879\n",
+      "    cpu_util_percent: 22.973684210526315\n",
+      "    gpu_util_percent0: 0.3068421052631579\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16348854866217513\n",
-      "    mean_env_wait_ms: 1.6700574598453726\n",
-      "    mean_inference_ms: 5.072164794599845\n",
-      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
-      "  time_since_restore: 231.6390438079834\n",
-      "  time_this_iter_s: 28.30104660987854\n",
-      "  time_total_s: 231.6390438079834\n",
+      "    mean_action_processing_ms: 0.1614256084534045\n",
+      "    mean_env_wait_ms: 1.2089110374403544\n",
+      "    mean_inference_ms: 5.160506855743884\n",
+      "    mean_raw_obs_processing_ms: 0.4322031186244616\n",
+      "  time_since_restore: 125.68149065971375\n",
+      "  time_this_iter_s: 15.398607730865479\n",
+      "  time_total_s: 125.68149065971375\n",
       "  timers:\n",
-      "    learn_throughput: 7959.464\n",
-      "    learn_time_ms: 20326.997\n",
-      "    sample_throughput: 18968.066\n",
-      "    sample_time_ms: 8529.705\n",
-      "    update_time_ms: 47.225\n",
-      "  timestamp: 1602166080\n",
+      "    learn_throughput: 6932.158\n",
+      "    learn_time_ms: 11669.671\n",
+      "    sample_throughput: 20402.25\n",
+      "    sample_time_ms: 3965.053\n",
+      "    update_time_ms: 32.067\n",
+      "  timestamp: 1602414572\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 647168\n",
       "  training_iteration: 8\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      8 |          125.681 | 647168 |  221.015 |              282.687 |              129.051 |            870.843 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-28\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3583.548344370861\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-09-47\n",
       "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 864.9392405063292\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 223.6602096918551\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0281649146761214\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010988853871822357\n",
       "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        policy_loss: -0.03038667674575533\n",
+      "        total_loss: 99.28263092041016\n",
+      "        vf_explained_var: 0.9136572480201721\n",
+      "        vf_loss: 99.31092398507255\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.59705882352941\n",
-      "    gpu_util_percent0: 0.25941176470588234\n",
+      "    cpu_util_percent: 24.577777777777776\n",
+      "    gpu_util_percent0: 0.35444444444444445\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.162284443845516\n",
-      "    mean_env_wait_ms: 1.6727489665801578\n",
-      "    mean_inference_ms: 5.009821132584934\n",
-      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
-      "  time_since_restore: 259.97689414024353\n",
-      "  time_this_iter_s: 28.337850332260132\n",
-      "  time_total_s: 259.97689414024353\n",
+      "    mean_action_processing_ms: 0.15995345913671608\n",
+      "    mean_env_wait_ms: 1.2100571945889735\n",
+      "    mean_inference_ms: 5.073819843280334\n",
+      "    mean_raw_obs_processing_ms: 0.42774308899470204\n",
+      "  time_since_restore: 140.99153351783752\n",
+      "  time_this_iter_s: 15.31004285812378\n",
+      "  time_total_s: 140.99153351783752\n",
       "  timers:\n",
-      "    learn_throughput: 7968.61\n",
-      "    learn_time_ms: 20303.667\n",
-      "    sample_throughput: 19067.411\n",
-      "    sample_time_ms: 8485.263\n",
-      "    update_time_ms: 45.663\n",
-      "  timestamp: 1602166108\n",
+      "    learn_throughput: 6935.861\n",
+      "    learn_time_ms: 11663.441\n",
+      "    sample_throughput: 20591.808\n",
+      "    sample_time_ms: 3928.553\n",
+      "    update_time_ms: 31.2\n",
+      "  timestamp: 1602414587\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 728064\n",
       "  training_iteration: 9\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |      9 |          140.992 | 728064 |   223.66 |              282.687 |              129.051 |            864.939 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-57\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3581.105128205128\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-02\n",
       "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 863.6822085889571\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 224.0084898060356\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 25\n",
+      "  episodes_total: 815\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.987507028239114\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013111596660954612\n",
       "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        policy_loss: -0.03521772553878171\n",
+      "        total_loss: 20.77414403642927\n",
+      "        vf_explained_var: 0.9506732225418091\n",
+      "        vf_loss: 20.806838989257812\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.339393939393936\n",
-      "    gpu_util_percent0: 0.29575757575757583\n",
+      "    cpu_util_percent: 23.28421052631579\n",
+      "    gpu_util_percent0: 0.3494736842105264\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16170883141459513\n",
-      "    mean_env_wait_ms: 1.6746347609608598\n",
-      "    mean_inference_ms: 4.978956771385591\n",
-      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
-      "  time_since_restore: 288.5126984119415\n",
-      "  time_this_iter_s: 28.535804271697998\n",
-      "  time_total_s: 288.5126984119415\n",
+      "    mean_action_processing_ms: 0.15973198961384183\n",
+      "    mean_env_wait_ms: 1.2103405669664478\n",
+      "    mean_inference_ms: 5.061434809621857\n",
+      "    mean_raw_obs_processing_ms: 0.42702146120421813\n",
+      "  time_since_restore: 156.33395624160767\n",
+      "  time_this_iter_s: 15.342422723770142\n",
+      "  time_total_s: 156.33395624160767\n",
       "  timers:\n",
-      "    learn_throughput: 7972.454\n",
-      "    learn_time_ms: 20293.877\n",
-      "    sample_throughput: 19124.35\n",
-      "    sample_time_ms: 8460.0\n",
-      "    update_time_ms: 44.735\n",
-      "  timestamp: 1602166137\n",
+      "    learn_throughput: 6938.897\n",
+      "    learn_time_ms: 11658.337\n",
+      "    sample_throughput: 20727.776\n",
+      "    sample_time_ms: 3902.782\n",
+      "    update_time_ms: 30.607\n",
+      "  timestamp: 1602414602\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 808960\n",
       "  training_iteration: 10\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     10 |          156.334 | 808960 |  224.008 |              282.687 |              129.051 |            863.682 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-25\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3571.9802847754654\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-18\n",
       "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 859.967299578059\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 225.29475131057393\n",
+      "  episode_reward_min: 129.0505050505048\n",
+      "  episodes_this_iter: 133\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.045826860836574\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009954532741435937\n",
       "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        policy_loss: -0.029595830610820224\n",
+      "        total_loss: 18.947863715035574\n",
+      "        vf_explained_var: 0.9571961164474487\n",
+      "        vf_loss: 18.975573131016322\n",
+      "    num_steps_sampled: 889856\n",
+      "    num_steps_trained: 889856\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.45151515151515\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 24.211111111111112\n",
+      "    gpu_util_percent0: 0.3644444444444444\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.194444444444445\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125382205207386\n",
-      "    mean_env_wait_ms: 1.6761243985903949\n",
-      "    mean_inference_ms: 4.954596343237678\n",
-      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
-      "  time_since_restore: 316.5878527164459\n",
-      "  time_this_iter_s: 28.075154304504395\n",
-      "  time_total_s: 316.5878527164459\n",
+      "    mean_action_processing_ms: 0.15879813645463797\n",
+      "    mean_env_wait_ms: 1.211128149274603\n",
+      "    mean_inference_ms: 5.005509192438234\n",
+      "    mean_raw_obs_processing_ms: 0.42413205982647995\n",
+      "  time_since_restore: 171.7176637649536\n",
+      "  time_this_iter_s: 15.383707523345947\n",
+      "  time_total_s: 171.7176637649536\n",
       "  timers:\n",
-      "    learn_throughput: 8000.406\n",
-      "    learn_time_ms: 20222.974\n",
-      "    sample_throughput: 19629.04\n",
-      "    sample_time_ms: 8242.482\n",
-      "    update_time_ms: 45.435\n",
-      "  timestamp: 1602166165\n",
+      "    learn_throughput: 6953.498\n",
+      "    learn_time_ms: 11633.857\n",
+      "    sample_throughput: 21513.646\n",
+      "    sample_time_ms: 3760.218\n",
+      "    update_time_ms: 28.069\n",
+      "  timestamp: 1602414618\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 889856\n",
       "  training_iteration: 11\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     11 |          171.718 | 889856 |  225.295 |              282.687 |              129.051 |            859.967 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-54\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3566.089635854342\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-33\n",
       "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 856.50904159132\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 226.2248707691744\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9601052488599505\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012055230060858386\n",
       "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        policy_loss: -0.030359721343432153\n",
+      "        total_loss: 37.07370104108538\n",
+      "        vf_explained_var: 0.9558514952659607\n",
+      "        vf_loss: 37.10174560546875\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.993939393939392\n",
-      "    gpu_util_percent0: 0.26969696969696966\n",
+      "    cpu_util_percent: 23.46315789473684\n",
+      "    gpu_util_percent0: 0.3863157894736842\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757575757575758\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16085250209822033\n",
-      "    mean_env_wait_ms: 1.6775510346401423\n",
-      "    mean_inference_ms: 4.932401985457557\n",
-      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
-      "  time_since_restore: 345.2145109176636\n",
-      "  time_this_iter_s: 28.62665820121765\n",
-      "  time_total_s: 345.2145109176636\n",
+      "    mean_action_processing_ms: 0.15789295050711372\n",
+      "    mean_env_wait_ms: 1.2122332529673068\n",
+      "    mean_inference_ms: 4.951915592301066\n",
+      "    mean_raw_obs_processing_ms: 0.4213907139795608\n",
+      "  time_since_restore: 187.1134786605835\n",
+      "  time_this_iter_s: 15.395814895629883\n",
+      "  time_total_s: 187.1134786605835\n",
       "  timers:\n",
-      "    learn_throughput: 8013.686\n",
-      "    learn_time_ms: 20189.46\n",
-      "    sample_throughput: 19635.364\n",
-      "    sample_time_ms: 8239.827\n",
-      "    update_time_ms: 45.402\n",
-      "  timestamp: 1602166194\n",
+      "    learn_throughput: 6954.196\n",
+      "    learn_time_ms: 11632.689\n",
+      "    sample_throughput: 21859.474\n",
+      "    sample_time_ms: 3700.729\n",
+      "    update_time_ms: 27.535\n",
+      "  timestamp: 1602414633\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 970752\n",
       "  training_iteration: 12\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     12 |          187.113 | 970752 |  226.225 |              282.687 |              117.687 |            856.509 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-22\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3566.089635854342\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-11_11-10-49\n",
       "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 856.50904159132\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 226.2248707691744\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9797454476356506\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012896751053631306\n",
       "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        policy_loss: -0.041537076767001836\n",
+      "        total_loss: 7.74065773827689\n",
+      "        vf_explained_var: 0.9532109498977661\n",
+      "        vf_loss: 7.779713494437082\n",
+      "    num_steps_sampled: 1051648\n",
+      "    num_steps_trained: 1051648\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.370588235294115\n",
-      "    gpu_util_percent0: 0.2747058823529412\n",
+      "    cpu_util_percent: 23.205555555555556\n",
+      "    gpu_util_percent0: 0.36388888888888893\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16017287678084888\n",
-      "    mean_env_wait_ms: 1.6802277086992836\n",
-      "    mean_inference_ms: 4.89439148640374\n",
-      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
-      "  time_since_restore: 373.45997977256775\n",
-      "  time_this_iter_s: 28.245468854904175\n",
-      "  time_total_s: 373.45997977256775\n",
+      "    mean_action_processing_ms: 0.1578929505071137\n",
+      "    mean_env_wait_ms: 1.2122332529673068\n",
+      "    mean_inference_ms: 4.951915592301066\n",
+      "    mean_raw_obs_processing_ms: 0.42139071397956074\n",
+      "  time_since_restore: 202.41565418243408\n",
+      "  time_this_iter_s: 15.302175521850586\n",
+      "  time_total_s: 202.41565418243408\n",
       "  timers:\n",
-      "    learn_throughput: 8026.419\n",
-      "    learn_time_ms: 20157.433\n",
-      "    sample_throughput: 19763.446\n",
-      "    sample_time_ms: 8186.427\n",
-      "    update_time_ms: 44.475\n",
-      "  timestamp: 1602166222\n",
+      "    learn_throughput: 6946.916\n",
+      "    learn_time_ms: 11644.879\n",
+      "    sample_throughput: 22062.043\n",
+      "    sample_time_ms: 3666.75\n",
+      "    update_time_ms: 28.95\n",
+      "  timestamp: 1602414649\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 1051648\n",
       "  training_iteration: 13\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     13 |          202.416 | 1051648 |  226.225 |              282.687 |              117.687 |            856.509 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-50\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3559.820179007323\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-04\n",
       "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 853.4018987341772\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 227.41044943101886\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9573245303971427\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010491540655493736\n",
       "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        policy_loss: -0.02854319236108235\n",
+      "        total_loss: 28.880344118390763\n",
+      "        vf_explained_var: 0.9712379574775696\n",
+      "        vf_loss: 28.906884329659597\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.312121212121212\n",
-      "    gpu_util_percent0: 0.26151515151515153\n",
+      "    cpu_util_percent: 23.321052631578947\n",
+      "    gpu_util_percent0: 0.2831578947368421\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.772727272727275\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15988462752258317\n",
-      "    mean_env_wait_ms: 1.6814425515145586\n",
-      "    mean_inference_ms: 4.878041025826835\n",
-      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
-      "  time_since_restore: 401.80727195739746\n",
-      "  time_this_iter_s: 28.347292184829712\n",
-      "  time_total_s: 401.80727195739746\n",
+      "    mean_action_processing_ms: 0.1571431737437744\n",
+      "    mean_env_wait_ms: 1.213288599347626\n",
+      "    mean_inference_ms: 4.906653870888696\n",
+      "    mean_raw_obs_processing_ms: 0.4189866891285491\n",
+      "  time_since_restore: 217.90839791297913\n",
+      "  time_this_iter_s: 15.492743730545044\n",
+      "  time_total_s: 217.90839791297913\n",
       "  timers:\n",
-      "    learn_throughput: 8023.866\n",
-      "    learn_time_ms: 20163.846\n",
-      "    sample_throughput: 19841.783\n",
-      "    sample_time_ms: 8154.106\n",
-      "    update_time_ms: 44.12\n",
-      "  timestamp: 1602166250\n",
+      "    learn_throughput: 6942.93\n",
+      "    learn_time_ms: 11651.565\n",
+      "    sample_throughput: 22027.115\n",
+      "    sample_time_ms: 3672.564\n",
+      "    update_time_ms: 29.496\n",
+      "  timestamp: 1602414664\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 1132544\n",
       "  training_iteration: 14\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     14 |          217.908 | 1132544 |   227.41 |              282.687 |              117.687 |            853.402 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-19\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3553.6249062265565\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-20\n",
       "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 851.2441520467836\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 228.1558125110755\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 104\n",
+      "  episodes_total: 1368\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9227380497114999\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012362753839365073\n",
       "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        policy_loss: -0.03274130182606833\n",
+      "        total_loss: 24.246925626482284\n",
+      "        vf_explained_var: 0.9645282626152039\n",
+      "        vf_loss: 24.277286802019393\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.59705882352941\n",
-      "    gpu_util_percent0: 0.27\n",
+      "    cpu_util_percent: 23.694444444444443\n",
+      "    gpu_util_percent0: 0.37611111111111106\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15962256586295442\n",
-      "    mean_env_wait_ms: 1.6825632050368664\n",
-      "    mean_inference_ms: 4.862887505621167\n",
-      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
-      "  time_since_restore: 430.180118560791\n",
-      "  time_this_iter_s: 28.372846603393555\n",
-      "  time_total_s: 430.180118560791\n",
+      "    mean_action_processing_ms: 0.15669643186371113\n",
+      "    mean_env_wait_ms: 1.213879770455507\n",
+      "    mean_inference_ms: 4.880938505249473\n",
+      "    mean_raw_obs_processing_ms: 0.41758802125738176\n",
+      "  time_since_restore: 233.22773909568787\n",
+      "  time_this_iter_s: 15.31934118270874\n",
+      "  time_total_s: 233.22773909568787\n",
       "  timers:\n",
-      "    learn_throughput: 8029.244\n",
-      "    learn_time_ms: 20150.342\n",
-      "    sample_throughput: 19898.49\n",
-      "    sample_time_ms: 8130.868\n",
-      "    update_time_ms: 37.742\n",
-      "  timestamp: 1602166279\n",
+      "    learn_throughput: 6940.425\n",
+      "    learn_time_ms: 11655.771\n",
+      "    sample_throughput: 22087.15\n",
+      "    sample_time_ms: 3662.582\n",
+      "    update_time_ms: 29.445\n",
+      "  timestamp: 1602414680\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 1213440\n",
       "  training_iteration: 15\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     15 |          233.228 | 1213440 |  228.156 |              282.687 |              117.687 |            851.244 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-48\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3550.6575342465753\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-35\n",
       "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 850.6476793248945\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 228.66575033030716\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 54\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9501965812274388\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011891363986900874\n",
       "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        policy_loss: -0.03691769976701055\n",
+      "        total_loss: 6.539995942796979\n",
+      "        vf_explained_var: 0.9532654881477356\n",
+      "        vf_loss: 6.574630396706717\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.03030303030303\n",
-      "    gpu_util_percent0: 0.28878787878787876\n",
+      "    cpu_util_percent: 23.257894736842108\n",
+      "    gpu_util_percent0: 0.3689473684210527\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76060606060606\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.205263157894738\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15936424957771478\n",
-      "    mean_env_wait_ms: 1.6837075606485503\n",
-      "    mean_inference_ms: 4.8476482100837615\n",
-      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
-      "  time_since_restore: 458.61421608924866\n",
-      "  time_this_iter_s: 28.43409752845764\n",
-      "  time_total_s: 458.61421608924866\n",
+      "    mean_action_processing_ms: 0.15652106777015845\n",
+      "    mean_env_wait_ms: 1.2141530806568188\n",
+      "    mean_inference_ms: 4.869173612186312\n",
+      "    mean_raw_obs_processing_ms: 0.41700752465286606\n",
+      "  time_since_restore: 248.63334608078003\n",
+      "  time_this_iter_s: 15.405606985092163\n",
+      "  time_total_s: 248.63334608078003\n",
       "  timers:\n",
-      "    learn_throughput: 8025.775\n",
-      "    learn_time_ms: 20159.051\n",
-      "    sample_throughput: 19933.741\n",
-      "    sample_time_ms: 8116.489\n",
-      "    update_time_ms: 36.891\n",
-      "  timestamp: 1602166308\n",
+      "    learn_throughput: 6948.54\n",
+      "    learn_time_ms: 11642.158\n",
+      "    sample_throughput: 22107.419\n",
+      "    sample_time_ms: 3659.224\n",
+      "    update_time_ms: 27.808\n",
+      "  timestamp: 1602414695\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 1294336\n",
       "  training_iteration: 16\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     16 |          248.633 | 1294336 |  228.666 |              282.687 |              117.687 |            850.648 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-16\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3544.044012944984\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-11-51\n",
       "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 847.9379746835443\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 229.5562587904359\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8869837948254177\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010574847858931338\n",
       "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        policy_loss: -0.030033384316733906\n",
+      "        total_loss: 23.887325014386857\n",
+      "        vf_explained_var: 0.9734358191490173\n",
+      "        vf_loss: 23.9153322492327\n",
+      "    num_steps_sampled: 1375232\n",
+      "    num_steps_trained: 1375232\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.170588235294122\n",
-      "    gpu_util_percent0: 0.22911764705882354\n",
+      "    cpu_util_percent: 24.12777777777778\n",
+      "    gpu_util_percent0: 0.37111111111111117\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1589481712029165\n",
-      "    mean_env_wait_ms: 1.6856610626461734\n",
-      "    mean_inference_ms: 4.823647348850542\n",
-      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
-      "  time_since_restore: 486.7920489311218\n",
-      "  time_this_iter_s: 28.17783284187317\n",
-      "  time_total_s: 486.7920489311218\n",
+      "    mean_action_processing_ms: 0.15598861878496514\n",
+      "    mean_env_wait_ms: 1.2151207173575873\n",
+      "    mean_inference_ms: 4.836795072091276\n",
+      "    mean_raw_obs_processing_ms: 0.41531330512907777\n",
+      "  time_since_restore: 264.00063276290894\n",
+      "  time_this_iter_s: 15.367286682128906\n",
+      "  time_total_s: 264.00063276290894\n",
       "  timers:\n",
-      "    learn_throughput: 8025.414\n",
-      "    learn_time_ms: 20159.958\n",
-      "    sample_throughput: 20020.205\n",
-      "    sample_time_ms: 8081.436\n",
-      "    update_time_ms: 37.784\n",
-      "  timestamp: 1602166336\n",
+      "    learn_throughput: 6950.277\n",
+      "    learn_time_ms: 11639.249\n",
+      "    sample_throughput: 22092.804\n",
+      "    sample_time_ms: 3661.645\n",
+      "    update_time_ms: 26.446\n",
+      "  timestamp: 1602414711\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 1375232\n",
       "  training_iteration: 17\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     17 |          264.001 | 1375232 |  229.556 |              282.687 |              117.687 |            847.938 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-44\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3543.446233097231\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-06\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 847.7896725440806\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 229.63910515736697\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 8\n",
+      "  episodes_total: 1588\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8809702311243329\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013751132280698844\n",
       "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.04006186420364039\n",
+      "        total_loss: 8.013969761984688\n",
+      "        vf_explained_var: 0.9799981117248535\n",
+      "        vf_loss: 8.05136946269444\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.263636363636362\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 24.18888888888889\n",
+      "    gpu_util_percent0: 0.34388888888888886\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15875079551526766\n",
-      "    mean_env_wait_ms: 1.6865974079727117\n",
-      "    mean_inference_ms: 4.812393081904589\n",
-      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
-      "  time_since_restore: 515.002126455307\n",
-      "  time_this_iter_s: 28.21007752418518\n",
-      "  time_total_s: 515.002126455307\n",
+      "    mean_action_processing_ms: 0.15596295876330984\n",
+      "    mean_env_wait_ms: 1.2152144628972157\n",
+      "    mean_inference_ms: 4.835293774425444\n",
+      "    mean_raw_obs_processing_ms: 0.4152315100989919\n",
+      "  time_since_restore: 279.209707736969\n",
+      "  time_this_iter_s: 15.209074974060059\n",
+      "  time_total_s: 279.209707736969\n",
       "  timers:\n",
-      "    learn_throughput: 8034.771\n",
-      "    learn_time_ms: 20136.48\n",
-      "    sample_throughput: 19987.012\n",
-      "    sample_time_ms: 8094.857\n",
-      "    update_time_ms: 37.274\n",
-      "  timestamp: 1602166364\n",
+      "    learn_throughput: 6958.713\n",
+      "    learn_time_ms: 11625.139\n",
+      "    sample_throughput: 22105.921\n",
+      "    sample_time_ms: 3659.472\n",
+      "    update_time_ms: 24.606\n",
+      "  timestamp: 1602414726\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 1456128\n",
       "  training_iteration: 18\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     18 |           279.21 | 1456128 |  229.639 |              282.687 |              117.687 |             847.79 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-13\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3538.6934820904285\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-22\n",
       "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 846.4361334867664\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 230.19087886924467\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 150\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8852814521108355\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0099599530388202\n",
       "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.027756639091031893\n",
+      "        total_loss: 17.517151968819753\n",
+      "        vf_explained_var: 0.9784713387489319\n",
+      "        vf_loss: 17.543005534580775\n",
+      "    num_steps_sampled: 1537024\n",
+      "    num_steps_trained: 1537024\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.017647058823528\n",
-      "    gpu_util_percent0: 0.2832352941176471\n",
+      "    cpu_util_percent: 23.321052631578947\n",
+      "    gpu_util_percent0: 0.3547368421052632\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.189473684210527\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15856558726293105\n",
-      "    mean_env_wait_ms: 1.6874969155605837\n",
-      "    mean_inference_ms: 4.801814859500953\n",
-      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
-      "  time_since_restore: 543.3891928195953\n",
-      "  time_this_iter_s: 28.38706636428833\n",
-      "  time_total_s: 543.3891928195953\n",
+      "    mean_action_processing_ms: 0.15553169296870034\n",
+      "    mean_env_wait_ms: 1.2159003987180077\n",
+      "    mean_inference_ms: 4.808477786258893\n",
+      "    mean_raw_obs_processing_ms: 0.4138048648065393\n",
+      "  time_since_restore: 294.74597215652466\n",
+      "  time_this_iter_s: 15.536264419555664\n",
+      "  time_total_s: 294.74597215652466\n",
       "  timers:\n",
-      "    learn_throughput: 8037.512\n",
-      "    learn_time_ms: 20129.612\n",
-      "    sample_throughput: 19971.836\n",
-      "    sample_time_ms: 8101.008\n",
-      "    update_time_ms: 41.201\n",
-      "  timestamp: 1602166393\n",
+      "    learn_throughput: 6952.935\n",
+      "    learn_time_ms: 11634.798\n",
+      "    sample_throughput: 22040.273\n",
+      "    sample_time_ms: 3670.372\n",
+      "    update_time_ms: 25.99\n",
+      "  timestamp: 1602414742\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 1537024\n",
       "  training_iteration: 19\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     19 |          294.746 | 1537024 |  230.191 |              282.687 |              117.687 |            846.436 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-42\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3532.3775620280476\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-37\n",
       "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 844.0365272631021\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 231.15752014587363\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 151\n",
+      "  episodes_total: 1889\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8439452222415379\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01139848040682929\n",
       "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        policy_loss: -0.03071598948112556\n",
+      "        total_loss: 18.11450685773577\n",
+      "        vf_explained_var: 0.9758296608924866\n",
+      "        vf_loss: 18.143027441842214\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.500000000000007\n",
-      "    gpu_util_percent0: 0.2582352941176471\n",
+      "    cpu_util_percent: 23.226315789473684\n",
+      "    gpu_util_percent0: 0.3752631578947369\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15824728170515573\n",
-      "    mean_env_wait_ms: 1.689080359464987\n",
-      "    mean_inference_ms: 4.783977737237845\n",
-      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
-      "  time_since_restore: 572.0331726074219\n",
-      "  time_this_iter_s: 28.643979787826538\n",
-      "  time_total_s: 572.0331726074219\n",
+      "    mean_action_processing_ms: 0.1551511801015778\n",
+      "    mean_env_wait_ms: 1.2166455419470106\n",
+      "    mean_inference_ms: 4.784982314134217\n",
+      "    mean_raw_obs_processing_ms: 0.4125990287185259\n",
+      "  time_since_restore: 310.2400779724121\n",
+      "  time_this_iter_s: 15.494105815887451\n",
+      "  time_total_s: 310.2400779724121\n",
       "  timers:\n",
-      "    learn_throughput: 8035.517\n",
-      "    learn_time_ms: 20134.61\n",
-      "    sample_throughput: 19976.949\n",
-      "    sample_time_ms: 8098.935\n",
-      "    update_time_ms: 46.558\n",
-      "  timestamp: 1602166422\n",
+      "    learn_throughput: 6943.523\n",
+      "    learn_time_ms: 11650.57\n",
+      "    sample_throughput: 22063.796\n",
+      "    sample_time_ms: 3666.459\n",
+      "    update_time_ms: 28.532\n",
+      "  timestamp: 1602414757\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 1617920\n",
       "  training_iteration: 20\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     20 |           310.24 | 1617920 |  231.158 |              282.687 |              117.687 |            844.037 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-14-10\n",
-      "  done: true\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3531.802256851155\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-12-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.964135021097\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 231.25578570515262\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 7\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.849527929510389\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012149149152849401\n",
       "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
+      "        policy_loss: -0.0404457508453301\n",
+      "        total_loss: 5.171197891235352\n",
+      "        vf_explained_var: 0.9693788886070251\n",
+      "        vf_loss: 5.209298746926444\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
       "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.76060606060606\n",
-      "    gpu_util_percent0: 0.25030303030303036\n",
+      "    cpu_util_percent: 24.477777777777774\n",
+      "    gpu_util_percent0: 0.3211111111111111\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15806698356889384\n",
-      "    mean_env_wait_ms: 1.6900183481280247\n",
-      "    mean_inference_ms: 4.773945395364269\n",
-      "    mean_raw_obs_processing_ms: 0.42436064467246504\n",
-      "  time_since_restore: 600.5207903385162\n",
-      "  time_this_iter_s: 28.48761773109436\n",
-      "  time_total_s: 600.5207903385162\n",
+      "    mean_action_processing_ms: 0.15513663481693202\n",
+      "    mean_env_wait_ms: 1.2166701954384804\n",
+      "    mean_inference_ms: 4.784032923931228\n",
+      "    mean_raw_obs_processing_ms: 0.412545884382204\n",
+      "  time_since_restore: 325.52921962738037\n",
+      "  time_this_iter_s: 15.289141654968262\n",
+      "  time_total_s: 325.52921962738037\n",
       "  timers:\n",
-      "    learn_throughput: 8034.641\n",
-      "    learn_time_ms: 20136.804\n",
-      "    sample_throughput: 19881.19\n",
-      "    sample_time_ms: 8137.943\n",
-      "    update_time_ms: 46.415\n",
-      "  timestamp: 1602166450\n",
+      "    learn_throughput: 6945.797\n",
+      "    learn_time_ms: 11646.755\n",
+      "    sample_throughput: 22099.962\n",
+      "    sample_time_ms: 3660.459\n",
+      "    update_time_ms: 28.36\n",
+      "  timestamp: 1602414773\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
+      "  timesteps_total: 1698816\n",
       "  training_iteration: 21\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57594\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3176.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 614\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602166450\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 282.48485\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 227.63033\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "2020-10-08 14:14:19,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 5nvugt1y\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 14:14:19,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_141421-fpfrymi0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:14:23,731\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:14:24,486 - wandb.wandb_agent - INFO - Running runs: ['fpfrymi0']\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     21 |          325.529 | 1698816 |  231.256 |              282.687 |              117.687 |            843.964 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=756)\u001b[0m 2020-10-08 14:14:26,675\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-14-58\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3524.741456166419\n",
+      "    time_step_min: 3212\n",
+      "  date: 2020-10-11_11-13-08\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 37.735483870967734\n",
-      "    gpu_util_percent0: 0.051935483870967754\n",
-      "    gpu_util_percent1: 0.0003225806451612903\n",
-      "    gpu_util_percent2: 0.0003225806451612903\n",
-      "    ram_util_percent: 9.529032258064516\n",
-      "    vram_util_percent0: 0.25613104243591234\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17423707785964127\n",
-      "    mean_env_wait_ms: 1.645963223637825\n",
-      "    mean_inference_ms: 5.692081848902995\n",
-      "    mean_raw_obs_processing_ms: 0.4677243687628816\n",
-      "  time_since_restore: 26.03303360939026\n",
-      "  time_this_iter_s: 26.03303360939026\n",
-      "  time_total_s: 26.03303360939026\n",
-      "  timers:\n",
-      "    learn_throughput: 9842.911\n",
-      "    learn_time_ms: 16437.413\n",
-      "    sample_throughput: 17001.439\n",
-      "    sample_time_ms: 9516.371\n",
-      "    update_time_ms: 39.605\n",
-      "  timestamp: 1602166498\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      1 |           26.033 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-23\n",
-      "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.220689655172414\n",
-      "    gpu_util_percent0: 0.019655172413793106\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74137931034483\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17038163777984144\n",
-      "    mean_env_wait_ms: 1.6424572254451888\n",
-      "    mean_inference_ms: 5.447572680731352\n",
-      "    mean_raw_obs_processing_ms: 0.4584056950467155\n",
-      "  time_since_restore: 50.949177742004395\n",
-      "  time_this_iter_s: 24.916144132614136\n",
-      "  time_total_s: 50.949177742004395\n",
-      "  timers:\n",
-      "    learn_throughput: 9861.266\n",
-      "    learn_time_ms: 16406.818\n",
-      "    sample_throughput: 18024.658\n",
-      "    sample_time_ms: 8976.148\n",
-      "    update_time_ms: 38.131\n",
-      "  timestamp: 1602166523\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      2 |          50.9492 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-48\n",
-      "  done: false\n",
-      "  episode_len_mean: 867.8713080168776\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 228.246196138601\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1271256804466248\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007389193354174495\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018508310522884132\n",
-      "        total_loss: 6.457739639282226\n",
-      "        vf_explained_var: 0.9464155435562134\n",
-      "        vf_loss: 6.4747700691223145\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.61379310344827\n",
-      "    gpu_util_percent0: 0.21344827586206902\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16769761323536675\n",
-      "    mean_env_wait_ms: 1.6416986329657957\n",
-      "    mean_inference_ms: 5.306852272749373\n",
-      "    mean_raw_obs_processing_ms: 0.4500760030355006\n",
-      "  time_since_restore: 75.78218650817871\n",
-      "  time_this_iter_s: 24.833008766174316\n",
-      "  time_total_s: 75.78218650817871\n",
-      "  timers:\n",
-      "    learn_throughput: 9901.992\n",
-      "    learn_time_ms: 16339.339\n",
-      "    sample_throughput: 18316.884\n",
-      "    sample_time_ms: 8832.943\n",
-      "    update_time_ms: 36.895\n",
-      "  timestamp: 1602166548\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      3 |          75.7822 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3230.0\n",
-      "  date: 2020-10-08_14-16-13\n",
-      "  done: false\n",
-      "  episode_len_mean: 862.3544303797469\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 230.3964326812426\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0996861219406129\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008276985818520188\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020328705292195083\n",
-      "        total_loss: 5.005046558380127\n",
-      "        vf_explained_var: 0.9697187542915344\n",
-      "        vf_loss: 5.023719763755798\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.723333333333336\n",
-      "    gpu_util_percent0: 0.4343333333333333\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1657578301907817\n",
-      "    mean_env_wait_ms: 1.6430517247856948\n",
-      "    mean_inference_ms: 5.2018997182402025\n",
-      "    mean_raw_obs_processing_ms: 0.44406851617825566\n",
-      "  time_since_restore: 100.74394655227661\n",
-      "  time_this_iter_s: 24.9617600440979\n",
-      "  time_total_s: 100.74394655227661\n",
-      "  timers:\n",
-      "    learn_throughput: 9911.992\n",
-      "    learn_time_ms: 16322.854\n",
-      "    sample_throughput: 18445.327\n",
-      "    sample_time_ms: 8771.436\n",
-      "    update_time_ms: 36.541\n",
-      "  timestamp: 1602166573\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      4 |          100.744 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-16-38\n",
-      "  done: false\n",
-      "  episode_len_mean: 852.6247216035634\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.18069334773102\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 266\n",
-      "  episodes_total: 898\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0624429881572723\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0077964670956134794\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02084309732308611\n",
-      "        total_loss: 7.683893799781799\n",
-      "        vf_explained_var: 0.9791978597640991\n",
-      "        vf_loss: 7.703177666664123\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.225\n",
-      "    gpu_util_percent0: 0.25178571428571433\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16364555568838862\n",
-      "    mean_env_wait_ms: 1.649353801806338\n",
-      "    mean_inference_ms: 5.083644859595276\n",
-      "    mean_raw_obs_processing_ms: 0.4376329609722663\n",
-      "  time_since_restore: 125.15412139892578\n",
-      "  time_this_iter_s: 24.41017484664917\n",
-      "  time_total_s: 125.15412139892578\n",
-      "  timers:\n",
-      "    learn_throughput: 9921.993\n",
-      "    learn_time_ms: 16306.401\n",
-      "    sample_throughput: 18736.645\n",
-      "    sample_time_ms: 8635.057\n",
-      "    update_time_ms: 35.191\n",
-      "  timestamp: 1602166598\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      5 |          125.154 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-17-02\n",
-      "  done: false\n",
-      "  episode_len_mean: 846.0479204339964\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.96029919447625\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 208\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0738083600997925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007217544643208384\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02225890466943383\n",
-      "        total_loss: 4.545075726509094\n",
-      "        vf_explained_var: 0.9842392206192017\n",
-      "        vf_loss: 4.565891194343567\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.55517241379311\n",
-      "    gpu_util_percent0: 0.4293103448275861\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16251990142651115\n",
-      "    mean_env_wait_ms: 1.6530343779974206\n",
-      "    mean_inference_ms: 5.018380813854082\n",
-      "    mean_raw_obs_processing_ms: 0.43409996967266995\n",
-      "  time_since_restore: 149.7096438407898\n",
-      "  time_this_iter_s: 24.555522441864014\n",
-      "  time_total_s: 149.7096438407898\n",
-      "  timers:\n",
-      "    learn_throughput: 9912.286\n",
-      "    learn_time_ms: 16322.371\n",
-      "    sample_throughput: 18942.241\n",
-      "    sample_time_ms: 8541.334\n",
-      "    update_time_ms: 33.368\n",
-      "  timestamp: 1602166622\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      6 |           149.71 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.3995253164557\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 232.7926815624599\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0473353922367097\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006994991353712976\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022564191045239566\n",
-      "        total_loss: 4.000831997394561\n",
-      "        vf_explained_var: 0.9874190092086792\n",
-      "        vf_loss: 4.021997082233429\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.59655172413793\n",
-      "    gpu_util_percent0: 0.4562068965517241\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655174\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16183355318977655\n",
-      "    mean_env_wait_ms: 1.656038102133309\n",
-      "    mean_inference_ms: 4.9782716342931606\n",
-      "    mean_raw_obs_processing_ms: 0.4319914234530791\n",
-      "  time_since_restore: 174.1368727684021\n",
-      "  time_this_iter_s: 24.427228927612305\n",
-      "  time_total_s: 174.1368727684021\n",
-      "  timers:\n",
-      "    learn_throughput: 9918.301\n",
-      "    learn_time_ms: 16312.471\n",
-      "    sample_throughput: 19088.76\n",
-      "    sample_time_ms: 8475.773\n",
-      "    update_time_ms: 33.238\n",
-      "  timestamp: 1602166647\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      7 |          174.137 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.3713080168776\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 233.61432184006011\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.01868434548378\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007189809367991984\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023347471375018358\n",
-      "        total_loss: 3.781139385700226\n",
-      "        vf_explained_var: 0.9891014099121094\n",
-      "        vf_loss: 3.803048861026764\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.625\n",
-      "    gpu_util_percent0: 0.04107142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.771428571428572\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125876245924115\n",
-      "    mean_env_wait_ms: 1.6590341255429097\n",
-      "    mean_inference_ms: 4.943515953135972\n",
-      "    mean_raw_obs_processing_ms: 0.430128591449942\n",
-      "  time_since_restore: 198.50214219093323\n",
-      "  time_this_iter_s: 24.365269422531128\n",
-      "  time_total_s: 198.50214219093323\n",
-      "  timers:\n",
-      "    learn_throughput: 9923.421\n",
-      "    learn_time_ms: 16304.054\n",
-      "    sample_throughput: 19218.701\n",
-      "    sample_time_ms: 8418.467\n",
-      "    update_time_ms: 34.044\n",
-      "  timestamp: 1602166671\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      8 |          198.502 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-15\n",
-      "  done: false\n",
-      "  episode_len_mean: 829.8141542002302\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.34277179156337\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9904811769723892\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006311689200811088\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020997717510908842\n",
-      "        total_loss: 5.1504497051239015\n",
-      "        vf_explained_var: 0.9909344911575317\n",
-      "        vf_loss: 5.170185089111328\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.30821428571428566\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.160369309924211\n",
-      "    mean_env_wait_ms: 1.6650071130850876\n",
-      "    mean_inference_ms: 4.888377085687167\n",
-      "    mean_raw_obs_processing_ms: 0.42729617584826485\n",
-      "  time_since_restore: 222.59675359725952\n",
-      "  time_this_iter_s: 24.094611406326294\n",
-      "  time_total_s: 222.59675359725952\n",
-      "  timers:\n",
-      "    learn_throughput: 9938.553\n",
-      "    learn_time_ms: 16279.231\n",
-      "    sample_throughput: 19342.706\n",
-      "    sample_time_ms: 8364.497\n",
-      "    update_time_ms: 33.218\n",
-      "  timestamp: 1602166695\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      9 |          222.597 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-40\n",
-      "  done: false\n",
-      "  episode_len_mean: 826.4541139240506\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.7108905510803\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9730047971010208\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006372990598902106\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022790615819394587\n",
-      "        total_loss: 3.343014180660248\n",
-      "        vf_explained_var: 0.9915106892585754\n",
-      "        vf_loss: 3.3645302057266235\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.324137931034485\n",
-      "    gpu_util_percent0: 0.2775862068965517\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16000657164975352\n",
-      "    mean_env_wait_ms: 1.6678046661692965\n",
-      "    mean_inference_ms: 4.86599024622493\n",
-      "    mean_raw_obs_processing_ms: 0.42614775920547227\n",
-      "  time_since_restore: 246.9238064289093\n",
-      "  time_this_iter_s: 24.32705283164978\n",
-      "  time_total_s: 246.9238064289093\n",
-      "  timers:\n",
-      "    learn_throughput: 9939.106\n",
-      "    learn_time_ms: 16278.326\n",
-      "    sample_throughput: 19435.411\n",
-      "    sample_time_ms: 8324.599\n",
-      "    update_time_ms: 33.566\n",
-      "  timestamp: 1602166720\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     10 |          246.924 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-04\n",
-      "  done: false\n",
-      "  episode_len_mean: 823.6002921129503\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 236.65748035368276\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9577732890844345\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006211055861786008\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022765795403392984\n",
-      "        total_loss: 3.0192813992500307\n",
-      "        vf_explained_var: 0.9923363924026489\n",
-      "        vf_loss: 3.0408049702644346\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.706896551724135\n",
-      "    gpu_util_percent0: 0.43068965517241387\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1596848966715417\n",
-      "    mean_env_wait_ms: 1.6704675074629387\n",
-      "    mean_inference_ms: 4.845793508809106\n",
-      "    mean_raw_obs_processing_ms: 0.42510446710641553\n",
-      "  time_since_restore: 271.42553091049194\n",
-      "  time_this_iter_s: 24.50172448158264\n",
-      "  time_total_s: 271.42553091049194\n",
-      "  timers:\n",
-      "    learn_throughput: 9946.653\n",
-      "    learn_time_ms: 16265.974\n",
-      "    sample_throughput: 19772.529\n",
-      "    sample_time_ms: 8182.666\n",
-      "    update_time_ms: 32.542\n",
-      "  timestamp: 1602166744\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     11 |          271.426 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.2957437472576\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 237.36838769440774\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 225\n",
-      "  episodes_total: 2279\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9244333893060684\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006004941323772073\n",
-      "        model: {}\n",
-      "        policy_loss: -0.021168453525751828\n",
-      "        total_loss: 4.074023377895355\n",
-      "        vf_explained_var: 0.9932994842529297\n",
-      "        vf_loss: 4.093990921974182\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.251724137931035\n",
-      "    gpu_util_percent0: 0.39206896551724135\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744827586206897\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1592619934185692\n",
-      "    mean_env_wait_ms: 1.6739541868498113\n",
-      "    mean_inference_ms: 4.819806265535011\n",
-      "    mean_raw_obs_processing_ms: 0.42372078258183\n",
-      "  time_since_restore: 296.40609192848206\n",
-      "  time_this_iter_s: 24.980561017990112\n",
-      "  time_total_s: 296.40609192848206\n",
-      "  timers:\n",
-      "    learn_throughput: 9957.289\n",
-      "    learn_time_ms: 16248.6\n",
-      "    sample_throughput: 19727.515\n",
-      "    sample_time_ms: 8201.337\n",
-      "    update_time_ms: 32.973\n",
-      "  timestamp: 1602166769\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     12 |          296.406 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 817.5490506329114\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.05452068149842\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 249\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9116032361984253\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0059999656863510605\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020421561488183214\n",
-      "        total_loss: 3.2677656054496764\n",
-      "        vf_explained_var: 0.9931272268295288\n",
-      "        vf_loss: 3.2869871616363526\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.02857142857143\n",
-      "    gpu_util_percent0: 0.06035714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.764285714285716\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15888263499780286\n",
-      "    mean_env_wait_ms: 1.677646536061787\n",
-      "    mean_inference_ms: 4.796171409815506\n",
-      "    mean_raw_obs_processing_ms: 0.42253131691795703\n",
-      "  time_since_restore: 320.67564845085144\n",
-      "  time_this_iter_s: 24.269556522369385\n",
-      "  time_total_s: 320.67564845085144\n",
-      "  timers:\n",
-      "    learn_throughput: 9954.003\n",
-      "    learn_time_ms: 16253.963\n",
-      "    sample_throughput: 19876.989\n",
-      "    sample_time_ms: 8139.664\n",
-      "    update_time_ms: 31.685\n",
-      "  timestamp: 1602166794\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     13 |          320.676 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 816.2442293373045\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.46138225140444\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9013321816921234\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006421135948039591\n",
-      "        model: {}\n",
-      "        policy_loss: -0.021805241936817765\n",
-      "        total_loss: 2.9366058349609374\n",
-      "        vf_explained_var: 0.9931826591491699\n",
-      "        vf_loss: 2.9571268558502197\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.642857142857146\n",
-      "    gpu_util_percent0: 0.30678571428571433\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15866013164662812\n",
-      "    mean_env_wait_ms: 1.6796736234314602\n",
-      "    mean_inference_ms: 4.782626736230756\n",
-      "    mean_raw_obs_processing_ms: 0.42183995211689523\n",
-      "  time_since_restore: 344.8741044998169\n",
-      "  time_this_iter_s: 24.198456048965454\n",
-      "  time_total_s: 344.8741044998169\n",
-      "  timers:\n",
-      "    learn_throughput: 9964.721\n",
-      "    learn_time_ms: 16236.481\n",
-      "    sample_throughput: 20015.961\n",
-      "    sample_time_ms: 8083.149\n",
-      "    update_time_ms: 29.819\n",
-      "  timestamp: 1602166818\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     14 |          344.874 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-43\n",
-      "  done: false\n",
-      "  episode_len_mean: 814.502106741573\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.95662736919752\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 162\n",
-      "  episodes_total: 2848\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8737345904111862\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005880716699175536\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023541058914270253\n",
-      "        total_loss: 2.77874299287796\n",
-      "        vf_explained_var: 0.9943079948425293\n",
-      "        vf_loss: 2.801107919216156\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.53793103448275\n",
-      "    gpu_util_percent0: 0.09275862068965515\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77241379310345\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15844943627409838\n",
-      "    mean_env_wait_ms: 1.6816497328437465\n",
-      "    mean_inference_ms: 4.769681731783559\n",
-      "    mean_raw_obs_processing_ms: 0.42115262835775236\n",
-      "  time_since_restore: 369.2295935153961\n",
-      "  time_this_iter_s: 24.355489015579224\n",
-      "  time_total_s: 369.2295935153961\n",
-      "  timers:\n",
-      "    learn_throughput: 9970.424\n",
-      "    learn_time_ms: 16227.193\n",
-      "    sample_throughput: 20006.648\n",
-      "    sample_time_ms: 8086.912\n",
-      "    update_time_ms: 28.747\n",
-      "  timestamp: 1602166843\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     15 |           369.23 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-07\n",
-      "  done: false\n",
-      "  episode_len_mean: 811.5661392405063\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.56847270170044\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 312\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.836417630314827\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005600748467259109\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019153478858061134\n",
-      "        total_loss: 3.4916038155555724\n",
-      "        vf_explained_var: 0.9944165349006653\n",
-      "        vf_loss: 3.5096370816230773\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.9551724137931\n",
-      "    gpu_util_percent0: 0.43275862068965526\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15809978406417496\n",
-      "    mean_env_wait_ms: 1.6853761096348427\n",
-      "    mean_inference_ms: 4.748027409045223\n",
-      "    mean_raw_obs_processing_ms: 0.42003623239671906\n",
-      "  time_since_restore: 393.7941789627075\n",
-      "  time_this_iter_s: 24.5645854473114\n",
-      "  time_total_s: 393.7941789627075\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.021\n",
-      "    learn_time_ms: 16216.464\n",
-      "    sample_throughput: 19987.267\n",
-      "    sample_time_ms: 8094.753\n",
-      "    update_time_ms: 30.454\n",
-      "  timestamp: 1602166867\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     16 |          393.794 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-32\n",
-      "  done: false\n",
-      "  episode_len_mean: 810.3282097649186\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.7355501975754\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8335719257593155\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006123062083497643\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020987965818494558\n",
-      "        total_loss: 2.507720983028412\n",
-      "        vf_explained_var: 0.9944343566894531\n",
-      "        vf_loss: 2.5274842858314512\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.18275862068966\n",
-      "    gpu_util_percent0: 0.27655172413793105\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655173\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15794348066077543\n",
-      "    mean_env_wait_ms: 1.687080352601384\n",
-      "    mean_inference_ms: 4.7382363513709365\n",
-      "    mean_raw_obs_processing_ms: 0.41954097731825146\n",
-      "  time_since_restore: 418.4777216911316\n",
-      "  time_this_iter_s: 24.683542728424072\n",
-      "  time_total_s: 418.4777216911316\n",
-      "  timers:\n",
-      "    learn_throughput: 9984.096\n",
-      "    learn_time_ms: 16204.972\n",
-      "    sample_throughput: 19915.659\n",
-      "    sample_time_ms: 8123.859\n",
-      "    update_time_ms: 31.876\n",
-      "  timestamp: 1602166892\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     17 |          418.478 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 809.0097813578826\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.89810649649536\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.830751609802246\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005981297581456602\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023448871518485247\n",
-      "        total_loss: 2.440117084980011\n",
-      "        vf_explained_var: 0.994672954082489\n",
-      "        vf_loss: 2.462369680404663\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.04142857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.792857142857144\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15779369461228313\n",
-      "    mean_env_wait_ms: 1.6887300269221321\n",
-      "    mean_inference_ms: 4.729069241301459\n",
-      "    mean_raw_obs_processing_ms: 0.419066132995007\n",
-      "  time_since_restore: 442.8714327812195\n",
-      "  time_this_iter_s: 24.39371109008789\n",
-      "  time_total_s: 442.8714327812195\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.82\n",
-      "    learn_time_ms: 16215.165\n",
-      "    sample_throughput: 19931.133\n",
-      "    sample_time_ms: 8117.551\n",
-      "    update_time_ms: 31.094\n",
-      "  timestamp: 1602166917\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     18 |          442.871 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 806.8230485232068\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.2267639474917\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7929262965917587\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005467748525552452\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018968340079300105\n",
-      "        total_loss: 3.431827688217163\n",
-      "        vf_explained_var: 0.9950782060623169\n",
-      "        vf_loss: 3.4497024059295653\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.27379310344827584\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15751807790452294\n",
-      "    mean_env_wait_ms: 1.6918670821992567\n",
-      "    mean_inference_ms: 4.71261405039136\n",
-      "    mean_raw_obs_processing_ms: 0.41822277427376653\n",
-      "  time_since_restore: 467.25490164756775\n",
-      "  time_this_iter_s: 24.383468866348267\n",
-      "  time_total_s: 467.25490164756775\n",
-      "  timers:\n",
-      "    learn_throughput: 9975.719\n",
-      "    learn_time_ms: 16218.58\n",
-      "    sample_throughput: 19874.518\n",
-      "    sample_time_ms: 8140.676\n",
-      "    update_time_ms: 32.327\n",
-      "  timestamp: 1602166941\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     19 |          467.255 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-46\n",
-      "  done: false\n",
-      "  episode_len_mean: 805.7225316455696\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.49984400971735\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3950\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7794228792190552\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005526655982248485\n",
-      "        model: {}\n",
-      "        policy_loss: -0.023039081250317395\n",
-      "        total_loss: 2.078591358661652\n",
-      "        vf_explained_var: 0.9953739047050476\n",
-      "        vf_loss: 2.1005250751972198\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.92068965517242\n",
-      "    gpu_util_percent0: 0.4165517241379311\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1573904574836841\n",
-      "    mean_env_wait_ms: 1.6933221569620878\n",
-      "    mean_inference_ms: 4.705165325354333\n",
-      "    mean_raw_obs_processing_ms: 0.4178457110788417\n",
-      "  time_since_restore: 491.8251175880432\n",
-      "  time_this_iter_s: 24.570215940475464\n",
-      "  time_total_s: 491.8251175880432\n",
-      "  timers:\n",
-      "    learn_throughput: 9972.19\n",
-      "    learn_time_ms: 16224.319\n",
-      "    sample_throughput: 19829.965\n",
-      "    sample_time_ms: 8158.965\n",
-      "    update_time_ms: 31.231\n",
-      "  timestamp: 1602166966\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     20 |          491.825 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 804.7280915287245\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.70876486382807\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7865538984537125\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005757506913505494\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02310952057596296\n",
-      "        total_loss: 1.973700213432312\n",
-      "        vf_explained_var: 0.9953605532646179\n",
-      "        vf_loss: 1.9956582367420197\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.4148275862068965\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15726970308067142\n",
-      "    mean_env_wait_ms: 1.6947178273814376\n",
-      "    mean_inference_ms: 4.698130026253491\n",
-      "    mean_raw_obs_processing_ms: 0.4174790686263623\n",
-      "  time_since_restore: 516.4608044624329\n",
-      "  time_this_iter_s: 24.63568687438965\n",
-      "  time_total_s: 516.4608044624329\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.798\n",
-      "    learn_time_ms: 16215.201\n",
-      "    sample_throughput: 19793.078\n",
-      "    sample_time_ms: 8174.171\n",
-      "    update_time_ms: 32.464\n",
-      "  timestamp: 1602166991\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     21 |          516.461 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-36\n",
-      "  done: false\n",
-      "  episode_len_mean: 803.1457812144644\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.09711855879692\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4397\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.755255714058876\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005404739850200712\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019464567000977696\n",
-      "        total_loss: 3.0453175783157347\n",
-      "        vf_explained_var: 0.9953736066818237\n",
-      "        vf_loss: 3.0637012124061584\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.010344827586216\n",
-      "    gpu_util_percent0: 0.25551724137931037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15706065795015647\n",
-      "    mean_env_wait_ms: 1.6971458462496418\n",
-      "    mean_inference_ms: 4.686353824274288\n",
-      "    mean_raw_obs_processing_ms: 0.41688654879158077\n",
-      "  time_since_restore: 541.0245015621185\n",
-      "  time_this_iter_s: 24.56369709968567\n",
-      "  time_total_s: 541.0245015621185\n",
-      "  timers:\n",
-      "    learn_throughput: 9974.186\n",
-      "    learn_time_ms: 16221.074\n",
-      "    sample_throughput: 19914.903\n",
-      "    sample_time_ms: 8124.167\n",
-      "    update_time_ms: 32.124\n",
-      "  timestamp: 1602167016\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     22 |          541.025 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-00\n",
-      "  done: false\n",
-      "  episode_len_mean: 802.2247926669577\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.27666671075653\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7225345104932785\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005478021572344005\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022186438925564288\n",
-      "        total_loss: 1.9642526030540466\n",
-      "        vf_explained_var: 0.9957612752914429\n",
-      "        vf_loss: 1.9853434622287751\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.33793103448276\n",
-      "    gpu_util_percent0: 0.43206896551724133\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569378381550041\n",
-      "    mean_env_wait_ms: 1.698596232047108\n",
-      "    mean_inference_ms: 4.679417530334113\n",
-      "    mean_raw_obs_processing_ms: 0.4165376750547412\n",
-      "  time_since_restore: 565.687112569809\n",
-      "  time_this_iter_s: 24.66261100769043\n",
-      "  time_total_s: 565.687112569809\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.382\n",
-      "    learn_time_ms: 16230.518\n",
-      "    sample_throughput: 19860.374\n",
-      "    sample_time_ms: 8146.473\n",
-      "    update_time_ms: 32.606\n",
-      "  timestamp: 1602167040\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     23 |          565.687 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 801.512447257384\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.5184460640156\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7451686680316925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005771003756672144\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024150656536221504\n",
-      "        total_loss: 1.7480961799621582\n",
-      "        vf_explained_var: 0.9958817362785339\n",
-      "        vf_loss: 1.7710926413536072\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.81071428571429\n",
-      "    gpu_util_percent0: 0.16499999999999998\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.782142857142857\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15683784552145583\n",
-      "    mean_env_wait_ms: 1.6997744080868349\n",
-      "    mean_inference_ms: 4.673850092393118\n",
-      "    mean_raw_obs_processing_ms: 0.4162613145590402\n",
-      "  time_since_restore: 590.1530044078827\n",
-      "  time_this_iter_s: 24.46589183807373\n",
-      "  time_total_s: 590.1530044078827\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.406\n",
-      "    learn_time_ms: 16230.478\n",
-      "    sample_throughput: 19802.656\n",
-      "    sample_time_ms: 8170.217\n",
-      "    update_time_ms: 35.007\n",
-      "  timestamp: 1602167065\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     24 |          590.153 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-50\n",
-      "  done: true\n",
-      "  episode_len_mean: 800.4764492753624\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.8013874656386\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 228\n",
-      "  episodes_total: 4968\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7212436735630036\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00533560358453542\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020342798670753837\n",
-      "        total_loss: 2.63335440158844\n",
-      "        vf_explained_var: 0.9957489967346191\n",
-      "        vf_loss: 2.65263010263443\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.09666666666667\n",
-      "    gpu_util_percent0: 0.22766666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746666666666668\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15670386391308977\n",
-      "    mean_env_wait_ms: 1.7014434824573494\n",
-      "    mean_inference_ms: 4.66638510128689\n",
-      "    mean_raw_obs_processing_ms: 0.41590574797057145\n",
-      "  time_since_restore: 614.7696187496185\n",
-      "  time_this_iter_s: 24.61661434173584\n",
-      "  time_total_s: 614.7696187496185\n",
-      "  timers:\n",
-      "    learn_throughput: 9960.015\n",
-      "    learn_time_ms: 16244.153\n",
-      "    sample_throughput: 19778.628\n",
-      "    sample_time_ms: 8180.143\n",
-      "    update_time_ms: 36.793\n",
-      "  timestamp: 1602167090\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 502\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3125.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167090\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.24242\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 235.34277\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1738\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "2020-10-08 14:25:03,027 - wandb.wandb_agent - INFO - Cleaning up finished run: fpfrymi0\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 16384\n",
-      "2020-10-08 14:25:03,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_142505-w8c2p6ff\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:25:07,555\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:25:08,410 - wandb.wandb_agent - INFO - Running runs: ['w8c2p6ff']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=33202)\u001b[0m 2020-10-08 14:25:10,570\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-25-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1623204231262207\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048057976178824905\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00972368239890784\n",
-      "        total_loss: 8.319466400146485\n",
-      "        vf_explained_var: 0.7498777508735657\n",
-      "        vf_loss: 8.328228569030761\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 37.63333333333333\n",
-      "    gpu_util_percent0: 0.26266666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003333333333333333\n",
-      "    ram_util_percent: 9.49\n",
-      "    vram_util_percent0: 0.2729856783644911\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17678140968259154\n",
-      "    mean_env_wait_ms: 1.6502532711659141\n",
-      "    mean_inference_ms: 5.870735121936333\n",
-      "    mean_raw_obs_processing_ms: 0.4788182656976241\n",
-      "  time_since_restore: 25.622228860855103\n",
-      "  time_this_iter_s: 25.622228860855103\n",
-      "  time_total_s: 25.622228860855103\n",
-      "  timers:\n",
-      "    learn_throughput: 10340.312\n",
-      "    learn_time_ms: 15646.724\n",
-      "    sample_throughput: 16338.488\n",
-      "    sample_time_ms: 9902.507\n",
-      "    update_time_ms: 42.975\n",
-      "  timestamp: 1602167142\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-06\n",
-      "  done: false\n",
-      "  episode_len_mean: 870.7974683544304\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.3724267996418\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.138706338405609\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006825200421735645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01274334719637409\n",
-      "        total_loss: 7.690042400360108\n",
-      "        vf_explained_var: 0.8869457244873047\n",
-      "        vf_loss: 7.702103328704834\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.425925925925924\n",
-      "    gpu_util_percent0: 0.3437037037037037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.73703703703704\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17196632938280343\n",
-      "    mean_env_wait_ms: 1.646491991621751\n",
-      "    mean_inference_ms: 5.588687582318563\n",
-      "    mean_raw_obs_processing_ms: 0.467505042931231\n",
-      "  time_since_restore: 49.39094591140747\n",
-      "  time_this_iter_s: 23.768717050552368\n",
-      "  time_total_s: 49.39094591140747\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.268\n",
-      "    learn_time_ms: 15479.129\n",
-      "    sample_throughput: 17702.943\n",
-      "    sample_time_ms: 9139.271\n",
-      "    update_time_ms: 38.137\n",
-      "  timestamp: 1602167166\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-30\n",
-      "  done: false\n",
-      "  episode_len_mean: 866.331223628692\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.87126539658163\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1217446804046631\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007683717552572489\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014337884564884006\n",
-      "        total_loss: 8.763248443603516\n",
-      "        vf_explained_var: 0.9284197092056274\n",
-      "        vf_loss: 8.77681770324707\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.08620689655172\n",
-      "    gpu_util_percent0: 0.3172413793103448\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16894469760208242\n",
-      "    mean_env_wait_ms: 1.6450424063300917\n",
-      "    mean_inference_ms: 5.427040881695507\n",
-      "    mean_raw_obs_processing_ms: 0.45877313240781425\n",
-      "  time_since_restore: 73.57178139686584\n",
-      "  time_this_iter_s: 24.180835485458374\n",
-      "  time_total_s: 73.57178139686584\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.901\n",
-      "    learn_time_ms: 15478.191\n",
-      "    sample_throughput: 18089.282\n",
-      "    sample_time_ms: 8944.081\n",
-      "    update_time_ms: 56.055\n",
-      "  timestamp: 1602167190\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 861.253164556962\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 227.7450294080039\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0939712405204773\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009209706541150808\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015771377924829723\n",
-      "        total_loss: 8.429035234451295\n",
-      "        vf_explained_var: 0.9521434903144836\n",
-      "        vf_loss: 8.443885612487794\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.03333333333334\n",
-      "    gpu_util_percent0: 0.2777777777777778\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16676384022481172\n",
-      "    mean_env_wait_ms: 1.6466515242102222\n",
-      "    mean_inference_ms: 5.307577815654116\n",
-      "    mean_raw_obs_processing_ms: 0.4522795805237597\n",
-      "  time_since_restore: 97.21736693382263\n",
-      "  time_this_iter_s: 23.645585536956787\n",
-      "  time_total_s: 97.21736693382263\n",
-      "  timers:\n",
-      "    learn_throughput: 10478.311\n",
-      "    learn_time_ms: 15440.657\n",
-      "    sample_throughput: 18466.869\n",
-      "    sample_time_ms: 8761.204\n",
-      "    update_time_ms: 52.666\n",
-      "  timestamp: 1602167214\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.2613882863341\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.4696860141544\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 290\n",
-      "  episodes_total: 922\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0592716097831727\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007743995590135455\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014329827937763185\n",
-      "        total_loss: 12.433664703369141\n",
-      "        vf_explained_var: 0.967904269695282\n",
-      "        vf_loss: 12.447219848632812\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.35357142857143\n",
-      "    gpu_util_percent0: 0.2582142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16431055835082262\n",
-      "    mean_env_wait_ms: 1.6540874340682217\n",
-      "    mean_inference_ms: 5.1659246506223315\n",
-      "    mean_raw_obs_processing_ms: 0.4451297976580212\n",
-      "  time_since_restore: 120.98013472557068\n",
-      "  time_this_iter_s: 23.762767791748047\n",
-      "  time_total_s: 120.98013472557068\n",
-      "  timers:\n",
-      "    learn_throughput: 10471.141\n",
-      "    learn_time_ms: 15451.229\n",
-      "    sample_throughput: 18710.121\n",
-      "    sample_time_ms: 8647.299\n",
-      "    update_time_ms: 46.768\n",
-      "  timestamp: 1602167237\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-41\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2649186256781\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.83911447202573\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 184\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0483574509620666\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007546161720529199\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015934903593733906\n",
-      "        total_loss: 6.211568450927734\n",
-      "        vf_explained_var: 0.979483425617218\n",
-      "        vf_loss: 6.22674880027771\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.42962962962963\n",
-      "    gpu_util_percent0: 0.23518518518518516\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16320835121240662\n",
-      "    mean_env_wait_ms: 1.658072254904595\n",
-      "    mean_inference_ms: 5.101929976377745\n",
-      "    mean_raw_obs_processing_ms: 0.44197622201871506\n",
-      "  time_since_restore: 144.46361637115479\n",
-      "  time_this_iter_s: 23.483481645584106\n",
-      "  time_total_s: 144.46361637115479\n",
-      "  timers:\n",
-      "    learn_throughput: 10482.756\n",
-      "    learn_time_ms: 15434.108\n",
-      "    sample_throughput: 18930.618\n",
-      "    sample_time_ms: 8546.578\n",
-      "    update_time_ms: 45.48\n",
-      "  timestamp: 1602167261\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-05\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.381329113924\n",
-      "  episode_reward_max: 279.83838383838383\n",
-      "  episode_reward_mean: 228.88543664493022\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0276257395744324\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006892968993633985\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01625481452792883\n",
-      "        total_loss: 5.934515047073364\n",
-      "        vf_explained_var: 0.9834254384040833\n",
-      "        vf_loss: 5.950080394744873\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.47777777777778\n",
-      "    gpu_util_percent0: 0.2955555555555555\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16243749898577767\n",
-      "    mean_env_wait_ms: 1.6615503416153818\n",
-      "    mean_inference_ms: 5.056720554339727\n",
-      "    mean_raw_obs_processing_ms: 0.439742077717109\n",
-      "  time_since_restore: 168.09322547912598\n",
-      "  time_this_iter_s: 23.62960910797119\n",
-      "  time_total_s: 168.09322547912598\n",
-      "  timers:\n",
-      "    learn_throughput: 10486.247\n",
-      "    learn_time_ms: 15428.971\n",
-      "    sample_throughput: 19063.221\n",
-      "    sample_time_ms: 8487.128\n",
-      "    update_time_ms: 45.241\n",
-      "  timestamp: 1602167285\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-28\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.6736990154711\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.3878233814942\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9920619606971741\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0067844231147319075\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01662699868902564\n",
-      "        total_loss: 5.330079460144043\n",
-      "        vf_explained_var: 0.9873720407485962\n",
-      "        vf_loss: 5.346027898788452\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.72222222222223\n",
-      "    gpu_util_percent0: 0.2811111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16179048159969586\n",
-      "    mean_env_wait_ms: 1.664834322637065\n",
-      "    mean_inference_ms: 5.017627986563437\n",
-      "    mean_raw_obs_processing_ms: 0.43762471876215703\n",
-      "  time_since_restore: 191.7211263179779\n",
-      "  time_this_iter_s: 23.62790083885193\n",
-      "  time_total_s: 191.7211263179779\n",
-      "  timers:\n",
-      "    learn_throughput: 10499.739\n",
-      "    learn_time_ms: 15409.145\n",
-      "    sample_throughput: 19126.146\n",
-      "    sample_time_ms: 8459.205\n",
-      "    update_time_ms: 44.366\n",
-      "  timestamp: 1602167308\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 827.9994246260069\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.99320593739455\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9606243968009949\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005957465758547187\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013455570582300425\n",
-      "        total_loss: 7.494734096527099\n",
-      "        vf_explained_var: 0.9888100624084473\n",
-      "        vf_loss: 7.5075939178466795\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.90357142857143\n",
-      "    gpu_util_percent0: 0.26678571428571424\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16076244116115793\n",
-      "    mean_env_wait_ms: 1.6704480394177186\n",
-      "    mean_inference_ms: 4.955192966914281\n",
-      "    mean_raw_obs_processing_ms: 0.4343471050403994\n",
-      "  time_since_restore: 215.57324147224426\n",
-      "  time_this_iter_s: 23.852115154266357\n",
-      "  time_total_s: 215.57324147224426\n",
-      "  timers:\n",
-      "    learn_throughput: 10506.415\n",
-      "    learn_time_ms: 15399.353\n",
-      "    sample_throughput: 19131.856\n",
-      "    sample_time_ms: 8456.681\n",
-      "    update_time_ms: 41.666\n",
-      "  timestamp: 1602167332\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 826.5395569620254\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.1556546477432\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9285854279994965\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0062581704463809725\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016021200059913098\n",
-      "        total_loss: 3.8204103231430055\n",
-      "        vf_explained_var: 0.9922056198120117\n",
-      "        vf_loss: 3.835805630683899\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.096296296296295\n",
-      "    gpu_util_percent0: 0.25592592592592595\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1603412050605606\n",
-      "    mean_env_wait_ms: 1.6728638400028686\n",
-      "    mean_inference_ms: 4.929926052491426\n",
-      "    mean_raw_obs_processing_ms: 0.4330192737930434\n",
-      "  time_since_restore: 238.919837474823\n",
-      "  time_this_iter_s: 23.346596002578735\n",
-      "  time_total_s: 238.919837474823\n",
-      "  timers:\n",
-      "    learn_throughput: 10519.707\n",
-      "    learn_time_ms: 15379.897\n",
-      "    sample_throughput: 19222.536\n",
-      "    sample_time_ms: 8416.788\n",
-      "    update_time_ms: 40.812\n",
-      "  timestamp: 1602167356\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-39\n",
-      "  done: false\n",
-      "  episode_len_mean: 825.4615384615385\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.21514069615333\n",
-      "  episode_reward_min: 114.74747474747485\n",
+      "  episode_len_mean: 841.4780915287245\n",
+      "  episode_reward_max: 282.68686868686825\n",
+      "  episode_reward_mean: 232.2242089837025\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9235042989253998\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005789411393925548\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8218174661908831\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010251943288104874\n",
       "        model: {}\n",
-      "        policy_loss: -0.014859883906319737\n",
-      "        total_loss: 4.004831600189209\n",
-      "        vf_explained_var: 0.9919689893722534\n",
-      "        vf_loss: 4.019112539291382\n",
+      "        policy_loss: -0.02944521393094744\n",
+      "        total_loss: 17.44329833984375\n",
+      "        vf_explained_var: 0.9816536903381348\n",
+      "        vf_loss: 17.47077533176967\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
+      "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.4\n",
-      "    gpu_util_percent0: 0.3125925925925926\n",
+      "    cpu_util_percent: 22.842105263157894\n",
+      "    gpu_util_percent0: 0.4152631578947369\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15996985034496003\n",
-      "    mean_env_wait_ms: 1.675007114196491\n",
-      "    mean_inference_ms: 4.907016710777437\n",
-      "    mean_raw_obs_processing_ms: 0.4317794077781022\n",
-      "  time_since_restore: 262.4391770362854\n",
-      "  time_this_iter_s: 23.519339561462402\n",
-      "  time_total_s: 262.4391770362854\n",
+      "    mean_action_processing_ms: 0.15478313317442852\n",
+      "    mean_env_wait_ms: 1.2174722675860634\n",
+      "    mean_inference_ms: 4.762186846049648\n",
+      "    mean_raw_obs_processing_ms: 0.41139221014187294\n",
+      "  time_since_restore: 340.94291734695435\n",
+      "  time_this_iter_s: 15.413697719573975\n",
+      "  time_total_s: 340.94291734695435\n",
       "  timers:\n",
-      "    learn_throughput: 10544.089\n",
-      "    learn_time_ms: 15344.332\n",
-      "    sample_throughput: 19638.715\n",
-      "    sample_time_ms: 8238.421\n",
-      "    update_time_ms: 40.485\n",
-      "  timestamp: 1602167379\n",
+      "    learn_throughput: 6938.785\n",
+      "    learn_time_ms: 11658.525\n",
+      "    sample_throughput: 22166.284\n",
+      "    sample_time_ms: 3649.507\n",
+      "    update_time_ms: 28.858\n",
+      "  timestamp: 1602414788\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.152428057554\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.18242224402292\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 170\n",
-      "  episodes_total: 2224\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8818272411823272\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005413110228255391\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013095138547942042\n",
-      "        total_loss: 5.083396100997925\n",
-      "        vf_explained_var: 0.9921062588691711\n",
-      "        vf_loss: 5.0959498405456545\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.042857142857144\n",
-      "    gpu_util_percent0: 0.1942857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15960744702974256\n",
-      "    mean_env_wait_ms: 1.677271579492208\n",
-      "    mean_inference_ms: 4.884761150099492\n",
-      "    mean_raw_obs_processing_ms: 0.4305594741365648\n",
-      "  time_since_restore: 286.0365300178528\n",
-      "  time_this_iter_s: 23.597352981567383\n",
-      "  time_total_s: 286.0365300178528\n",
-      "  timers:\n",
-      "    learn_throughput: 10540.17\n",
-      "    learn_time_ms: 15350.038\n",
-      "    sample_throughput: 19693.201\n",
-      "    sample_time_ms: 8215.627\n",
-      "    update_time_ms: 39.264\n",
-      "  timestamp: 1602167403\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 822.2670094936709\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.69313387034907\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 304\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8522311568260192\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005159769672900438\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012773643853142858\n",
-      "        total_loss: 5.1331462383270265\n",
-      "        vf_explained_var: 0.9925912618637085\n",
-      "        vf_loss: 5.145403909683227\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.01481481481482\n",
-      "    gpu_util_percent0: 0.30111111111111116\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15905681990758594\n",
-      "    mean_env_wait_ms: 1.68066117965344\n",
-      "    mean_inference_ms: 4.850479242048183\n",
-      "    mean_raw_obs_processing_ms: 0.4287066632526924\n",
-      "  time_since_restore: 309.50186347961426\n",
-      "  time_this_iter_s: 23.465333461761475\n",
-      "  time_total_s: 309.50186347961426\n",
-      "  timers:\n",
-      "    learn_throughput: 10553.501\n",
-      "    learn_time_ms: 15330.648\n",
-      "    sample_throughput: 19829.166\n",
-      "    sample_time_ms: 8159.294\n",
-      "    update_time_ms: 40.29\n",
-      "  timestamp: 1602167427\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 821.4538346984364\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.94512511563886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8369874477386474\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005370886158198118\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01467731585726142\n",
-      "        total_loss: 3.154995489120483\n",
-      "        vf_explained_var: 0.9942510724067688\n",
-      "        vf_loss: 3.1691357612609865\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.181481481481484\n",
-      "    gpu_util_percent0: 0.3040740740740741\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1588082507195649\n",
-      "    mean_env_wait_ms: 1.6822641931487865\n",
-      "    mean_inference_ms: 4.835116455543884\n",
-      "    mean_raw_obs_processing_ms: 0.42786989591003743\n",
-      "  time_since_restore: 332.9755485057831\n",
-      "  time_this_iter_s: 23.473685026168823\n",
-      "  time_total_s: 332.9755485057831\n",
-      "  timers:\n",
-      "    learn_throughput: 10555.883\n",
-      "    learn_time_ms: 15327.187\n",
-      "    sample_throughput: 19878.044\n",
-      "    sample_time_ms: 8139.232\n",
-      "    update_time_ms: 45.711\n",
-      "  timestamp: 1602167450\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: '11823_00000'\n",
+      "  training_iteration: 22\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     22 |          340.943 | 1779712 |  232.224 |              282.687 |              117.687 |            841.478 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-14\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.854781997187\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.2064917813863\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3521.2922932330825\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-13-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.4711049468331\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 232.7377239804423\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 109\n",
+      "  episodes_total: 2163\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.827689278125763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005339382635429502\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8014648301260812\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010746340666498457\n",
       "        model: {}\n",
-      "        policy_loss: -0.014263017289340495\n",
-      "        total_loss: 3.00002179145813\n",
-      "        vf_explained_var: 0.9941463470458984\n",
-      "        vf_loss: 3.0137508869171143\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
+      "        policy_loss: -0.030137435400060246\n",
+      "        total_loss: 15.846869196210589\n",
+      "        vf_explained_var: 0.9765214920043945\n",
+      "        vf_loss: 15.874937057495117\n",
+      "    num_steps_sampled: 1860608\n",
+      "    num_steps_trained: 1860608\n",
+      "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.57037037037037\n",
-      "    gpu_util_percent0: 0.2274074074074074\n",
+      "    cpu_util_percent: 24.450000000000003\n",
+      "    gpu_util_percent0: 0.37111111111111117\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77037037037037\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15857855076630387\n",
-      "    mean_env_wait_ms: 1.6837618809370547\n",
-      "    mean_inference_ms: 4.820936656490715\n",
-      "    mean_raw_obs_processing_ms: 0.4270767088680792\n",
-      "  time_since_restore: 356.605441570282\n",
-      "  time_this_iter_s: 23.6298930644989\n",
-      "  time_total_s: 356.605441570282\n",
+      "    mean_action_processing_ms: 0.15456071634715085\n",
+      "    mean_env_wait_ms: 1.2180728870997632\n",
+      "    mean_inference_ms: 4.748850502955983\n",
+      "    mean_raw_obs_processing_ms: 0.41069641132000073\n",
+      "  time_since_restore: 356.4750211238861\n",
+      "  time_this_iter_s: 15.532103776931763\n",
+      "  time_total_s: 356.4750211238861\n",
       "  timers:\n",
-      "    learn_throughput: 10553.654\n",
-      "    learn_time_ms: 15330.425\n",
-      "    sample_throughput: 19924.68\n",
-      "    sample_time_ms: 8120.181\n",
-      "    update_time_ms: 47.653\n",
-      "  timestamp: 1602167474\n",
+      "    learn_throughput: 6936.205\n",
+      "    learn_time_ms: 11662.861\n",
+      "    sample_throughput: 22060.373\n",
+      "    sample_time_ms: 3667.028\n",
+      "    update_time_ms: 29.02\n",
+      "  timestamp: 1602414804\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1860608\n",
+      "  training_iteration: 23\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     23 |          356.475 | 1860608 |  232.738 |              285.111 |              117.687 |            839.471 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-38\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3520.273311897106\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-13-39\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0182767624021\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.22214310203864\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 220\n",
-      "  episodes_total: 3064\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 838.866636528029\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 232.95071876084518\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 49\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7918125212192535\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004892151476815343\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.8027615376881191\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011178621756178992\n",
       "        model: {}\n",
-      "        policy_loss: -0.012084704916924238\n",
-      "        total_loss: 4.1488186597824095\n",
-      "        vf_explained_var: 0.9942665100097656\n",
-      "        vf_loss: 4.160414218902588\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.03632411014820848\n",
+      "        total_loss: 5.472229072025844\n",
+      "        vf_explained_var: 0.9705377817153931\n",
+      "        vf_loss: 5.506397928510394\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 24\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.81481481481482\n",
-      "    gpu_util_percent0: 0.3077777777777778\n",
+      "    cpu_util_percent: 23.073684210526316\n",
+      "    gpu_util_percent0: 0.3136842105263158\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.158297804116007\n",
-      "    mean_env_wait_ms: 1.6859562656031242\n",
-      "    mean_inference_ms: 4.803618536248515\n",
-      "    mean_raw_obs_processing_ms: 0.42616514556223817\n",
-      "  time_since_restore: 380.0873718261719\n",
-      "  time_this_iter_s: 23.481930255889893\n",
-      "  time_total_s: 380.0873718261719\n",
+      "    mean_action_processing_ms: 0.1544685852667721\n",
+      "    mean_env_wait_ms: 1.2182278892020562\n",
+      "    mean_inference_ms: 4.742784170217995\n",
+      "    mean_raw_obs_processing_ms: 0.4103645265367753\n",
+      "  time_since_restore: 371.84721636772156\n",
+      "  time_this_iter_s: 15.37219524383545\n",
+      "  time_total_s: 371.84721636772156\n",
       "  timers:\n",
-      "    learn_throughput: 10556.149\n",
-      "    learn_time_ms: 15326.802\n",
-      "    sample_throughput: 19915.022\n",
-      "    sample_time_ms: 8124.119\n",
-      "    update_time_ms: 46.174\n",
-      "  timestamp: 1602167498\n",
+      "    learn_throughput: 6939.484\n",
+      "    learn_time_ms: 11657.352\n",
+      "    sample_throughput: 22095.085\n",
+      "    sample_time_ms: 3661.267\n",
+      "    update_time_ms: 27.78\n",
+      "  timestamp: 1602414819\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 24\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     24 |          371.847 | 1941504 |  232.951 |              285.111 |              117.687 |            838.867 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-01\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3514.3297644539616\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-13-55\n",
       "  done: false\n",
-      "  episode_len_mean: 819.2076552139844\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.34207049396923\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 836.1455696202531\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 233.97161488300716\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.05\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7639730334281921\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004952558875083923\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7634506140436444\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01075770945421287\n",
       "        model: {}\n",
-      "        policy_loss: -0.011812644638121128\n",
-      "        total_loss: 3.641219711303711\n",
-      "        vf_explained_var: 0.9940530061721802\n",
-      "        vf_loss: 3.6527847766876222\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.03034432658127376\n",
+      "        total_loss: 13.53955432346889\n",
+      "        vf_explained_var: 0.9839022755622864\n",
+      "        vf_loss: 13.567823546273369\n",
+      "    num_steps_sampled: 2022400\n",
+      "    num_steps_trained: 2022400\n",
+      "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.58928571428571\n",
-      "    gpu_util_percent0: 0.33428571428571435\n",
+      "    cpu_util_percent: 23.66842105263158\n",
+      "    gpu_util_percent0: 0.3626315789473684\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1579861428053209\n",
-      "    mean_env_wait_ms: 1.6878268274425987\n",
-      "    mean_inference_ms: 4.784786851610141\n",
-      "    mean_raw_obs_processing_ms: 0.4251258149287427\n",
-      "  time_since_restore: 403.5224757194519\n",
-      "  time_this_iter_s: 23.43510389328003\n",
-      "  time_total_s: 403.5224757194519\n",
+      "    mean_action_processing_ms: 0.15418583463624513\n",
+      "    mean_env_wait_ms: 1.219061598042449\n",
+      "    mean_inference_ms: 4.7252878782857275\n",
+      "    mean_raw_obs_processing_ms: 0.40943558152485915\n",
+      "  time_since_restore: 387.34790420532227\n",
+      "  time_this_iter_s: 15.500687837600708\n",
+      "  time_total_s: 387.34790420532227\n",
       "  timers:\n",
-      "    learn_throughput: 10564.477\n",
-      "    learn_time_ms: 15314.719\n",
-      "    sample_throughput: 19933.192\n",
-      "    sample_time_ms: 8116.713\n",
-      "    update_time_ms: 45.777\n",
-      "  timestamp: 1602167521\n",
+      "    learn_throughput: 6935.852\n",
+      "    learn_time_ms: 11663.455\n",
+      "    sample_throughput: 22038.179\n",
+      "    sample_time_ms: 3670.721\n",
+      "    update_time_ms: 29.508\n",
+      "  timestamp: 1602414835\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2022400\n",
+      "  training_iteration: 25\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     25 |          387.348 | 2022400 |  233.972 |              285.111 |              117.687 |            836.146 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-25\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3512.205439330544\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-10\n",
       "  done: false\n",
-      "  episode_len_mean: 818.5304948216341\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.56991956387816\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 835.2358762886598\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 234.24388212017067\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 55\n",
+      "  episodes_total: 2425\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7660917460918426\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005422895355150103\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7645284192902702\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011046201921999454\n",
       "        model: {}\n",
-      "        policy_loss: -0.013137935660779476\n",
-      "        total_loss: 2.9323360919952393\n",
-      "        vf_explained_var: 0.9942866563796997\n",
-      "        vf_loss: 2.94533851146698\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.03211360025618758\n",
+      "        total_loss: 11.541997228349958\n",
+      "        vf_explained_var: 0.9777361750602722\n",
+      "        vf_loss: 11.571977751595634\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.25925925925925\n",
-      "    gpu_util_percent0: 0.36148148148148146\n",
+      "    cpu_util_percent: 24.450000000000003\n",
+      "    gpu_util_percent0: 0.32944444444444443\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.759259259259261\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15781721284272957\n",
-      "    mean_env_wait_ms: 1.6890502862525536\n",
-      "    mean_inference_ms: 4.774409463690571\n",
-      "    mean_raw_obs_processing_ms: 0.4245721837690542\n",
-      "  time_since_restore: 426.88156366348267\n",
-      "  time_this_iter_s: 23.35908794403076\n",
-      "  time_total_s: 426.88156366348267\n",
+      "    mean_action_processing_ms: 0.1540866708881542\n",
+      "    mean_env_wait_ms: 1.2193572901306673\n",
+      "    mean_inference_ms: 4.719611668274306\n",
+      "    mean_raw_obs_processing_ms: 0.4091137457703957\n",
+      "  time_since_restore: 402.7666323184967\n",
+      "  time_this_iter_s: 15.418728113174438\n",
+      "  time_total_s: 402.7666323184967\n",
       "  timers:\n",
-      "    learn_throughput: 10562.111\n",
-      "    learn_time_ms: 15318.149\n",
-      "    sample_throughput: 20027.117\n",
-      "    sample_time_ms: 8078.647\n",
-      "    update_time_ms: 51.49\n",
-      "  timestamp: 1602167545\n",
+      "    learn_throughput: 6927.737\n",
+      "    learn_time_ms: 11677.118\n",
+      "    sample_throughput: 22093.872\n",
+      "    sample_time_ms: 3661.468\n",
+      "    update_time_ms: 31.122\n",
+      "  timestamp: 1602414850\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 26\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     26 |          402.767 | 2103296 |  234.244 |              285.111 |              117.687 |            835.236 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-49\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3508.1211391897314\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-26\n",
       "  done: false\n",
-      "  episode_len_mean: 817.8346629986245\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.78994900865604\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3635\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 834.1194620253165\n",
+      "  episode_reward_max: 285.1111111111108\n",
+      "  episode_reward_mean: 234.74916490857933\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 103\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.761504179239273\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00561123825609684\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7696538737842015\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009899940873895372\n",
       "        model: {}\n",
-      "        policy_loss: -0.01371184946037829\n",
-      "        total_loss: 2.586661458015442\n",
-      "        vf_explained_var: 0.9948149919509888\n",
-      "        vf_loss: 2.6002331018447875\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
+      "        policy_loss: -0.03010483897690262\n",
+      "        total_loss: 7.996133531842913\n",
+      "        vf_explained_var: 0.9810003042221069\n",
+      "        vf_loss: 8.024335248129708\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.98518518518519\n",
-      "    gpu_util_percent0: 0.25\n",
+      "    cpu_util_percent: 23.047368421052635\n",
+      "    gpu_util_percent0: 0.32263157894736844\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.205263157894737\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1576552038626758\n",
-      "    mean_env_wait_ms: 1.6902745430630273\n",
-      "    mean_inference_ms: 4.764639495963006\n",
-      "    mean_raw_obs_processing_ms: 0.42404147010851506\n",
-      "  time_since_restore: 450.4647214412689\n",
-      "  time_this_iter_s: 23.583157777786255\n",
-      "  time_total_s: 450.4647214412689\n",
+      "    mean_action_processing_ms: 0.15393358815170508\n",
+      "    mean_env_wait_ms: 1.2198577496072052\n",
+      "    mean_inference_ms: 4.709424175827586\n",
+      "    mean_raw_obs_processing_ms: 0.40858386146833126\n",
+      "  time_since_restore: 418.18699383735657\n",
+      "  time_this_iter_s: 15.420361518859863\n",
+      "  time_total_s: 418.18699383735657\n",
       "  timers:\n",
-      "    learn_throughput: 10558.952\n",
-      "    learn_time_ms: 15322.733\n",
-      "    sample_throughput: 20107.322\n",
-      "    sample_time_ms: 8046.422\n",
-      "    update_time_ms: 53.421\n",
-      "  timestamp: 1602167569\n",
+      "    learn_throughput: 6928.452\n",
+      "    learn_time_ms: 11675.912\n",
+      "    sample_throughput: 22068.825\n",
+      "    sample_time_ms: 3665.623\n",
+      "    update_time_ms: 33.599\n",
+      "  timestamp: 1602414866\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 27\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     27 |          418.187 | 2184192 |  234.749 |              285.111 |              117.687 |            834.119 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-12\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3502.2642506606267\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-41\n",
       "  done: false\n",
-      "  episode_len_mean: 816.6687881873727\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.22543664753442\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 293\n",
-      "  episodes_total: 3928\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 832.1322652757079\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 235.60601920847813\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 156\n",
+      "  episodes_total: 2684\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7176933705806732\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004935431573539972\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7382196017674038\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010356013397020953\n",
       "        model: {}\n",
-      "        policy_loss: -0.011507348460145294\n",
-      "        total_loss: 3.7333247661590576\n",
-      "        vf_explained_var: 0.9947683215141296\n",
-      "        vf_loss: 3.744708704948425\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
+      "        policy_loss: -0.028260654636791775\n",
+      "        total_loss: 13.343521799360003\n",
+      "        vf_explained_var: 0.9828724265098572\n",
+      "        vf_loss: 13.36978530883789\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 28\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92962962962963\n",
-      "    gpu_util_percent0: 0.22925925925925927\n",
+      "    cpu_util_percent: 23.80526315789474\n",
+      "    gpu_util_percent0: 0.35578947368421054\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15738510281829127\n",
-      "    mean_env_wait_ms: 1.6923950386450304\n",
-      "    mean_inference_ms: 4.748233050103123\n",
-      "    mean_raw_obs_processing_ms: 0.4231474863161252\n",
-      "  time_since_restore: 473.9994788169861\n",
-      "  time_this_iter_s: 23.534757375717163\n",
-      "  time_total_s: 473.9994788169861\n",
+      "    mean_action_processing_ms: 0.1537085266981266\n",
+      "    mean_env_wait_ms: 1.220682130353048\n",
+      "    mean_inference_ms: 4.6951938469222805\n",
+      "    mean_raw_obs_processing_ms: 0.40782552885921136\n",
+      "  time_since_restore: 433.7264211177826\n",
+      "  time_this_iter_s: 15.539427280426025\n",
+      "  time_total_s: 433.7264211177826\n",
       "  timers:\n",
-      "    learn_throughput: 10546.772\n",
-      "    learn_time_ms: 15340.429\n",
-      "    sample_throughput: 20112.723\n",
-      "    sample_time_ms: 8044.261\n",
-      "    update_time_ms: 53.96\n",
-      "  timestamp: 1602167592\n",
+      "    learn_throughput: 6914.972\n",
+      "    learn_time_ms: 11698.674\n",
+      "    sample_throughput: 22014.804\n",
+      "    sample_time_ms: 3674.618\n",
+      "    update_time_ms: 33.996\n",
+      "  timestamp: 1602414881\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 28\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     28 |          433.726 | 2265088 |  235.606 |              288.899 |              117.687 |            832.132 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-36\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3501.7143393393394\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-14-57\n",
       "  done: false\n",
-      "  episode_len_mean: 815.9362220058423\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.68833171048362\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 831.9573916265283\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 235.6916291480944\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 15\n",
+      "  episodes_total: 2699\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6961194634437561\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0054001738782972096\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.741259115082877\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011515548718827111\n",
       "        model: {}\n",
-      "        policy_loss: -0.013575149234384298\n",
-      "        total_loss: 2.1967584609985353\n",
-      "        vf_explained_var: 0.9954622387886047\n",
-      "        vf_loss: 2.210266089439392\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
+      "        policy_loss: -0.0386028066277504\n",
+      "        total_loss: 5.7686494418552945\n",
+      "        vf_explained_var: 0.9847227931022644\n",
+      "        vf_loss: 5.805023602076939\n",
+      "    num_steps_sampled: 2345984\n",
+      "    num_steps_trained: 2345984\n",
+      "  iterations_since_restore: 29\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.440740740740736\n",
-      "    gpu_util_percent0: 0.29666666666666663\n",
+      "    cpu_util_percent: 24.344444444444445\n",
+      "    gpu_util_percent0: 0.3016666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.211111111111112\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15722895249997093\n",
-      "    mean_env_wait_ms: 1.6936030533075188\n",
-      "    mean_inference_ms: 4.738907510439971\n",
-      "    mean_raw_obs_processing_ms: 0.42262820408828605\n",
-      "  time_since_restore: 497.52709674835205\n",
-      "  time_this_iter_s: 23.527617931365967\n",
-      "  time_total_s: 497.52709674835205\n",
+      "    mean_action_processing_ms: 0.15368784955660025\n",
+      "    mean_env_wait_ms: 1.220787727557082\n",
+      "    mean_inference_ms: 4.693690857541116\n",
+      "    mean_raw_obs_processing_ms: 0.40773859312733546\n",
+      "  time_since_restore: 449.04663133621216\n",
+      "  time_this_iter_s: 15.320210218429565\n",
+      "  time_total_s: 449.04663133621216\n",
       "  timers:\n",
-      "    learn_throughput: 10537.753\n",
-      "    learn_time_ms: 15353.558\n",
-      "    sample_throughput: 20139.989\n",
-      "    sample_time_ms: 8033.371\n",
-      "    update_time_ms: 52.995\n",
-      "  timestamp: 1602167616\n",
+      "    learn_throughput: 6918.65\n",
+      "    learn_time_ms: 11692.455\n",
+      "    sample_throughput: 22099.217\n",
+      "    sample_time_ms: 3660.582\n",
+      "    update_time_ms: 32.081\n",
+      "  timestamp: 1602414897\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2345984\n",
+      "  training_iteration: 29\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     29 |          449.047 | 2345984 |  235.692 |              288.899 |              117.687 |            831.957 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-00\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3496.444998220007\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-13\n",
       "  done: false\n",
-      "  episode_len_mean: 815.2585560243788\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.9339172313856\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 830.2095639943741\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 236.55434087712558\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 145\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7063014328479766\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005521039292216301\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7333477054323468\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009345830285123416\n",
       "        model: {}\n",
-      "        policy_loss: -0.013345666276291013\n",
-      "        total_loss: 2.40686240196228\n",
-      "        vf_explained_var: 0.994661808013916\n",
-      "        vf_loss: 2.4201390743255615\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
+      "        policy_loss: -0.027462404487388476\n",
+      "        total_loss: 9.17048522404262\n",
+      "        vf_explained_var: 0.985461413860321\n",
+      "        vf_loss: 9.196151460920062\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 30\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.3\n",
-      "    gpu_util_percent0: 0.3596428571428571\n",
+      "    cpu_util_percent: 21.994736842105265\n",
+      "    gpu_util_percent0: 0.3536842105263157\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.760714285714286\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15710538677505165\n",
-      "    mean_env_wait_ms: 1.694637493002915\n",
-      "    mean_inference_ms: 4.731284261187251\n",
-      "    mean_raw_obs_processing_ms: 0.42220494507105216\n",
-      "  time_since_restore: 521.2907056808472\n",
-      "  time_this_iter_s: 23.763608932495117\n",
-      "  time_total_s: 521.2907056808472\n",
+      "    mean_action_processing_ms: 0.1534987590693203\n",
+      "    mean_env_wait_ms: 1.2214597079228968\n",
+      "    mean_inference_ms: 4.681632229679235\n",
+      "    mean_raw_obs_processing_ms: 0.4070969874551114\n",
+      "  time_since_restore: 464.6360778808594\n",
+      "  time_this_iter_s: 15.589446544647217\n",
+      "  time_total_s: 464.6360778808594\n",
       "  timers:\n",
-      "    learn_throughput: 10529.291\n",
-      "    learn_time_ms: 15365.897\n",
-      "    sample_throughput: 20152.527\n",
-      "    sample_time_ms: 8028.373\n",
-      "    update_time_ms: 60.563\n",
-      "  timestamp: 1602167640\n",
+      "    learn_throughput: 6916.731\n",
+      "    learn_time_ms: 11695.698\n",
+      "    sample_throughput: 22056.083\n",
+      "    sample_time_ms: 3667.741\n",
+      "    update_time_ms: 30.853\n",
+      "  timestamp: 1602414913\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 30\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     30 |          464.636 | 2426880 |  236.554 |              288.899 |              117.687 |             830.21 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-24\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3491.385887913572\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-28\n",
       "  done: false\n",
-      "  episode_len_mean: 814.5122444394518\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.18438711990723\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4451\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 828.4894894894895\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 237.34450612228375\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 153\n",
+      "  episodes_total: 2997\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.687007212638855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005151082994416356\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7141761098589215\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010538498205798013\n",
       "        model: {}\n",
-      "        policy_loss: -0.0136242700740695\n",
-      "        total_loss: 2.3987212419509887\n",
-      "        vf_explained_var: 0.9956458210945129\n",
-      "        vf_loss: 2.412281060218811\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
+      "        policy_loss: -0.03002121073326894\n",
+      "        total_loss: 12.987276213509697\n",
+      "        vf_explained_var: 0.9814284443855286\n",
+      "        vf_loss: 13.015260968889509\n",
+      "    num_steps_sampled: 2507776\n",
+      "    num_steps_trained: 2507776\n",
+      "  iterations_since_restore: 31\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.87777777777778\n",
-      "    gpu_util_percent0: 0.32259259259259254\n",
+      "    cpu_util_percent: 23.484210526315795\n",
+      "    gpu_util_percent0: 0.3489473684210526\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15697868978775206\n",
-      "    mean_env_wait_ms: 1.6959996633636125\n",
-      "    mean_inference_ms: 4.723299684373984\n",
-      "    mean_raw_obs_processing_ms: 0.42177767922029563\n",
-      "  time_since_restore: 544.7509255409241\n",
-      "  time_this_iter_s: 23.460219860076904\n",
-      "  time_total_s: 544.7509255409241\n",
+      "    mean_action_processing_ms: 0.1533164741883748\n",
+      "    mean_env_wait_ms: 1.2222260271011502\n",
+      "    mean_inference_ms: 4.669791183442398\n",
+      "    mean_raw_obs_processing_ms: 0.4064721500356665\n",
+      "  time_since_restore: 480.01299381256104\n",
+      "  time_this_iter_s: 15.37691593170166\n",
+      "  time_total_s: 480.01299381256104\n",
       "  timers:\n",
-      "    learn_throughput: 10523.637\n",
-      "    learn_time_ms: 15374.152\n",
-      "    sample_throughput: 20153.695\n",
-      "    sample_time_ms: 8027.908\n",
-      "    update_time_ms: 54.413\n",
-      "  timestamp: 1602167664\n",
+      "    learn_throughput: 6914.421\n",
+      "    learn_time_ms: 11699.606\n",
+      "    sample_throughput: 22037.607\n",
+      "    sample_time_ms: 3670.816\n",
+      "    update_time_ms: 32.095\n",
+      "  timestamp: 1602414928\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2507776\n",
+      "  training_iteration: 31\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     31 |          480.013 | 2507776 |  237.345 |              288.899 |              117.687 |            828.489 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-48\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3491.1973728528124\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-44\n",
       "  done: false\n",
-      "  episode_len_mean: 813.3535864978903\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.57533989685885\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 828.3931424766978\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 237.37692840522388\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 7\n",
+      "  episodes_total: 3004\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6324166178703308\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048749387264251706\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7138987694467817\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011370175118957247\n",
       "        model: {}\n",
-      "        policy_loss: -0.011797640426084399\n",
-      "        total_loss: 2.6533204078674317\n",
-      "        vf_explained_var: 0.9955232739448547\n",
-      "        vf_loss: 2.66505708694458\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
+      "        policy_loss: -0.04013798572123051\n",
+      "        total_loss: 4.070477996553693\n",
+      "        vf_explained_var: 0.9827483892440796\n",
+      "        vf_loss: 4.10841349193028\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 32\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.074074074074076\n",
-      "    gpu_util_percent0: 0.3251851851851852\n",
+      "    cpu_util_percent: 23.51111111111111\n",
+      "    gpu_util_percent0: 0.36277777777777775\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.222222222222222\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15677630383088909\n",
-      "    mean_env_wait_ms: 1.6975983446472827\n",
-      "    mean_inference_ms: 4.710750302441915\n",
-      "    mean_raw_obs_processing_ms: 0.421060709542158\n",
-      "  time_since_restore: 568.4359018802643\n",
-      "  time_this_iter_s: 23.68497633934021\n",
-      "  time_total_s: 568.4359018802643\n",
+      "    mean_action_processing_ms: 0.1533064561571048\n",
+      "    mean_env_wait_ms: 1.2222521564882434\n",
+      "    mean_inference_ms: 4.6691816857432045\n",
+      "    mean_raw_obs_processing_ms: 0.40643459995117087\n",
+      "  time_since_restore: 495.2956557273865\n",
+      "  time_this_iter_s: 15.28266191482544\n",
+      "  time_total_s: 495.2956557273865\n",
       "  timers:\n",
-      "    learn_throughput: 10517.772\n",
-      "    learn_time_ms: 15382.726\n",
-      "    sample_throughput: 20124.264\n",
-      "    sample_time_ms: 8039.648\n",
-      "    update_time_ms: 48.571\n",
-      "  timestamp: 1602167688\n",
+      "    learn_throughput: 6922.456\n",
+      "    learn_time_ms: 11686.026\n",
+      "    sample_throughput: 22035.276\n",
+      "    sample_time_ms: 3671.204\n",
+      "    update_time_ms: 31.844\n",
+      "  timestamp: 1602414944\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 32\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     32 |          495.296 | 2588672 |  237.377 |              288.899 |              117.687 |            828.393 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-11\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3486.02176\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-15-59\n",
       "  done: false\n",
-      "  episode_len_mean: 812.6929358922009\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.80383252698485\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4898\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 826.7759493670886\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 238.20249968034767\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 156\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.00625\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6476718962192536\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004980697343125939\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.7064724820000785\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009518824517726898\n",
       "        model: {}\n",
-      "        policy_loss: -0.012937380420044064\n",
-      "        total_loss: 2.2160698890686037\n",
-      "        vf_explained_var: 0.9949172735214233\n",
-      "        vf_loss: 2.2289761781692503\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
+      "        policy_loss: -0.029149129454578673\n",
+      "        total_loss: 8.81074333190918\n",
+      "        vf_explained_var: 0.988771378993988\n",
+      "        vf_loss: 8.838059425354004\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 33\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.93703703703704\n",
-      "    gpu_util_percent0: 0.2511111111111111\n",
+      "    cpu_util_percent: 24.18888888888889\n",
+      "    gpu_util_percent0: 0.32944444444444443\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15667803602924033\n",
-      "    mean_env_wait_ms: 1.6985389146300989\n",
-      "    mean_inference_ms: 4.704622565044838\n",
-      "    mean_raw_obs_processing_ms: 0.420720785257639\n",
-      "  time_since_restore: 592.1190402507782\n",
-      "  time_this_iter_s: 23.683138370513916\n",
-      "  time_total_s: 592.1190402507782\n",
+      "    mean_action_processing_ms: 0.1531353521503298\n",
+      "    mean_env_wait_ms: 1.2230012031400455\n",
+      "    mean_inference_ms: 4.657997312372352\n",
+      "    mean_raw_obs_processing_ms: 0.405836882924193\n",
+      "  time_since_restore: 510.6310017108917\n",
+      "  time_this_iter_s: 15.335345983505249\n",
+      "  time_total_s: 510.6310017108917\n",
       "  timers:\n",
-      "    learn_throughput: 10525.475\n",
-      "    learn_time_ms: 15371.468\n",
-      "    sample_throughput: 20083.377\n",
-      "    sample_time_ms: 8056.016\n",
-      "    update_time_ms: 47.817\n",
-      "  timestamp: 1602167711\n",
+      "    learn_throughput: 6922.808\n",
+      "    learn_time_ms: 11685.432\n",
+      "    sample_throughput: 22142.487\n",
+      "    sample_time_ms: 3653.429\n",
+      "    update_time_ms: 30.31\n",
+      "  timestamp: 1602414959\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 33\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     33 |          510.631 | 2669568 |  238.202 |              288.899 |              117.687 |            826.776 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-35\n",
-      "  done: true\n",
-      "  episode_len_mean: 812.0104784499803\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 234.07366667864886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 160\n",
-      "  episodes_total: 5058\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3481.9266871165646\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-16-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.322913505311\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 238.75570576784526\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 135\n",
+      "  episodes_total: 3295\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.003125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6387091696262359\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00521918865852058\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6861251592636108\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009984563237854413\n",
       "        model: {}\n",
-      "        policy_loss: -0.013382896583061665\n",
-      "        total_loss: 2.0056067228317263\n",
-      "        vf_explained_var: 0.9955011606216431\n",
-      "        vf_loss: 2.0189733505249023\n",
-      "    num_steps_sampled: 4206592\n",
-      "    num_steps_trained: 4206592\n",
-      "  iterations_since_restore: 26\n",
+      "        policy_loss: -0.028198028781584332\n",
+      "        total_loss: 13.189177240644183\n",
+      "        vf_explained_var: 0.9802125096321106\n",
+      "        vf_loss: 13.21544715336391\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 34\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.729629629629635\n",
-      "    gpu_util_percent0: 0.267037037037037\n",
+      "    cpu_util_percent: 23.45263157894737\n",
+      "    gpu_util_percent0: 0.3442105263157894\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "    ram_util_percent: 6.210526315789474\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15658306876779257\n",
-      "    mean_env_wait_ms: 1.6995085455679213\n",
-      "    mean_inference_ms: 4.6987769399539845\n",
-      "    mean_raw_obs_processing_ms: 0.42039589930108456\n",
-      "  time_since_restore: 615.6618909835815\n",
-      "  time_this_iter_s: 23.542850732803345\n",
-      "  time_total_s: 615.6618909835815\n",
+      "    mean_action_processing_ms: 0.1529844828154928\n",
+      "    mean_env_wait_ms: 1.223661539893914\n",
+      "    mean_inference_ms: 4.648884962993294\n",
+      "    mean_raw_obs_processing_ms: 0.4053319879620939\n",
+      "  time_since_restore: 526.1448483467102\n",
+      "  time_this_iter_s: 15.513846635818481\n",
+      "  time_total_s: 526.1448483467102\n",
       "  timers:\n",
-      "    learn_throughput: 10524.21\n",
-      "    learn_time_ms: 15373.315\n",
-      "    sample_throughput: 20076.608\n",
-      "    sample_time_ms: 8058.732\n",
-      "    update_time_ms: 48.59\n",
-      "  timestamp: 1602167735\n",
+      "    learn_throughput: 6915.508\n",
+      "    learn_time_ms: 11697.767\n",
+      "    sample_throughput: 22132.635\n",
+      "    sample_time_ms: 3655.055\n",
+      "    update_time_ms: 30.002\n",
+      "  timestamp: 1602414975\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4206592\n",
-      "  training_iteration: 26\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 34\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32990\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3204.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 630\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 279.83838\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.88544\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "2020-10-08 14:35:46,970 - wandb.wandb_agent - INFO - Cleaning up finished run: w8c2p6ff\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 32768\n",
-      "2020-10-08 14:35:47,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=32768\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/y6ys1sgz\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_143549-y6ys1sgz\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:35:51,552\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:35:52,322 - wandb.wandb_agent - INFO - Running runs: ['y6ys1sgz']\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     34 |          526.145 | 2750464 |  238.756 |              288.899 |              117.687 |            825.323 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=62403)\u001b[0m 2020-10-08 14:35:54,588\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-36-25\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3480.9317697228144\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-16-30\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 825.1428571428571\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 238.89698065647423\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 23\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1634249687194824\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0036954283714294434\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6846187114715576\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010950947712574686\n",
       "        model: {}\n",
-      "        policy_loss: -0.006869117938913405\n",
-      "        total_loss: 9.30032901763916\n",
-      "        vf_explained_var: 0.7174946069717407\n",
-      "        vf_loss: 9.306459045410156\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.03858303331903049\n",
+      "        total_loss: 3.6150619983673096\n",
+      "        vf_explained_var: 0.9793863296508789\n",
+      "        vf_loss: 3.6515232835497176\n",
+      "    num_steps_sampled: 2831360\n",
+      "    num_steps_trained: 2831360\n",
+      "  iterations_since_restore: 35\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 39.282758620689656\n",
-      "    gpu_util_percent0: 0.27758620689655167\n",
+      "    cpu_util_percent: 22.778947368421054\n",
+      "    gpu_util_percent0: 0.29\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003448275862068966\n",
-      "    ram_util_percent: 9.486206896551723\n",
-      "    vram_util_percent0: 0.30692086721480194\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1757240295410156\n",
-      "    mean_env_wait_ms: 1.64632514878238\n",
-      "    mean_inference_ms: 5.702464303031089\n",
-      "    mean_raw_obs_processing_ms: 0.4785182454697177\n",
-      "  time_since_restore: 24.381270170211792\n",
-      "  time_this_iter_s: 24.381270170211792\n",
-      "  time_total_s: 24.381270170211792\n",
+      "    mean_action_processing_ms: 0.15297329920887245\n",
+      "    mean_env_wait_ms: 1.2237476763616006\n",
+      "    mean_inference_ms: 4.6474416361949995\n",
+      "    mean_raw_obs_processing_ms: 0.4052684775842852\n",
+      "  time_since_restore: 541.7210958003998\n",
+      "  time_this_iter_s: 15.576247453689575\n",
+      "  time_total_s: 541.7210958003998\n",
       "  timers:\n",
-      "    learn_throughput: 10955.585\n",
-      "    learn_time_ms: 14767.992\n",
-      "    sample_throughput: 16976.731\n",
-      "    sample_time_ms: 9530.221\n",
-      "    update_time_ms: 49.441\n",
-      "  timestamp: 1602167785\n",
+      "    learn_throughput: 6910.252\n",
+      "    learn_time_ms: 11706.663\n",
+      "    sample_throughput: 22141.4\n",
+      "    sample_time_ms: 3653.608\n",
+      "    update_time_ms: 30.476\n",
+      "  timestamp: 1602414990\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2831360\n",
+      "  training_iteration: 35\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     35 |          541.721 | 2831360 |  238.897 |              288.899 |              117.687 |            825.143 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-36-48\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3476.683812845103\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-11_11-16-46\n",
       "  done: false\n",
-      "  episode_len_mean: 867.5569620253165\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 226.67721518987318\n",
-      "  episode_reward_min: 115.78787878787875\n",
+      "  episode_len_mean: 823.734752589183\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 239.4782868965837\n",
+      "  episode_reward_min: 117.68686868686848\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1362101554870605\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006970350444316864\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6705271346228463\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009495977844510759\n",
       "        model: {}\n",
-      "        policy_loss: -0.009705625101923942\n",
-      "        total_loss: 10.32210750579834\n",
-      "        vf_explained_var: 0.8451136350631714\n",
-      "        vf_loss: 10.331116104125977\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.027984988210456713\n",
+      "        total_loss: 10.82583590916225\n",
+      "        vf_explained_var: 0.9875221252441406\n",
+      "        vf_loss: 10.851988383701869\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 36\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.548148148148144\n",
-      "    gpu_util_percent0: 0.2866666666666667\n",
+      "    cpu_util_percent: 23.383333333333336\n",
+      "    gpu_util_percent0: 0.3\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.733333333333334\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.222222222222222\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17100616576939356\n",
-      "    mean_env_wait_ms: 1.647485749663841\n",
-      "    mean_inference_ms: 5.449976105277291\n",
-      "    mean_raw_obs_processing_ms: 0.4667153357279003\n",
-      "  time_since_restore: 47.252567291259766\n",
-      "  time_this_iter_s: 22.871297121047974\n",
-      "  time_total_s: 47.252567291259766\n",
+      "    mean_action_processing_ms: 0.15282164445607432\n",
+      "    mean_env_wait_ms: 1.2244793275638173\n",
+      "    mean_inference_ms: 4.63757056643333\n",
+      "    mean_raw_obs_processing_ms: 0.4047337000957116\n",
+      "  time_since_restore: 557.1422667503357\n",
+      "  time_this_iter_s: 15.421170949935913\n",
+      "  time_total_s: 557.1422667503357\n",
       "  timers:\n",
-      "    learn_throughput: 11041.238\n",
-      "    learn_time_ms: 14653.429\n",
-      "    sample_throughput: 18199.954\n",
-      "    sample_time_ms: 8889.693\n",
-      "    update_time_ms: 42.206\n",
-      "  timestamp: 1602167808\n",
+      "    learn_throughput: 6913.815\n",
+      "    learn_time_ms: 11700.631\n",
+      "    sample_throughput: 22094.423\n",
+      "    sample_time_ms: 3661.376\n",
+      "    update_time_ms: 28.494\n",
+      "  timestamp: 1602415006\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 36\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     36 |          557.142 | 2912256 |  239.478 |              288.899 |              117.687 |            823.735 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-11\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3474.3468811741463\n",
+      "    time_step_min: 3172\n",
+      "  date: 2020-10-11_11-17-02\n",
       "  done: false\n",
-      "  episode_len_mean: 859.824894514768\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.24830584324238\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 822.8353828954723\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 239.84187317557905\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 102\n",
+      "  episodes_total: 3578\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.12405526638031\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006674189120531082\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.6732551966394696\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010459980927407742\n",
       "        model: {}\n",
-      "        policy_loss: -0.010977230872958899\n",
-      "        total_loss: 12.676021194458007\n",
-      "        vf_explained_var: 0.8899718523025513\n",
-      "        vf_loss: 12.686330986022949\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.02988721669784614\n",
+      "        total_loss: 12.020891189575195\n",
+      "        vf_explained_var: 0.9796990156173706\n",
+      "        vf_loss: 12.04875387464251\n",
+      "    num_steps_sampled: 2993152\n",
+      "    num_steps_trained: 2993152\n",
+      "  iterations_since_restore: 37\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.05555555555555\n",
-      "    gpu_util_percent0: 0.2644444444444444\n",
+      "    cpu_util_percent: 22.978947368421053\n",
+      "    gpu_util_percent0: 0.3431578947368421\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16808367664964877\n",
-      "    mean_env_wait_ms: 1.6489405832417077\n",
-      "    mean_inference_ms: 5.307994845910706\n",
-      "    mean_raw_obs_processing_ms: 0.45738673020424264\n",
-      "  time_since_restore: 70.47958087921143\n",
-      "  time_this_iter_s: 23.22701358795166\n",
-      "  time_total_s: 70.47958087921143\n",
+      "    mean_action_processing_ms: 0.1527189275009953\n",
+      "    mean_env_wait_ms: 1.2249342826484029\n",
+      "    mean_inference_ms: 4.63159545625294\n",
+      "    mean_raw_obs_processing_ms: 0.4044093019860797\n",
+      "  time_since_restore: 572.7838077545166\n",
+      "  time_this_iter_s: 15.641541004180908\n",
+      "  time_total_s: 572.7838077545166\n",
       "  timers:\n",
-      "    learn_throughput: 11042.229\n",
-      "    learn_time_ms: 14652.115\n",
-      "    sample_throughput: 18479.026\n",
-      "    sample_time_ms: 8755.44\n",
-      "    update_time_ms: 41.454\n",
-      "  timestamp: 1602167831\n",
+      "    learn_throughput: 6895.582\n",
+      "    learn_time_ms: 11731.569\n",
+      "    sample_throughput: 22149.093\n",
+      "    sample_time_ms: 3652.339\n",
+      "    update_time_ms: 28.275\n",
+      "  timestamp: 1602415022\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2993152\n",
+      "  training_iteration: 37\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     37 |          572.784 | 2993152 |  239.842 |              288.899 |              117.687 |            822.835 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-34\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3472.9027507641013\n",
+      "    time_step_min: 3172\n",
+      "  date: 2020-10-11_11-17-17\n",
       "  done: false\n",
-      "  episode_len_mean: 853.2689873417721\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.76543920214786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 822.44551458448\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 240.0620375466274\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 56\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0947366952896118\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005848201550543308\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.657863906451634\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010496733177985464\n",
       "        model: {}\n",
-      "        policy_loss: -0.01150441262871027\n",
-      "        total_loss: 13.476828002929688\n",
-      "        vf_explained_var: 0.9183750152587891\n",
-      "        vf_loss: 13.487747383117675\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.0346918199211359\n",
+      "        total_loss: 4.282534122467041\n",
+      "        vf_explained_var: 0.9811368584632874\n",
+      "        vf_loss: 4.315192358834403\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 38\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.855555555555554\n",
-      "    gpu_util_percent0: 0.27814814814814814\n",
+      "    cpu_util_percent: 23.42105263157895\n",
+      "    gpu_util_percent0: 0.3310526315789474\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744444444444445\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.215789473684211\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16618084056987167\n",
-      "    mean_env_wait_ms: 1.652121993019246\n",
-      "    mean_inference_ms: 5.206010003773685\n",
-      "    mean_raw_obs_processing_ms: 0.45115332512960615\n",
-      "  time_since_restore: 93.41903614997864\n",
-      "  time_this_iter_s: 22.939455270767212\n",
-      "  time_total_s: 93.41903614997864\n",
+      "    mean_action_processing_ms: 0.15268028988154853\n",
+      "    mean_env_wait_ms: 1.2251785091633063\n",
+      "    mean_inference_ms: 4.628354002228403\n",
+      "    mean_raw_obs_processing_ms: 0.4042345731914658\n",
+      "  time_since_restore: 588.1606180667877\n",
+      "  time_this_iter_s: 15.376810312271118\n",
+      "  time_total_s: 588.1606180667877\n",
       "  timers:\n",
-      "    learn_throughput: 11054.503\n",
-      "    learn_time_ms: 14635.845\n",
-      "    sample_throughput: 18733.219\n",
-      "    sample_time_ms: 8636.637\n",
-      "    update_time_ms: 36.312\n",
-      "  timestamp: 1602167854\n",
+      "    learn_throughput: 6899.122\n",
+      "    learn_time_ms: 11725.55\n",
+      "    sample_throughput: 22216.641\n",
+      "    sample_time_ms: 3641.234\n",
+      "    update_time_ms: 28.207\n",
+      "  timestamp: 1602415037\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 38\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | RUNNING  | 172.17.0.4:11517 |     38 |          588.161 | 3074048 |  240.062 |              288.899 |              117.687 |            822.446 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_ed8b7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2431289640592\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.57511691972567\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 314\n",
-      "  episodes_total: 946\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "    time_step_max: 4279\n",
+      "    time_step_mean: 3469.076923076923\n",
+      "    time_step_min: 3172\n",
+      "  date: 2020-10-11_11-17-33\n",
+      "  done: true\n",
+      "  episode_len_mean: 821.0094936708861\n",
+      "  episode_reward_max: 288.8989898989897\n",
+      "  episode_reward_mean: 240.60125783147927\n",
+      "  episode_reward_min: 117.68686868686848\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: ee8f92ed3fe143e58f93e958dfaea929\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0704583883285523\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006159011553972959\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.642860301903316\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.009801473202449935\n",
       "        model: {}\n",
-      "        policy_loss: -0.01097527714446187\n",
-      "        total_loss: 18.48041114807129\n",
-      "        vf_explained_var: 0.9505600929260254\n",
-      "        vf_loss: 18.490771102905274\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.027483725188566104\n",
+      "        total_loss: 13.555409022739955\n",
+      "        vf_explained_var: 0.9839209318161011\n",
+      "        vf_loss: 13.580996922084264\n",
+      "    num_steps_sampled: 3154944\n",
+      "    num_steps_trained: 3154944\n",
+      "  iterations_since_restore: 39\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.67142857142857\n",
-      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    cpu_util_percent: 24.233333333333334\n",
+      "    gpu_util_percent0: 0.2744444444444445\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.739285714285716\n",
-      "    vram_util_percent0: 0.355608396195474\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "    ram_util_percent: 6.216666666666667\n",
+      "    vram_util_percent0: 0.2038373237126927\n",
+      "    vram_util_percent1: 0.0009075233687267447\n",
+      "    vram_util_percent2: 0.0009075233687267447\n",
+      "  pid: 11517\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1637216679032345\n",
-      "    mean_env_wait_ms: 1.6595417244788717\n",
-      "    mean_inference_ms: 5.075327722233796\n",
-      "    mean_raw_obs_processing_ms: 0.443719930951552\n",
-      "  time_since_restore: 116.6165714263916\n",
-      "  time_this_iter_s: 23.197535276412964\n",
-      "  time_total_s: 116.6165714263916\n",
+      "    mean_action_processing_ms: 0.15254677791204402\n",
+      "    mean_env_wait_ms: 1.2258875543427181\n",
+      "    mean_inference_ms: 4.619694203955828\n",
+      "    mean_raw_obs_processing_ms: 0.4037668223539728\n",
+      "  time_since_restore: 603.536078453064\n",
+      "  time_this_iter_s: 15.375460386276245\n",
+      "  time_total_s: 603.536078453064\n",
       "  timers:\n",
-      "    learn_throughput: 11077.95\n",
-      "    learn_time_ms: 14604.868\n",
-      "    sample_throughput: 18764.263\n",
-      "    sample_time_ms: 8622.347\n",
-      "    update_time_ms: 48.444\n",
-      "  timestamp: 1602167877\n",
+      "    learn_throughput: 6895.914\n",
+      "    learn_time_ms: 11731.006\n",
+      "    sample_throughput: 22231.775\n",
+      "    sample_time_ms: 3638.756\n",
+      "    update_time_ms: 30.262\n",
+      "  timestamp: 1602415053\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3154944\n",
+      "  training_iteration: 39\n",
+      "  trial_id: ed8b7_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | TERMINATED |       |     39 |          603.536 | 3154944 |  240.601 |              288.899 |              117.687 |            821.009 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 46.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed8b7_00000 | TERMINATED |       |     39 |          603.536 | 3154944 |  240.601 |              288.899 |              117.687 |            821.009 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
+      "    return self._engine.get_loc(casted_key)\n",
+      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "The above exception was the direct cause of the following exception:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 57, in train_func\n",
+      "    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 92, in dataframe\n",
+      "    rows = self._retrieve_rows(metric=metric, mode=mode)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 254, in _retrieve_rows\n",
+      "    idx = df[metric].idxmin()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
+      "    indexer = self.columns.get_loc(key)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
+      "    raise KeyError(key) from err\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 11266\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_110715-y7fi985h/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_110715-y7fi985h/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpleasant-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/y7fi985h\u001b[0m\n",
+      "2020-10-11 11:17:44,012 - wandb.wandb_agent - INFO - Cleaning up finished run: y7fi985h\n",
+      "2020-10-11 11:17:44,320 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:17:44,320 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\trollout_fragment_length: 512\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "\tuse_gae: False\n",
+      "2020-10-11 11:17:44,324 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --rollout_fragment_length=512 --sgd_minibatch_size=12112 --use_gae=False\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwinter-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/m8f9dubo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ege8euj2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_111746-ege8euj2\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 11:17:48,204\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:17:49,338 - wandb.wandb_agent - INFO - Running runs: ['ege8euj2']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 32.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_658bd_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "2020-10-11 11:17:51,139\tERROR trial_runner.py:567 -- Trial PPO_jss_env_658bd_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::PPO.train()\u001b[39m (pid=52949, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 445, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 101, in __init__\n",
+      "    Trainer.__init__(self, config, env, logger_creator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 476, in __init__\n",
+      "    super().__init__(config, logger_creator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 249, in __init__\n",
+      "    self.setup(copy.deepcopy(self.config))\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 629, in setup\n",
+      "    self._init(self.config, self.env_creator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 107, in _init\n",
+      "    validate_config(config)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/ppo/ppo.py\", line 127, in validate_config\n",
+      "    raise ValueError(\n",
+      "ValueError: Episode truncation is not supported without a value function. Consider setting batch_mode=complete_episodes.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 32.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/536.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_658bd_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_658bd_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_658bd_00000_0_2020-10-11_11-17-49/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_658bd_00000])\n",
+      "\u001b[2m\u001b[36m(pid=52949)\u001b[0m 2020-10-11 11:17:51,127\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 52730\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_111746-ege8euj2/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_111746-ege8euj2/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwinter-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ege8euj2\u001b[0m\n",
+      "2020-10-11 11:17:59,973 - wandb.wandb_agent - INFO - Cleaning up finished run: ege8euj2\n",
+      "2020-10-11 11:18:00,301 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:18:00,301 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\trollout_fragment_length: 512\n",
+      "\tsgd_minibatch_size: 14112\n",
+      "\tuse_gae: True\n",
+      "2020-10-11 11:18:00,305 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --rollout_fragment_length=512 --sgd_minibatch_size=14112 --use_gae=True\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfragrant-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/m8f9dubo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3ljhyuu6\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_111802-3ljhyuu6\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 11:18:04,196\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:18:05,322 - wandb.wandb_agent - INFO - Running runs: ['3ljhyuu6']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 32.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/536.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_6f133_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
       "\n",
-      "\n"
+      "\u001b[2m\u001b[36m(pid=54494)\u001b[0m 2020-10-11 11:18:07,106\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=54505)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54505)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54430)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54430)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54425)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54425)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54538)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54538)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54499)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54499)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54437)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54437)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54512)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54512)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54414)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54414)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54435)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54435)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54536)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54536)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54417)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54417)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54528)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54528)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54422)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54422)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54434)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54434)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54409)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54409)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54424)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54424)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54421)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54421)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54410)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54410)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54442)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54442)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54439)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54439)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54501)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54501)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54407)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54407)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54490)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54490)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54412)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54412)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54441)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54441)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54426)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54426)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54416)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54416)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54482)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54482)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54428)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54428)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54420)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54420)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54521)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54521)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54418)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54418)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54423)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54423)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=54492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=54492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent rfs7la4y"
+    "!wandb agent uy2qf72q"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index 768b7fd..2a3703a 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index c91ecc1..8fb0ebb 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -12,7 +12,7 @@ default_config = {
     'num_envs_per_worker': 2,
     'rollout_fragment_length': 1024,
     'num_workers': mp.cpu_count() - 1,
-    'sgd_minibatch_size': 16112,
+    'sgd_minibatch_size': 12112,
     'evaluation_interval': None,
     'metrics_smoothing_episodes': 100000,
     'layer_size': 1024,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 0.0,
+    "entropy_coeff": 1e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/train.py b/JSS/train.py
index 568cc37..726922e 100644
--- a/JSS/train.py
+++ b/JSS/train.py
@@ -54,7 +54,7 @@ def train_func():
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
-    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
+    result = analysis.dataframe(metric='episode_reward_max', mode='max').to_dict('index')[0]
     wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
     if result['custom_metrics/time_step_max'] != float('inf'):
         wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 593fb77..2c9d0c4 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef/logs/debug-internal.log
\ No newline at end of file
+run-20201011_112901-s981ltt1/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4ee8a74..cc5758a 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef/logs/debug.log
\ No newline at end of file
+run-20201011_112901-s981ltt1/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 086031d..07dc50f 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef
\ No newline at end of file
+run-20201011_112901-s981ltt1
\ No newline at end of file
